[{"content":"It was about time\u0026hellip; TL;DR A couple of months ago I\u0026rsquo;ve taken the CKS exam last week and I have passed it. It was about time to make a post about it which can be helpful to others.\nAfter studying for some weeks of studying (in fact, I scheduled the exam a week before the exam was expiring) and two attempts, I got the pass, the first was just to be safe as it was going to expire but the second one, let me 2 additional weeks to nail a couple of things.\nIn my opinion, the exam wasn\u0026rsquo;t that hard, by doing the killer.sh tests (provided when you order the exam) you have great questions which will be harder than the real exam.\nAs with other experiences with CKx certifications, killer-sh is extremely helpful but maybe you will have to dig deeper in some aspects if you want to have everything clear.\nThis one is not like the CKA or CKAD, as already mentioned in the CHECK THE DOC, you need to know your way around about many things: processes, tools, different K8s of course, and more. Check the DOC!!!!!\nDay of the exam It\u0026rsquo;s a 2-hour exam, so any extra time you can save, the better, maybe you should go to the toilet before taking the exam (although you can request a break if needed).\nUse the cheat sheet provided by the Kubernetes documentation at the beginning of the exam (search for it) as it will help you to remember some commands if you don\u0026rsquo;t remember them correctly\nYou can have opened more than one tab (that was my experience) to read through the documentation. In my case I had the official Kubernetes documentation opened to search as fast as I can through each topic.\nIf you get stuck in one question for more than 10 min, probably you should flag it and go with the next one!\nNote: The exam taken was based in Kubernetes v1.26 so obviously, PSPs were already out of the equation!\nResources The famous CKA Udemy course by Mumshad Mannambeth was great to know about some other resources I haven\u0026rsquo;t used nor known and for reviewing many others. The amazing collection of resources from Walid is a must: https://github.com/walidshaari/Kubernetes-Certified-Administrator CKA/CKAD exercises from https://github.com/dgkanatsios/CKAD-exercises More exercises: https://github.com/StenlyTU/K8s-training-official The Killer.sh test provided by the Linux training foundation is extremely helpful. Useful things I have learnt but NOT ALL are mandatory for the exam Useful \u0026ldquo;shortcuts\u0026rdquo; to use (use them as exported variables or aliases) export k=kubectl # already configured export do=\u0026#34;--dry-run=client -o yaml\u0026#34; # k get pod x $do export now=\u0026#34;--force --grace-period 0\u0026#34; # k delete pod x $now Can be helpful where and which control-plane components are installed: Kubelet, DNS, scheduler, etcd, and API server (as pods): /etc/kubernetes/manifests Check if it\u0026rsquo;s managed by SystemD under the folder: /etc/systemd/system\nStop control-plane components. Proceed to move manifests files from (default) location: /etc/kubernetes/manifests if you want to quickly \u0026ldquo;restart\u0026rdquo; a service which runs in an specific container.\nThen check there are no containers running and move it back to the previous\nAlso, you can check if the process (in this case kubelet) is running on a worker node: ps aux | grep kubelet\nCommands to test within the pods Review if port is opened from a particular pod (using a shell)\n\u0026gt; k exec -it \u0026lt;pod-name\u0026gt; -- bin/sh -c \u0026#34;nc -vz 10.36.0.18 80\u0026#34; Check how a resource manifest is structured (aka how to put fields within the YAML) \u0026gt; k explain --recursive \u0026lt;api-resource\u0026gt; ETCD backup and restore summary Gather the data from the etcd pod: k describe Review the IP and port provided by \u0026ldquo;listen clients\u0026rdquo; Use the snapshot save command Stop all control plane components (by moving the YAML files where the static pods are defined to another folder): root@master-node:~# cd /etc/kubernetes/manifests/ root@master-node:/etc/kubernetes/manifests# mv * .. Check no pods are running within the master-node: crictl ps Create directory before restoring snapshot: mkdir\u0026hellip; Restore snapshot (in the new empty directory created): ETCDCTL_API=3 etcdctl --data-dir /var/lib/etcd/restore snapshot restore /tmp/etcd-backup.db Change manifest from etcd to point to new directory: vim /etc/kubernetes/manifests/etcd.yaml NOTE: Don\u0026rsquo;t use snapshot status because it can alter the snapshot file and render it invalid\nTest if an SA or user can perform an action For a user:\nk auth can-i create configmap --as \u0026lt;user\u0026gt; -n \u0026lt;namespace\u0026gt; For a SA:\nk auth can-i list pod --as system:serviceaccount:\u0026lt;namespace\u0026gt;:\u0026lt;role\u0026gt; Wrap up It wasn\u0026rsquo;t a hard exam even for the limited time you have (2h) and I learnt about other resources I usually don\u0026rsquo;t use but overall it was great to know about them.\nRemember you have a free retake when you order the exam so don\u0026rsquo;t worry if you don\u0026rsquo;t make it in the first one but make sure to use your time wisely when taking it.\nThat\u0026rsquo;s all, next one is the CKAD which should be \u0026ldquo;easier\u0026rdquo; as per other reviews I have read.\nMore in the next post!\n","permalink":"https://dangaiden.github.io/cks-exam-experience/","summary":"It was about time\u0026hellip; TL;DR A couple of months ago I\u0026rsquo;ve taken the CKS exam last week and I have passed it. It was about time to make a post about it which can be helpful to others.\nAfter studying for some weeks of studying (in fact, I scheduled the exam a week before the exam was expiring) and two attempts, I got the pass, the first was just to be safe as it was going to expire but the second one, let me 2 additional weeks to nail a couple of things.","title":"My CKS experience"},{"content":" This is a \u0026ldquo;remake\u0026rdquo; from my previous guide and maybe I have missed something which is not properly updated.\nVMware Explore 2022 Europe is just a few weeks away and I am extremely excited because it means the first event that I am going to attend this year! (after not being able to attend Kubecon in Valencia\u0026hellip;).\nThis event is a bit special for me because it\u0026rsquo;s where I started to meet many people I know nowadays, so I am looking forward to meet most of them there!\nAs mentioned before, this is a \"remake\" of my previous guide with tips about transport, restaurants, places to go, etc. I am trying to update as much as I can but also I won't extend as much as I did in my 2019 guide. General information The event will take place from the 7th (Monday) to the 10th (Thursday) of November at Fira Gran Via in Barcelona, Spain.\nAlso, it is a great way to connect with a lot of people from the community, vendors, or other persons that you could be interested in (try not to be aggressive when approaching them).\nPeople are really friendly so, don\u0026rsquo;t be shy (you can try first on Twitter) and try speaking to members from the vCommunity (if you don\u0026rsquo;t know what it is just search for #vCommunity on Twitter!) for example.\nBesides, be sure to meet the vBrownbag crew (which I am part of) in the Tech talks area, so feel free to go there and say \u0026ldquo;Hi!\u0026rdquo; :)\nEvents My friend Fred Hofer has this handy resource where you can find all sort of parties and gatherings!\nThis year I am not organizing any #vFit run but I am planning to attend this fantastic breakfast for the community called #vBreakfast\nSome notes In Spain, tipping is entirely optional and its not very common so, it\u0026rsquo;s up to you if you want to leave a tip in case the service was exceptional or you think it deserves it.\nIn restaurants, shops, etc. the VAT tax is included. Therefore, you don\u0026rsquo;t have to worry to calculate an extra amount of money.\nThe official language in Barcelona is Spanish but most of the population speaks Catalan. Be ready to don\u0026rsquo;t understand some signboards from the street or public places.\nTransportation There are 3 different train services: Renfe (Local Train), TMB (metro/subway/underground) and FGC (Regional Train).\nRenfe and TMB are the most used because they have more combinations than the FGC and also better schedules.\nThen, you will see in this guide mentioning \u0026ldquo;train\u0026rdquo; for Renfe (the company) and metro/subway/underground for TMB.\nMasks are mandatory when using any public transport.\nComing from the airport Once you have landed at \u0026ldquo;El Prat\u0026rdquo; airport, there are a few ways to go to the city of Barcelona:\nTaxi (expensive but more convenient for people with less time or when the hotel is located in an isolated area). It will cost between 30-50 € from the Barcelona Airport to Sants (always depending on the traffic). Putting the hand luggage on the taxi trunk costs an additional euro. One of the services available is FreeNow or Cabify as Uber is not available in Barcelona.\n*By train, service called Renfe You can go to the Aeroport (airport) stop on the R2 Nord line (you must go to Terminal 2 to take the train). This line will take you to Sants-Estacio and will be great for people staying near Sants.\nThis line is less frequent than the next option but it takes less time. Pricing is subject to zones. In that case, From Aeroport to Sants-Estacio the price for a single ticket will be 4.60 €.\nBy metro/subway, TMB: Whole map\nUse the L9 Sud line, this is the Metro (subway/underground) service and can be combined with other lines (like L5 at Collblanc stop for example) within the same ticket.\nThis service is more frequent than the train service. This can be the best option for most people because you can use the same single ticket to go to other places by combining lines.\nBy bus (Aerobus service): The least recommended option as it will be crowded but it depends on your preferences and where you want to go.\nThe Aerobus service will take you to «Plaça Catalunya» (Catalunya Plaza) but it costs a bit more than other services (still 5,90 € in 2022), you can review more information here.\nInside Barcelona The Metro (subway/underground) is your best choice wherever you stay in Barcelona. If you want a cheap, frequent and \u0026ldquo;reliable\u0026rdquo; service within the whole city.\nBefore, there was a ticket (with 10 single rides) that could be used for more than one person, nowadays that ticket (called T-casual) is completely individual and can\u0026rsquo;t be shared with other people. More information\nWith the metro, you can travel through lines at the same cost. The main stops to consider will be Fira in L9 Sud, Plaça Espanya in L1/L3 and, Sants-Estacio in L5/L3.\nThe fastest way to VMware Explore? The closest stop to the VMware Explore event is Fira in L9 Sud or the Europa-Fira stop which is another stop from the L9-Sud line that also combines with another train service which is a different transport service than the metro and it has different stops.\nIf you stay near the Sants area, the Sants-Estacio stop in L5 will be your choice. Then, at Sants-Estacio station take the L5 to Collblanc stop and after that, change the line to L9 Sud until you arrive at the Fira stop.\nYou can see in the following map the VMware Explore precinct highlighted in yellow and the closest stops (marked in Europa-Fira stop which combines FGC and Metro services and, Fira stop at L9 Sud.\nOutside VMware Explore (Sightseeing) Here is a summary of famous places you could visit if you\u0026rsquo;re planning to visit Barcelona:\nLa Sagrada Familia Probably the most iconic building in Barcelona. It is an unfinished church designed by Gaudí, an architect who built many iconic buildings here in Barcelona.\nLocation Las Ramblas The most famous pedestrian street of Barcelona, you will see many kiosks and artists there while walking in the middle of the city.\nNote: Keep an eye on your belongings if you are watching an exhibition as pickpockets are specialists in those areas. Other than that, enjoy this long street.\nLocation\nLa Font Màgica de Montjuïc (Magic fountain of Montjuïc) This fountain is stunning at night. You should check the exhibitions scheduled with lights, music and water streams creating shapes.\nLocation\nPark Güell A gorgeous park with some designs from Gaudí and other architects that are interesting. You must buy a ticket in order to gain entrance to the Monumental Area (where you can see some monuments from Gaudí).\nLocation\nCasa Batlló A famous building designed by Gaudí also named «House of bones». Look at the facade which is something that you probably never seen before with the sculpted stonework, the windows or the painting.\nIt is also a museum where you can visit (ticket is needed) the building insights\nLocation\nCasa Milà; La Pedrera (The stone quarry) Another famous building designed by Gaudí. It has unique balconies and a courtyard that defines the style of Gaudí and also his last private residence.\nLocation\nThe Olympic port of Barcelona It is one of the most exciting leisure and touristic spots throughout Barcelona, with a wide offering of shops, clubs, and restaurants. It\u0026rsquo;s the gateway to the Barcelona beaches.\nLocation\nIn general, avoid going alone in the night, especially in «Las Ramblas», «El Raval»\nAlso, avoid the neighborhood known as «La Mina» which is farther from Barcelona but it still accessible by Metro.\nRestaurants The food in Barcelona is\u0026hellip;very nice (compared to other countries ;) ) and some of you probably know it.\nIn Gran Via 2 (a shopping center pretty close to Fira Gran via) I can suggest you:\nA great Japanese (Udon) A good Italian (La Tagliatella) Great overall local food (Casa Carmen) The best places aren\u0026rsquo;t near Fira Gran Via but if you want to try better food, here are a couple of restaurants that are really nice:\nBacoa Burger Amazing and customized burgers, also hand-made fries and sauces. It\u0026rsquo;s a franchise but one of those which are extremely worth it.\nKönig Great restaurant where you can try almost everything: tapas, amazing beer, flatbread, and many other options.\nLa Bella Napoli Not too many choices on the menu in this Italian restaurant but the food quality is amazing.\nBuenos Aires Grill Restaurant You want meat? Steak, ribs, Argentinian Beef, special cuts, etc.\nTakumi Ramen For me, one of the best ramen you can find, there are a couple in Barcelona, be sure to check them as they have different dishes depending on which one are you going.\nLocal food Let me put a short section about local food here.\nThe food you must try while staying here would be: Paella, Spanish omelet, Bread with (spread) tomato and of course Ham (Jamón)!\nDespite there many restaurants that they prepare all these dishes, I will avoid the ones in Las Ramblas because they\u0026rsquo;re usually not the best option…\nBread with (spread) tomato and olive oil can be found in almost any bar or restaurant so, just ask for it. They are also served at breakfast! Also, on these dates, it is common for street vendors to sell hot toasted chestnuts wrapped in newspaper, give it a try!\nFinally, within this season, you should try a sweety called «panellets» (special almond balls covered in pine nuts), you can find them in bakeries:\nThere are many other places and foods not included here. If you want something specific just let me know in the comments or DM on Twitter.\nConclusion That will be a summary of things to do at VMware Explore and in the city of Barcelona.\nBe sure to enjoy VMware Explore with all the events, parties, people and more things that can give you but overall, have fun!\nIf you think that something is missing, let me know.\nSee you at VMworld, sorry, I meant VMware Explore ;)\n","permalink":"https://dangaiden.github.io/vmwareexplore-europe-local-guide/","summary":"This is a \u0026ldquo;remake\u0026rdquo; from my previous guide and maybe I have missed something which is not properly updated.\nVMware Explore 2022 Europe is just a few weeks away and I am extremely excited because it means the first event that I am going to attend this year! (after not being able to attend Kubecon in Valencia\u0026hellip;).\nThis event is a bit special for me because it\u0026rsquo;s where I started to meet many people I know nowadays, so I am looking forward to meet most of them there!","title":"VMware Explore 2022 local guide (remake)"},{"content":"Wow, seems unbelievable but It\u0026rsquo;s been already a YEAR since I joined VMware!\nYes, in June 20th I started working in a new company, VMware, which most of people in IT will know because of the hypervisor revolution about 20 years ago or so ;)\nWhy? Well, if you\u0026rsquo;re reading this, chances are that you know that I\u0026rsquo;ve been around the #vCommunity for years and well, I\u0026rsquo;ve been working a lot with VMware products (basically since I started in IT, more than 10 years ago!).\nI am still a vExpert but no longer a VMUG Leader and although I haven\u0026rsquo;t touched anything VMware related since 2019 (as I moved twice), I still retain some of the knowledge which helps a bit I guess plus, I liked some of the VMware products, especially, the well known Hypervisor ESXim which is widely spread on many DCs.\nTherefore, why I decided to move?\nAlthough I aimed for this company years ago and now wasn\u0026rsquo;t my main target, once I saw the role and how it was related to Tanzu, it was a clear yes for me.\nMy team, Tanzu Platform Labs Service, is dedicated to enable customers with Tanzu and anything related to Kubernetes (or any other cloud-native technology) but we know the buzzword/famous one is K8s.\nUncertainity Regarding this uncertainity about the Broadcom acquisition and so, well, I can tell you I decided to join even after knowing it was going to be acquired.\nWas it a good decision?\nTime will tell but I am betting that the Tanzu portfolio is one of the best things that VMware has as company, hopefully Broadcom won\u0026rsquo;t do anything but I am just speaking out loud : )\nMeanwhile I am learning a lot from the customers and teammates where I work everyday so I can\u0026rsquo;t complain about my current situation.\nMy experience so far I am enjoying this role within the Tanzu Plaform Labs services team, a team which not only focuses on everything related Tanzu but enabling the customers with DevOps methodologies, Agile practices, etc to embrace Kubernetes in the best way.\nSounds like a sales-pitch but I like that I am not exclusively tied to teach how a product like Tanzu works.\nBesides that I have the opportunity to work deploying other OSS projects (like Harbor, Contour, cert-manager, etc.) plus teaching methodologies to companies which are embracing Kubernetes for their first time or have little experience with it.\n","permalink":"https://dangaiden.github.io/a-new-journey/","summary":"Wow, seems unbelievable but It\u0026rsquo;s been already a YEAR since I joined VMware!\nYes, in June 20th I started working in a new company, VMware, which most of people in IT will know because of the hypervisor revolution about 20 years ago or so ;)\nWhy? Well, if you\u0026rsquo;re reading this, chances are that you know that I\u0026rsquo;ve been around the #vCommunity for years and well, I\u0026rsquo;ve been working a lot with VMware products (basically since I started in IT, more than 10 years ago!","title":"New role"},{"content":"Another Kubernetes exam: CKAD TL;DR I passed the CKAD exam a couple of weeks ago. As I already expected, it was easier than the CKA. Most of the resources to be used are the same than the CKA.\nHow much do I study for this one? Well, I already have experience with Kubernetes, took the CKA 3 weeks ago so I just took twice the killer.sh test and It was enough but your mileage may vary.\nThis post will be way shorter than the other one I published as the topics for the exam are \u0026ldquo;similar\u0026rdquo; and most of the stuff is relevant to this exam.\nDay of the exam Tips are the same as I have used for my CKA experience post\nIt\u0026rsquo;s a 2-hour exam, so any extra time you can save, the better, maybe you should go to the toilet before taking the exam (although you can request a break if needed). Use the cheat sheet provided by the Kubernetes documentation at the beginning of the exam (search for it) as it will help you to remember some commands if you don\u0026rsquo;t remember them correctly You can have opened another tab to read through the documentation but only one tab. In my case I had the official Kubernetes documentation opened in my other screen to read/search as fast as I can. Don\u0026rsquo;t worry too much about the alias, the \u0026ldquo;alias k=kubectl\u0026rdquo; is already provided, maybe you want to remember the one for \u0026ndash;dry-run=client -o yaml. Bash completion is provided as well. If you get stuck in one question for more than 10 min, probably you should flag it and go with the next one! Note: The exam taken was based in Kubernetes v1.23\nSome resources CKAD exercises from https://github.com/dgkanatsios/CKAD-exercises More exercises: https://github.com/StenlyTU/K8s-training-official The Killer.sh test provided by the Linux training foundation is extremely helpful. Useful things to know for the exam Useful \u0026ldquo;shortcuts\u0026rdquo; to use (use them as exported variables or aliases) export k=kubectl # already configured export do=\u0026#34;--dry-run=client -o yaml\u0026#34; # k get pod x $do export now=\u0026#34;--force --grace-period 0\u0026#34; # k delete pod x $now Commands to test within the pods Review if port is opened from a particular pod (using a shell):\n\u0026gt; k exec -it \u0026lt;pod-name\u0026gt; -- bin/sh -c \u0026#34;nc -vz 10.36.0.18 80\u0026#34; Learn to run a temporary pod to test something k run temp --restart=Never --rm -i --image=nginx:alpine -- curl 10.18.38.43:443 Check how a resource manifest is structured (aka how to put fields within the YAML) \u0026gt; k explain --recursive \u0026lt;api-resource\u0026gt; Test if an SA or user can perform an action For a user:\n\u0026gt; k auth can-i create configmap --as \u0026lt;user\u0026gt; -n \u0026lt;namespace\u0026gt; For a SA:\n\u0026gt; k auth can-i list pod --as system:serviceaccount:\u0026lt;namespace\u0026gt;:\u0026lt;role\u0026gt; Important commands to know related to Helm # List installed releases in selected namespace \u0026gt; helm ls -n \u0026lt;namespace\u0026gt; # Install and upgrade releases \u0026gt; helm install \u0026lt;name-you-want-to-use\u0026gt; -f values.yaml \u0026lt;repository\u0026gt; --version \u0026lt;chart-version\u0026gt; --debug \u0026gt; helm upgrade \u0026lt;release-name\u0026gt; -n default -f values.yaml traefik/traefik --version 10.9.1 - Optional values: \u0026gt; --version: if not used, will use latest chart version \u0026gt; --debug: verbose output of what is being performed \u0026gt; -f \u0026lt;file\u0026gt;: values.yaml is the file which you use to override default values provided by a chart. \u0026gt; --force: can be used to replace (kubectl replace) objects instead of patching them (by default, kubectl apply) # Commands related to repositories \u0026gt; helm repo list \u0026gt; helm repo update \u0026gt; helm search repo \u0026lt;release\u0026gt; \u0026gt; helm history \u0026lt;release-name\u0026gt; -\u0026gt; Check deployed releases \u0026gt; helm uninstall -n \u0026lt;namespace\u0026gt; \u0026lt;release-name\u0026gt; -\u0026gt; Uninstall an installed release \u0026gt; helm rollback \u0026lt;release-name\u0026gt; -\u0026gt; Rollback to previous version \u0026gt; helm rollback \u0026lt;release-name\u0026gt; \u0026lt;revision\u0026gt; -\u0026gt; Rollback to specific release revision Learn how a Dockerfile is structured and how to build, tag and push Docker images. Summary An easier exam compared to the CKA as expected but good to know some things for this developer path which is more focused in how to use Kubernetes itself.\nNext one, will be the CKS which is the harder one, I\u0026rsquo;ll take a break so probably I\u0026rsquo;ll take it on April.\nMore things for the CKS in the next post! ;)\n","permalink":"https://dangaiden.github.io/ckad-exam-experience/","summary":"Another Kubernetes exam: CKAD TL;DR I passed the CKAD exam a couple of weeks ago. As I already expected, it was easier than the CKA. Most of the resources to be used are the same than the CKA.\nHow much do I study for this one? Well, I already have experience with Kubernetes, took the CKA 3 weeks ago so I just took twice the killer.sh test and It was enough but your mileage may vary.","title":"My CKAD experience"},{"content":"GitHub Actions concurrency ","permalink":"https://dangaiden.github.io/ghactions-concurrency/","summary":"GitHub Actions concurrency ","title":"Github Actions Concurrency"},{"content":"It was about time\u0026hellip; TL;DR Last week I\u0026rsquo;ve taken the CKA exam last week and I have passed it! You can read the rest of the post for more insights and resources.\nI have been studying for 2-3 weeks but I wanted to share what I have used to study although I already have experience with Kubernetes so your mileage may vary.\nAnyway, I really like the practice exams as they really test you but practice and understand things instead of memorizing questions from a test.\nIn my opinion, the exam wasn\u0026rsquo;t hard, by doing the killer.sh test (provided when you order the exam) you have great questions which will be harder than the real exam.\nTherefore, once you understand all questions from the tests, feel fluent using the VIM editor (quite useful as you\u0026rsquo;ll have to tweak manifests/YAML files) and creating/modifying resources, you should feel ready for taking the exam.\nDay of the exam It\u0026rsquo;s a 2-hour exam, so any extra time you can save, the better, maybe you should go to the toilet before taking the exam (although you can request a break if needed). Use the cheat sheet provided by the Kubernetes documentation at the beginning of the exam (search for it) as it will help you to remember some commands if you don\u0026rsquo;t remember them correctly You can have opened another tab to read through the documentation but only one tab. In my case I had the official Kubernetes documentation opened in my other screen to read/search as fast as I can. Don\u0026rsquo;t worry too much about the alias, the \u0026ldquo;alias k=kubectl\u0026rdquo; is already provided, maybe you want to remember the one for \u0026ndash;dry-run=client -o yaml. Bash completion is provided as well. If you get stuck in one question for more than 10 min, probably you should flag it and go with the next one! Note: The exam taken was based in Kubernetes v1.22\nResources The famous CKA Udemy course by Mumshad Mannambeth was great to know about some other resources I haven\u0026rsquo;t used nor known and for reviewing many others. The amazing collection of resources from Walid is a must: https://github.com/walidshaari/Kubernetes-Certified-Administrator CKA/CKAD exercises from https://github.com/dgkanatsios/CKAD-exercises More exercises: https://github.com/StenlyTU/K8s-training-official The Killer.sh test provided by the Linux training foundation is extremely helpful. Useful things I have learnt but NOT ALL are mandatory for the exam Useful \u0026ldquo;shortcuts\u0026rdquo; to use (use them as exported variables or aliases) export k=kubectl # already configured export do=\u0026#34;--dry-run=client -o yaml\u0026#34; # k get pod x $do export now=\u0026#34;--force --grace-period 0\u0026#34; # k delete pod x $now Check expiration of certificates (using openssl and kubeadm): \u0026gt; openssl x509 -noout -text -in /var/lib/minikube/certs/apiserver.crt | grep -i valid -A2 Validity Not Before: May 13 22:33:43 2021 GMT Not After : May 14 22:33:43 2022 GMT With kubeadm: kubeadm certs check-expiration Quick check of versions of kubelet, kubeadm and kubectl (for upgrading): \u0026gt; ssh \u0026lt;kubernetes-node\u0026gt; \u0026gt; kubectl version --short \u0026gt; kubeadm version \u0026gt; kubelet --version Check where and which control-plane components are installed: Default CNI location: /etc/cni/net.d/\nKubelet, DNS, scheduler, etcd, and API server (as pods): /etc/kubernetes/manifests\nCheck if it\u0026rsquo;s managed by SystemD under the folder: /etc/systemd/system\nStop control-plane components. Proceed to move manifests files from (default) location: /etc/kubernetes/manifests or stop the appropriate service within the master node (in the case is installed as a service).\nTroubleshooting nodes If you have other clusters (like in the exam), check the manifests from other master nodes to see if you\u0026rsquo;re missing something.\nUsually, the main issues are related to paths, ports or some other sort of misspelling within the /etc/kubernetes/manifests folder.\nOthers can be as simple as checking and starting the kubelet service in the worker nodes:\n\u0026gt; systemctl status service_name \u0026gt; service status service_name Also, you can check if the process is running on the worker node: ps aux | grep kubelet\nCommands to test within the pods Review if port is opened from a particular pod (using a shell)\n\u0026gt; k exec -it \u0026lt;pod-name\u0026gt; -- bin/sh -c \u0026#34;nc -vz 10.36.0.18 80\u0026#34; Check how a resource manifest is structured (aka how to put fields within the YAML) \u0026gt; k explain --recursive \u0026lt;api-resource\u0026gt; ETCD backup and restore summary Gather the data from the etcd pod: k describe Review the IP and port provided by \u0026ldquo;listen clients\u0026rdquo; Use the snapshot save command Stop all control plane components (by moving the YAML files where the static pods are defined to another folder): root@master-node:~# cd /etc/kubernetes/manifests/ root@master-node:/etc/kubernetes/manifests# mv * .. Check no pods are running within the master-node: crictl ps Create directory before restoring snapshot: mkdir\u0026hellip; Restore snapshot (in the new empty directory created): ETCDCTL_API=3 etcdctl --data-dir /var/lib/etcd/restore snapshot restore /tmp/etcd-backup.db Change manifest from etcd to point to new directory: vim /etc/kubernetes/manifests/etcd.yaml NOTE: Don\u0026rsquo;t use snapshot status because it can alter the snapshot file and render it invalid\nTest if an SA or user can perform an action For a user:\nk auth can-i create configmap --as \u0026lt;user\u0026gt; -n \u0026lt;namespace\u0026gt; For a SA:\nk auth can-i list pod --as system:serviceaccount:\u0026lt;namespace\u0026gt;:\u0026lt;role\u0026gt; Wrap up It wasn\u0026rsquo;t a hard exam even for the limited time you have (2h) and I learnt about other resources I usually don\u0026rsquo;t use but overall it was great to know about them.\nRemember you have a free retake when you order the exam so don\u0026rsquo;t worry if you don\u0026rsquo;t make it in the first one but make sure to use your time wisely when taking it.\nThat\u0026rsquo;s all, next one is the CKAD which should be \u0026ldquo;easier\u0026rdquo; as per other reviews I have read.\nMore in the next post!\n","permalink":"https://dangaiden.github.io/cka-exam-experience/","summary":"It was about time\u0026hellip; TL;DR Last week I\u0026rsquo;ve taken the CKA exam last week and I have passed it! You can read the rest of the post for more insights and resources.\nI have been studying for 2-3 weeks but I wanted to share what I have used to study although I already have experience with Kubernetes so your mileage may vary.\nAnyway, I really like the practice exams as they really test you but practice and understand things instead of memorizing questions from a test.","title":"My CKA experience"},{"content":"New adventure ahead! Yes, it happened, in the past week\u0026hellip; I have moved to a new company!\nAfter 2 months of challenges, interviews and so (that\u0026rsquo;s one of the main reasons that I haven\u0026rsquo;t published anything), I started in a new place which is completely different of where I\u0026rsquo;ve been in the past.\nInstead of a consultancy, I am working in an end company, meaning, no working for different customers but for the same one, the company it self!\nA new environment This new place is called\u0026hellip;Kodify!\nWhich produces video content and building, developing and managing a number of high-traffic websites. That means that they not only create media but also manage high-traffic websites were to host this media!\nTech perspective For technologies perspective I\u0026rsquo;ll be using many already known technologies:\nAWS as the main cloud provider with services like Cloudfront, RDS, EC2, etc. Kubernetes (self-hosted), Docker, and Helm 3. Cloudformation and Terraform from an IaC perspective. EFK with Grafana and Thanos for observability. MongoDB, MySQL and PostgreSQL. GH actions and Jenkins. (OS) Linux : Debian, Ubuntu, Fedora, etc. So you know, technical stuff : )\nWhy this movement? It was time for me to move on from NTT, I already felt like stuck in the same place with no much movement and a bit limited in terms of growth (I know I moved this year to a new role but it was almost the same).\nThe opportunity to move to an end company with high-traffic websites, see another different kind of culture was appealing and I took it.\nTo conclude I am embracing this new change and I already like the welcome I have received, not only the people but the provided material which exceeded my expecattions. In fact, I am now a Mac user (M1 Pro 2021) thanks to them.\nCan be scary sometimes to move from a huge place to an smaller one but time will say, for now, I expect to know more about the company itself, how to provide value on it and help in the growth and manteinance of it!\nThat\u0026rsquo;s all, happy holidays to everyone!\n","permalink":"https://dangaiden.github.io/new-adventure/","summary":"New adventure ahead! Yes, it happened, in the past week\u0026hellip; I have moved to a new company!\nAfter 2 months of challenges, interviews and so (that\u0026rsquo;s one of the main reasons that I haven\u0026rsquo;t published anything), I started in a new place which is completely different of where I\u0026rsquo;ve been in the past.\nInstead of a consultancy, I am working in an end company, meaning, no working for different customers but for the same one, the company it self!","title":"New adventure ahead"},{"content":"DISCLAIMER I decided to not continue with this due to the huge implications that will be to redo everything not in the cloud. Basically, a lot of time should be invested and I miscalculated it by too much. Therefore, this will be probably the first and only post about these series.\nContext In order to practice for the CKA exam, it is recommended to perform the famous Kubernetes The Hard Way by Kelsey Hightower.\nThat guide is one of the best way to create a Kubernetes cluster by installing each component of them separatedly instead of using other tools like Kind, MiniKube, etc. which will create a K8s cluster without dealing about any complexity.\nIn this way, we can learn the componentes involved and how they really interact them.\nAs per writting this blog, the components will be:\nkubernetes v1.21.0 containerd v1.4.4 coredns v1.8.3 cni v0.9.1 etcd v3.4.15 Therefore, the Kubernetes the hard way guide will be my base to perform the Kubernetes cluster creation with all the componenrs or basically saying, I will do the \u0026ldquo;Kubernetes the hard way\u0026rdquo; a bit different :)\nThis is the first part of the series for the Kubernetes the hard way but on-prem. (Now discontinued)\nLocal infrastructure Note: This post explains how I did it and I can be wrong in some parts, do it in the most comfortable way for you.\nHere is the main point when it differs from the guide, we will do it with virtual machines (a.k.a. VMs) instead of using instances in the cloud, why?\nBecause I don\u0026rsquo;t want to setup a cloud account in GCP which will exceed the limits of the free tier (as it does in the guide) plus other concerns.\nIn this way, I can do it for free (with Virtual Box and with almost any Linux distribution) but it will require you to setup more things from the \u0026ldquo;nodes\u0026rdquo; (VMs) side.\nA quick diagram of what I will have in the PC (3 VMs in the same network):\nLet\u0026rsquo;s start with the infra We basically need a hypervisor (type 2, as we\u0026rsquo;ll install it in our OS), 3 virtual machines (that will act as our nodes for the K8s cluster) with an operating system, configure them and then the Kubernetes hype can start.\nThe hypervisor As easy as downloading Virtual Box (Oracle VM VirtualBox) and installing it in the flavour you want (I am using Debian 10).\nOperating system for our nodes For the OS, you can use whatever Linux distro you like the most, I am choosing Redhat 8 as months ago it was announced that CentOS 8 will be discontinued in 2022 and I wanted something that is widely used.\nI\u0026rsquo;ll link soon a simple guide to install the OS within a VM and some tips.\nInstall the needed tools in your PC Going through my own \u0026ldquo;hard way\u0026rdquo; for Kubernetes, I started directly here since I don\u0026rsquo;t need any SDK.\nSo here is how I did it the \u0026ldquo;Installing the Client Tools\u0026rdquo; part which differs from the version published in GKE.\nAs a reminder I am doing this in my PC with Debian 10 (buster).\nInstalling cfssl and cfssljson Install CFSSL to provision the PKI infrastructure and generate TLS certificates: $ sudo curl -s -L -o /bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 $ sudo curl -s -L -o /bin/cfssljson https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 $ sudo curl -s -L -o /bin/cfssl-certinfo https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 $ sudo chmod +x /bin/cfssl* $ sudo ls -lah /bin/ | grep cfssl -rwxr-xr-x. 1 root root 9.9M Aug 12 22:31 cfssl -rwxr-xr-x. 1 root root 6.3M Aug 12 22:33 cfssl-certinfo -rwxr-xr-x. 1 root root 2.2M Aug 12 22:31 cfssljson Verifying that is installed correctly: $ cfssl version Version: 1.2.0 Revision: dev Runtime: go1.6 $ cfssljson --help Usage of cfssljson: -bare the response from CFSSL is not wrapped in the API standard response -f string JSON input (default \u0026#34;-\u0026#34;) -stdout output the response instead of saving to a file Install kubectl Install kubectl (command line utility) to interact with the Kubernetes API server. We will install kubectl based in the official documentation:\n$ curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; Validate the checksum as specified in the Kubernetes official documentation and proceed to install it:\n$ sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl Now verify the version to see if it\u0026rsquo;s working correctly:\n$ kubectl version --client Client Version: version.Info{Major:\u0026#34;1\u0026#34;, Minor:\u0026#34;22\u0026#34;, GitVersion:\u0026#34;v1.22.0\u0026#34;, GitCommit:\u0026#34;c2b5237ccd9c0f1d600d3072634ca66cefdf272f\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;, BuildDate:\u0026#34;2021-08-04T18:03:20Z\u0026#34;, GoVersion:\u0026#34;go1.16.6\u0026#34;, Compiler:\u0026#34;gc\u0026#34;, Platform:\u0026#34;linux/amd64\u0026#34;} Summary of tasks completed:\nVMs (compute resources) ready. Install CFSSL to provision the PKI infrastructure and generate TLS certificates Install kubectl to interact with the Kubernetes API server So this is the end of the first part.\nWe made some things in our future nodes and installed some tools that will be required for later.\nIn the next post I\u0026rsquo;ll continue with the Provisioning Compute Resources section based in the Kubernetes the Hard way tutorial\n","permalink":"https://dangaiden.github.io/kubernetes-the-hard-way-but-on-prem-part-1/","summary":"DISCLAIMER I decided to not continue with this due to the huge implications that will be to redo everything not in the cloud. Basically, a lot of time should be invested and I miscalculated it by too much. Therefore, this will be probably the first and only post about these series.\nContext In order to practice for the CKA exam, it is recommended to perform the famous Kubernetes The Hard Way by Kelsey Hightower.","title":"Kubernetes the hard way but on-prem - part 1 (Discontinued)"},{"content":"OSS monitoring series Context If you work with micro-services (maybe not) and in the cloud (or not), you have probably heard about the many products for monitoring (or monitoring stacks), the most \u0026ldquo;modern\u0026rdquo; and famous OSS are:\nELK stack (Elasticsearch, Logstash, and Kibana) Grafana stack (Grafana, Loki and Prometheus) All these products are open-source projects which have become the go-to for many companies and I can deny that they work well (at least in my experience) especially for services built in the cloud or micro-services.\nOf course I can\u0026rsquo;t forget other open source projects like Zabbix or Nagios but those are ones which I haven\u0026rsquo;t seen to escalate as good as these ones, being versatile or being used as much as the ones I mentioned before.\nThere are other products like Splunk, Dynatrace, Datadog, etc. to talk about but I am aiming for those two stacks in particular (ELK and Grafana) as they are well known, accessible and open source.\nSeries purpose In this particular post I want to give a general overview for each tool within each stack but in the next ones I will give instructions about how to install, configure and useful features of both.\nI hope this can guide new people or even discover new items for each tool.\nWait, why monitoring? Well, there are some points that we should take in to account but in a brief summary:\nAlerting: This is the most important ones, we want to know if something is broken and needs assistance to be fixed\nAnalyze trends (long and short ones): Maybe you would like to analyze the growth of a DB or simply want to know how many HTTP requests are handling your servers to\nDebugging : Correlate events at the same time can be extremely helpful for incidents\nSo with those in mind, we can build dashboards and have beatiful graphs, logs and so which is going to be key for\nBasics ELK stack ELK stands for Elasticsearch, Logstash, and Kibana as you probably have guessed.\nGrafana stack Reference: https://sre.google/sre-book/monitoring-distributed-systems/ https://www.moogsoft.com/blog/observability-site-reliability-engineers/\n","permalink":"https://dangaiden.github.io/oss-monitoring-series/","summary":"OSS monitoring series Context If you work with micro-services (maybe not) and in the cloud (or not), you have probably heard about the many products for monitoring (or monitoring stacks), the most \u0026ldquo;modern\u0026rdquo; and famous OSS are:\nELK stack (Elasticsearch, Logstash, and Kibana) Grafana stack (Grafana, Loki and Prometheus) All these products are open-source projects which have become the go-to for many companies and I can deny that they work well (at least in my experience) especially for services built in the cloud or micro-services.","title":"OSS monitoring series"},{"content":"Quick How-to with RHEL Create an account (it\u0026rsquo;s free) and download RHEL ISO from the official repository here Create a VM in VirtualBox with the resources you want. I created mine with 2GB of RAM, 2 vCPU and 40 GB of disk space . Follow the wizard and install the way you prefer: Minimal server, Keyboard, network, etc. Recommended to partition your disk with LVM and partition it as recommended by the provider Once is installed proceed to log as root to the OS (I used \u0026ldquo;Somred1\u0026rdquo; as hostname) and add another user (dangaiden as example) with a password: $ useradd dangaiden \u0026amp; passwd dangaiden 4.1 Add the user to the wheel group or to the sudoers file (as you prefer): Use visudo or usermod -aG wheel dangaiden Register the new system to RHEL portal:\n$ subscription-manager register --username=\u0026lt;username\u0026gt; --password=\u0026lt;password\u0026gt;\nYou are attempting to run \u0026#34;subscription-manager\u0026#34; which requires administrative privileges, but more information is needed in order to do so. Authenticating as \u0026#34;root\u0026#34; Password: Registering to: subscription.rhsm.redhat.com:443/subscription The system has been registered with ID: 5512e476-8ecd-4e44-a986-e4340424aa6d The registered system name is: Somred1 5.1 Attach a license from our newly created account in the RHEL portal.\n$ subscription-manager attach --auto\nYou are attempting to run \u0026#34;subscription-manager\u0026#34; which requires administrative privileges, but more information is needed in order to do so. Authenticating as \u0026#34;root\u0026#34; Password: Installed Product Current Status: Product Name: Red Hat Enterprise Linux for x86_64 Status: Subscribed 5.2 Verify the status:\n$ subscription-manager status\nYou are attempting to run \u0026#34;subscription-manager\u0026#34; which requires administrative privileges, but more information is needed in order to do so. Authenticating as \u0026#34;root\u0026#34; Password: +-------------------------------------------+ System Status Details +-------------------------------------------+ Overall Status: Current System Purpose Status: Not Specified 5.3 Verify the repositories list\n$ sudo yum repolist\n[sudo] password for dangaiden: Updating Subscription Management repositories. repo id repo name rhel-8-for-x86_64-appstream-rpms Red Hat Enterprise Linux 8 for x86_64 - AppStream (RPMs) rhel-8-for-x86_64-baseos-rpms Red Hat Enterprise Linux 8 for x86_64 - BaseOS (RPMs) You\u0026rsquo;re good to go, we can install for example tree!\n$ sudo yum install tree\n[sudo] password for dangaiden: Updating Subscription Management repositories. Red Hat Enterprise Linux 8 for x86_64 - BaseOS (RPMs) 6.4 MB/s | 34 MB 00:05 Red Hat Enterprise Linux 8 for x86_64 - AppStream (RPMs) 5.4 MB/s | 31 MB 00:05 Dependencies resolved. . . (Ommited some output) . Installed products updated. Installed: tree-1.7.0-15.el8.x86_64 Complete! Copy your ssh key to the server: ssh-copy-id\nShutdown and clone the newly created VM (Create a full clone and remember to change MAC address for the NICs).\nOnce it\u0026rsquo;s cloned, power on the new one and proceed to:\nChange the hostname: # vi /etc/hostname\nChange the ip address: # vi /etc/sysconfig/network-scripts/ifcfg-enp0s3\nReboot it and done! ","permalink":"https://dangaiden.github.io/Simple-guide-install-and-configure-RHEL-in-VM/","summary":"Quick How-to with RHEL Create an account (it\u0026rsquo;s free) and download RHEL ISO from the official repository here Create a VM in VirtualBox with the resources you want. I created mine with 2GB of RAM, 2 vCPU and 40 GB of disk space . Follow the wizard and install the way you prefer: Minimal server, Keyboard, network, etc. Recommended to partition your disk with LVM and partition it as recommended by the provider Once is installed proceed to log as root to the OS (I used \u0026ldquo;Somred1\u0026rdquo; as hostname) and add another user (dangaiden as example) with a password: $ useradd dangaiden \u0026amp; passwd dangaiden 4.","title":"Simple-guide-install-and-configure-RHEL-in-VM"},{"content":"Some months missing between my last update!\nI must say I have been quite busy with the new position and the massive change that has impacted my previous knowledge but overall, I am pretty happy with it!\nTherefore, let\u0026rsquo;s move to the point! So I just want to share some notes of the AZ-400 exam which I recently passed and I hope that can be useful to someone.\nCertification details This exam (AZ-400) is the second one of the path to the specific «Microsoft Certified: DevOps Engineer Expert» certification:\nLast month I passed the Azure Administrator Associate exam (AZ-104) so I had the prerequisite already.\nYou can check the objectives measured in detail for the exam here but as a summary, this is what the official documentation states:\nDevelop an instrumentation strategy (5-10%) Develop a Site Reliability Engineering (SRE) strategy (5-10%) Develop a security and compliance plan (10-15%) Manage source control (10-15%) Facilitate communication and collaboration (10-15%) Define and implement continuous integration (20-25%) Define and implement a continuous delivery and release management strategy (10-15%) Notes and resources for the exam Be sure to try Azure DevOps lab where you'll be able to use Azure DevOps for free and with many guided Hands-on labs (https://github.com/microsoft/azuredevopslabs) → MUST\nStudy the majority of the Azure Products that can be related to any process within a pipeline, therefore, applications, web apps, secrets, repositories, VMs, etc. Of course, I suggest you read and try Azure DevOps and the many of the integrations that can have with Github (remember that it's owned by MS) within a pipeline. This includes things like Azure boards, App Configuration, Azure feeds, Key Vault, Artifacts Credential Provider, etc. Monitoring tools within Azure\u0026#8230;you know, the ones that you already know if you have taken the AZ-104, things like Application Map (within App Insights), Security Center, Data Explorer, App Configuration, Hosted agents, etc. Knowledge about 3rd party products like Helm, Sonarqube, Terraform, Yeoman, and many other tools that analyze code or vulnerabilities will be helpful. Git basics is a must, knowing things like (init, Pull, push, commit, add, clone. etc.) but more «advanced» things like (prune, gc, pull \u0026#8211;rebase, stash). Branching with Git (Main, Develop, Feature, etc) and deployment (Rolling, A/B, canary, blue/green, etc.) strategies will be key to understand as one of the main things used in pipelines. Software testing as well: Smoke, flaky, unit, acceptance, etc. Container basics with Docker (Dockerfiles, build/scan images process, etc.), AKS (Install, RBAC, configure), Azure Container instances, etc. There can be more of course but I think you can get an idea of what can I think it can be useful and probably I missed many things I already know that I haven\u0026rsquo;t studied.\nExam and opinion As for now, there aren\u0026rsquo;t simulations in the exam but be prepared to answer multi-choice, single, hot-area, and drag \u0026amp; drop questions plus case studies.\nThere are about 60 questions in the exam and 150 minutes for non-native speakers (if I am not wrong) so plenty of time to answer each question.\nSome questions are quite specific and not very related to general knowledge or even outdated which I don\u0026rsquo;t like it but that\u0026rsquo;s how certifications work in many cases.\nMost of them are related to Azure, DevOps, and the integration with 3rd party applications so be sure to check them and don\u0026rsquo;t hesitate to make a list of third-party applications and the usage of them within different languages.\nI studied for a month or so but I do have a certain experience with Azure and I think a great knowledge of many of the processes, 3rd party tools (Jenkins, Sonarqube, Helm), and strategies used in pipelines within CI/CD. Be sure to test and experiment with Azure DevOps as it is obvious that it will appear in the exam 🙂\nConclusion I found it fair but not easy for someone who just got introduced to Azure Dev and has a general knowledge of the «DevOps world» (I hate to say it like this).\nIt requires a bit of experience with many of the Azure products, how are they correlated/integrated within a pipeline and many other tools.\nI hope this can be useful to anyone willing to take this but in my case, I did it so can you!\n","permalink":"https://dangaiden.github.io/2021-06-08-az-400-exam-notes/","summary":"Some months missing between my last update!\nI must say I have been quite busy with the new position and the massive change that has impacted my previous knowledge but overall, I am pretty happy with it!\nTherefore, let\u0026rsquo;s move to the point! So I just want to share some notes of the AZ-400 exam which I recently passed and I hope that can be useful to someone.\nCertification details This exam (AZ-400) is the second one of the path to the specific «Microsoft Certified: DevOps Engineer Expert» certification:","title":"AZ-400 exam notes"},{"content":"Finally, after some time\u0026hellip; I am writing something here.\nIt\u0026rsquo;s being almost 5 months since I wrote my last blog post and it happened so fast but my final project kept me quite busy between November \u0026lsquo;20 and January \u0026lsquo;21.\nAfter finishing my bachelor\u0026rsquo;s degree final project in January, I\u0026rsquo;ve been enjoying some free time for myself and with that, I «forgot» about writing (a.k.a. procrastination) but not anymore as I plan to start again writing as I did in the past.\nMore on that project and the bachelor\u0026rsquo;s degree in the next blog posts!\nGetting to the point… I am writing this because finally, after waiting for 5 months (internal arrangements) I am moving to another position! So I am changing the role but not the company.\nTherefore, since today, I\u0026rsquo;ll be a «Cloud SRE» within NTT.\nCloud what? Wait\u0026hellip;what the hell is «Cloud SRE»? I know\u0026hellip;it\u0026rsquo;s a weird name but it\u0026rsquo;s the official name for the position. Probably a better name would be Cloud Automation Engineer (or similar) as I am not going to work with developers in pipelines and helping them closely.\nI\u0026rsquo;ll be working with technologies and tools like Git, Ansible, Terraform, Packer, and more. Containers and Kubernetes (very well known) are also on the menu but the biggest change for me will be the infrastructure. I\u0026rsquo;ll be working only with cloud providers, specifically GCP and Azure, for now, we will see later.\nChallenges ahead Well, it could sound just a mere position change but for me, it would be a huge one. From using VMware, Microsoft and some Linux technologies mainly in on-premises infrastructures to mainly Linux with Git, Ansible plus containers in the cloud will be a huge change (which I am eager to start!). So basically Infrastructure as Code (IaC), which is a more common thing these days and quite convenient for the cloud.\nThis doesn\u0026rsquo;t mean I won\u0026rsquo;t be posting more VMware things but probably more container-ish, cloud (GCP and Azure), and probably Linux things as I will be learning a lot of them 🙂\nP.S. This change will have a massive impact on my Windows to Linux journey which I expect to write some of it shortly!\n","permalink":"https://dangaiden.github.io/2021-03-22-new-role-moving-to-the-cloud/","summary":"Finally, after some time\u0026hellip; I am writing something here.\nIt\u0026rsquo;s being almost 5 months since I wrote my last blog post and it happened so fast but my final project kept me quite busy between November \u0026lsquo;20 and January \u0026lsquo;21.\nAfter finishing my bachelor\u0026rsquo;s degree final project in January, I\u0026rsquo;ve been enjoying some free time for myself and with that, I «forgot» about writing (a.k.a. procrastination) but not anymore as I plan to start again writing as I did in the past.","title":"New role, moving to the cloud!"},{"content":"Well, I’ll be lying if I haven’t heard of containers in the past years although I used them barely at my job (solutions engineer) shouldn’t I consider them more every time to replace the applications where my customers have their servers?\nLike many people that work as sysadmin these days, they are used to work with virtualization, in particular Virtual Machines (VMs), customers still using them (and it will continue) to deploy their applications in an OS which delivers great benefits against the legacy approach of the Baremetal (Mainframe) era.\nAlthough there are other ways to deploy your applications (always depends on your application but we are taking a general approach), containers are always in the mind of Cx0 people because of their advantages against virtualization and the trend that has become in the past years.\nBut, which is the correct approach for an application? As always, it depends but I am going to talk about the technologies used now and the trend that I can see.\nTalking about virtualization For many years, virtual machines have been the way to go to deploy applications within servers. You seize the hardware by running an «OS» (hypervisor) and inside of it, you run your VMs where you can assign virtual resources as you desire.\nThis has been (and it continues) to be the first approach for many new companies as it’s now quite standardized.\nIn my opinion, I think that VMware is the most famous provider by offering their Hypervisor ESXi, which has proved to be the standard for VMs.\nI am not going to dive in on this as you can search for more information on Google (or whatever search engine you like to use).\nTalking a bit about containers It’s known that the most famous container runtime is Docker although Podman seems to be the direct rival (perspective only from my understanding, which is little)\nAlso, the benefits of segmenting your applications on different services (containers) will normally let you escalate, perform, etc. better than running it on VMs\nThe principal benefit of running services in containers is that you have a single OS where each container runs on it. All dependencies for the application you are deploying in the container are «in the OS» and this isolation is managed by the container runtime (Docker in the image that you see below):\nIs there a mix? Well\u0026hellip; The main problem I saw the first time when I saw how the container runtime works is, how «isolated» is each container from each other? What about a security breach in the OS?\nAnd then it’s when I found a mix of both worlds (which I really need to dig into it).\nKata Containers, a promising Open Source project where it combines both worlds and trying to deliver the best features from both technologies.\nBy running a dedicated kernel (part of the operating system) you provide isolation from many resource perspectives like network, memory, and I/O for example without the performance disadvantatges that virtual machines have.\nRemoves the necessity of nesting containers in virtual machines (which I do like in some environments to provide the isolation that a container runtime can provide).\nObviously not everything is good and it has some limitations like Networking, Host Resource and more. You can find them here\nSummary We don’t know the future but for sure containers are still a trend for many years.\nYou can see that even VMware embedded Kubernetes (Container orchestrator) in their products.\nSo it will be everything containers, a mix of containers and VMs or something like Kata Containers could be the next thing?\nWe will see, for now, let me research more in this last open-source project and see how it really delivers!\n","permalink":"https://dangaiden.github.io/2020-10-31-applications-future-containerd/","summary":"Well, I’ll be lying if I haven’t heard of containers in the past years although I used them barely at my job (solutions engineer) shouldn’t I consider them more every time to replace the applications where my customers have their servers?\nLike many people that work as sysadmin these days, they are used to work with virtualization, in particular Virtual Machines (VMs), customers still using them (and it will continue) to deploy their applications in an OS which delivers great benefits against the legacy approach of the Baremetal (Mainframe) era.","title":"Is the applications’ future «containe(r)d»?"},{"content":"It\u0026rsquo;s been more than one month since I published something here but I\u0026rsquo;ve been changing quite a lot my focus learning and I changed now from CCNA to DevOps things.\nTL;DR I will be building an automated CI/CD pipeline for my final assignment focusing on tools installed and configured on-premise although there will be cloud services like the front-end.\nAlso, I forgot to mention that last month I started the last semester of my Computer Engineering degree that I started back in 2014 (oh my!), and I expect to finish it (if I pass the last «subject») next January 2021!.\nAnd now let\u0026rsquo;s move to the point.\nIn this last semester, I have to deliver the «final assignment» which consists of a project of my own that will be documented and then defended (virtually as per the current circumstances) against university judges.\nIn my case, I finally decided to get into the DevOps world and my assignment is Building a production CI/CD pipeline.\nSome sort of introduction I suppose you\u0026rsquo;re currently aware of the trending topic regarding Containers and Container Orchestrators, in particular (you know them), Docker and Kubernetes.\nThose two are the most used technologies in the DevOps world because they work great in conjunction although there are alternatives that could work as good as them.\nSo regarding DevOps, you probably know is a culture and it follows a set of practices where the software development world and the IT operations are combined in order to speed up and improve the process of application delivery (a.k.a. SDLC).\nContinuing with DevOps, there is a pipeline or process which combines the practices of CI (Continuos Integrity) and CD (Continuous Delivery) and that\u0026rsquo;s the process that I am going to describe and build for my final assignment.\nBut\u0026hellip;why this topic? Good question\u0026hellip;I know almost nothing about that world which is a good approach for many enterprises but not for all of them.\nAnd, the same thing with containers, all the applications shouldn\u0026rsquo;t be always in containers but if you can re-code your app to split it into micro-services to make it better would you do it (That probably means spending large amounts of money)?\nAnyway, why I am choosing this topic?\nI think it\u0026rsquo;s a great opportunity to finally take a look into this area where developers need to push updates to production apps in the faster way possible. We saw that even VMware focused on Kubernetes in their product catalog so maybe you should take a look as well\u0026hellip;\nBut not because VMware did it nevertheless, we are moving to a faster and automated world where everything is becoming more and more automatized. Just deploying containers and building micro-services will make you the coolest guy in the world but in my opinion, knowing the use cases and some tools to provision and automate lots of items will make you smarter.\nI believe that this will help me to gain knowledge in those areas and advance in my career, therefore, I will be sharing all the useful information I researched during the entire project.\nHow? It is known that there many ways to build a CI/CD pipeline and many tools that you can use for each phase but in this project, I will try to start with the «foundation» of the main tools used (Container runtime, Container Orchestrator, Configuration and provision management, etc.).\nAll of them would be hosted in on-premise infrastructure, instead of going to the cloud where there are a lot of tools that integrates many things and will help you to avoid problems and headaches.\nSo basically, I am aiming* to build everything on-premise except the service itself (which will be a web application) that would be hosted in the cloud, in order to achieve a better service in terms of availability, resiliency, etc.\nTherefore,** a mix of on-premise and cloud CI/CD pipeline is the objective** with the main focus on the process and not the code of the application.\nThat doesn\u0026rsquo;t mean that the process where the developer has to push code to a repository (CI) will be neglected, in fact, probably some tools for the developer will be cloud-based due to the simplicity that adds but can\u0026rsquo;t ensure that this will be my final approach\nSummary In short, I am aiming to gain knowledge about this new area where developers and operations meet, and «everything» is automated (or at least a great part of it).\nAlthough there are many tools to build a CI/CD pipeline, learning which tools to use on each phase, how and why are chosen will be key in order to understand clearly the whole process from a technical perspective.\nI forgot to mention that, there are other things like IaC (Infrastructure as Code) and Control Version which are handy everywhere but especially in this environment as with code you can have different versions and avoid more errors than provisioning resources manually.\n","permalink":"https://dangaiden.github.io/2020-10-19-finishing-a-computer-engineering-degree-with-devops-stuff/","summary":"It\u0026rsquo;s been more than one month since I published something here but I\u0026rsquo;ve been changing quite a lot my focus learning and I changed now from CCNA to DevOps things.\nTL;DR I will be building an automated CI/CD pipeline for my final assignment focusing on tools installed and configured on-premise although there will be cloud services like the front-end.\nAlso, I forgot to mention that last month I started the last semester of my Computer Engineering degree that I started back in 2014 (oh my!","title":"Finishing a Computer Engineering degree with DevOps stuff"},{"content":"For some reason, our monitoring alerted that the service “vsphere-ui” from the vCSA it was having some problems randomly. From the user perspective only we noticed some slowness when navigating within the HTML5 client.\nI took a quick view of the VAMI I saw this message from the VMware vSphere Client service:\nThe server is running low on heap memory (\u0026gt;90% utilized.)\nSo it was time to solve those random alerts about memory utilization.\nLet’s work a bit… Accessing the vCSA via SSH (using PuTTY):\nI can see the service has 1110 MB assigned. So as the deployed VM for the vCenter Server appliance has 16GB of RAM allocated(you can see it anyway how much is being assigned in the previous screenshot), I decided to give it ~1.5x (1665MB) but in powers of 2!:\n512+1024 = 1536 MB . Executed:\n[powershell]cloudvm-ram-size -C 1536 vsphere-ui [/powershell]\nNow, restart the affected service:\n[powershell]service-control –stop vsphere-ui;service-control –start vsphere-ui; [/powershell]\nAnd now check the allocated memory for the service we configured:\nIt seems that the vCSA itself adjusted the value to what it considers it’s best so nothing that we can modify there. So finally this service memory allocation changed from 1110 MB to 1792 MB.\nFinal note: Obviously other services were modified and have allocated less memory, in general, it gathered a bit of memory allocation from each service (the most impacted was vmware-vpxd with ~ 300 MB)\nAll this information can be also reviewed in this KB: https://kb.vmware.com/s/article/2150757\nThat’s all for this quick post!\n","permalink":"https://dangaiden.github.io/2020-08-31-increasing-the-heap-memory-on-vcsa-6-7-services/","summary":"For some reason, our monitoring alerted that the service “vsphere-ui” from the vCSA it was having some problems randomly. From the user perspective only we noticed some slowness when navigating within the HTML5 client.\nI took a quick view of the VAMI I saw this message from the VMware vSphere Client service:\nThe server is running low on heap memory (\u0026gt;90% utilized.)\nSo it was time to solve those random alerts about memory utilization.","title":"Increasing the heap memory on vCSA 6.7 services"},{"content":"This is a short post talking about Windows Server Failover Clustering (WSFC) and a problem I found when adding the nodes from your cluster using the «Validate a Configuration» wizard.\nThis wizard is recommended to run after configuring your nodes and before creating the cluster in order to spot any misconfigurations.\nSo now, let’s go into the problem.\nThe issue In the wizard when trying to add (in my example) the second node shows an error:\nFailed to access remote registry on . Ensure the remote registry service is running, and have remote administration enabled.\nPossible solutions Execute in Powershell (PS): winrm quickconfig This will set up «winrm» (Windows Remote Management), more information in this link.\nReview the NIC settings on the affected node: Check the options “File and Print Sharing for Microsoft Networks» and «Client for Microsoft Networks» for the NIC that you’re are trying to add the node (based on what’s registered in DNS): Review the service «remote registry» is set to «automatic (trigger start)». After that, you shouldn’t have problems in order to add your nodes within the cluster from the wizard:\nNow, you could continue with the testing options and so on but this post is only to explain the error and how to solve it.\nThat will conclude this quick post about Windows Server Failover Cluster and an issue you can find while trying to validate the configuration of your cluster from the wizard.\n","permalink":"https://dangaiden.github.io/2020-06-29-wsfc-validate-configuration-wizard-error/","summary":"This is a short post talking about Windows Server Failover Clustering (WSFC) and a problem I found when adding the nodes from your cluster using the «Validate a Configuration» wizard.\nThis wizard is recommended to run after configuring your nodes and before creating the cluster in order to spot any misconfigurations.\nSo now, let’s go into the problem.\nThe issue In the wizard when trying to add (in my example) the second node shows an error:","title":"WSFC – Validate Configuration wizard error"},{"content":" In this blog post, we will see how to upgrade vRealize Operations (vROps) from version 6.7.0 to 8.0.1. The whole process takes about 30 minutes.\nBear in mind that, you will need new license keys after updating to the later version (after 8.0 version).\nNote: You will see a version mismatch in some screenshots.\nDownload the required files Download the Upgrade Assessment Tool available at VMware Downloads. And also, proceed to download the Virtual appliance upgrade PAK file, that will be used later for the real upgrade:\nUpgrade Assessment Tool (optional but recommended) The first thing to do is to install the Upgrade Assessment Tool in order to know if there are any problems before upgrading.\nAlthough this is not mandatory it is highly recommended in order to know if there are any issues before running the real upgrade process.\nThe steps are:\nLog in to the master node vRealize Operations Manager Administrator interface of your cluster at https://master-node-FQDN-or-IP-address/admin. Click Software Update in the left panel (you can see an attempt I made previously) and then «Install a Software Update…»: Follow the steps in the wizard to locate and install your PAK file. Upload the PAK file (the first file we downloaded) and check the first checkbox if you’re not sure if there is another one installed. The PAK file will be uploaded from your local machine to vRealize Operations Manager. Uploading may take a few minutes. Once it is uploaded you will see something like this. Once the uploaded PAK file, accept the EULA (step 2) if you agree, read the Update information (step 3) and finally click «Install». You will see that the software update is being installed Don’t worry this is just installing the Pre-Upgrade to 8.0.0 Assessment Tool, the real upgrade will be performed later\nWhen the process is complete, click Support in the left pane. The Support screen appears. Select the Support Bundles option above the toolbar. The available support bundles are listed: To review the report, extract the files from the ZIP file and open the HTML file.\nThe file is located in \\slice__\\apuat-data\\report\\index.html.\nThis is my report, which it only gives me a warning about executing the proper Virtual appliance upgrade (we will see later) After updating my Admin account I re-run the same process and checked that there were no errors. So now, let’s go to the point and update the vROps master node!\nUpgrade process Before doing anything, remember to take a snapshot of the Master node that is going to be upgraded!\nFirst, upload the .pak file we downloaded at the beginning of the Virtual Appliance upgrade PAK file (which is way larger than the Upgrade Assessment Tool PAK file).\nOnce downloaded, go to the vROps admin interface (https://master-node-FQDN-or-IP-address/admin) and then «Software Updates» :\nAnd then, upload the new file (which in this case is quite larger compared to the pre-upgrade assessment tool):\nOnce is staged (after you clicked upload), it will give you a warning regarding the cluster that will be restarted (obviously), just click NEXT:\nAccept the EULA if you agree and read the Update information (which tells you that you must take a snapshot of the cluster you’re upgrading):\nAnd proceed to install the update in step 4 by clicking INSTALL!\nYou will see on the same page that the upgrade is in progress:\nIt will take some time, and even you see that vROps is available, the cluster will still offline until the upgrade is finished. We just need to wait a bit more.\nThe whole upgrade took about 30 mins and it was upgraded successfully:\nFinally, the cluster is online and the new version was applied correctly.\nRemember to delete the snapshot that was created before proceeding with this upgrade. I hope this has been helpful to you.\n","permalink":"https://dangaiden.github.io/2020-05-21-upgrade-vrops-from-6-7-0-to-8-0-1/","summary":"In this blog post, we will see how to upgrade vRealize Operations (vROps) from version 6.7.0 to 8.0.1. The whole process takes about 30 minutes.\nBear in mind that, you will need new license keys after updating to the later version (after 8.0 version).\nNote: You will see a version mismatch in some screenshots.\nDownload the required files Download the Upgrade Assessment Tool available at VMware Downloads. And also, proceed to download the Virtual appliance upgrade PAK file, that will be used later for the real upgrade:","title":"Upgrade vROps from 6.7.0 to 8.0.1"},{"content":"Prologue With the release of vSphere 7 at the beginning of this month, I decided to make a post about how to install vCenter Server Appliance (vCSA) which is quite simple.\nWhich are the new features? Check this post from my friend Graham Barker to find out!\nLet’s move on!\nProceed to download the «VMware vCenter Server 7.0.0» ISO file from my.vmware.com Mount the ISO file and execute the installer.exe file : Prerequisite: We need DNS if we want to deploy vCenter with an FQDN but if you don’t have it or you can’t for any reason, you can trick the installer and put the IP address as the hostname and it will work.\nAnother prerequisite will be to have an ESXi host where we’re going to install our vCenter\nStage 1 – New deployment 1. We will proceed to select install as we are going to perform a fresh install from the scratch of vCenter Server 7.0.\n2. I like that it tells you that External PSC is deprecated! Continue with NEXT.\n3. Just put the details of a vCenter (if you have one) or an ESXi host where you want to deploy this new vCenter. In my case (and probably the most if you’re doing everything from the scratch) I am using a host called «johto.pokemon.jp» to deploy the vCSA.\nOnce you press next, accept the certificate warning if you know the fingerprint of the certificate.\n4. Put the name of the VM and set the root password for the vCSA and continue.\n5. I am going for the Tiny deployment as it is more than enough for my lab environment. In a production environment usually, you will deploy a small one that fits in many small companies (or in your lab if you’re testing it).\n6. Continue by selecting a Datastore and check » Enable Thin Disk Mode» which is usually the best deployment as it doesn’t allocate all the space and is also enabled by default. (Look even my VMFS-5 datastores work well).\n7. Now, let’s configure the network settings. Here my Network you can see a portgroup «Std_mgmt» from my ESXi host. If you have an ESXi host with default portgroups, yours probably is called «VM Network«.\nAbout the FQDN, as I said before (check the Prerequisite section in the beginning) you need to create an A record in your DNS in order to be able to deploy a vCenter with a name.\nIf you don’t have DNS because you’re installing vCenter and you don’t have it, you can use the IP address as FQDN and it will work.\n8. And that’s all for stage 1, here we have a summary saying what is going to do. Be sure to review it: Once you’re ready, press FINISH.\nIt will start with Stage 1, which is the deployment of the VM where the vCenter Server resides:\nAfter some minutes, STAGE 1 is completed, which means that the VM where the vCSA resides is deployed but not configured yet.\nStage 2 – Configuration Let’s go to STAGE 2 where the vCSA will be configured. 1. Set an NTP server or let the ESXi host also enable SSH if you want to have access to the vCSA.\n2. Configure the SSO, the default is the «vsphere.local» domain, in my case I created a custom one.\n3. And the last summary after we finish Stage 2 when the vCenter will be fully configured.\n4. After a while (15-20 min.), Stage 2 finished without errors!\n5. Now I access the GUI from the URL provided in the previous screenshot and I see that is working flawlessly!\n6. Enjoy your new vCenter Server with the only HTML5 interface and lots of new features that were mentioned at the beginning of this post.\nWe conclude this article where you can see how simple and easy is to install and deploy vCenter Server version 7.0.\n","permalink":"https://dangaiden.github.io/2020-04-28-vcenter-server-7-0-fresh-install/","summary":"Prologue With the release of vSphere 7 at the beginning of this month, I decided to make a post about how to install vCenter Server Appliance (vCSA) which is quite simple.\nWhich are the new features? Check this post from my friend Graham Barker to find out!\nLet’s move on!\nProceed to download the «VMware vCenter Server 7.0.0» ISO file from my.vmware.com Mount the ISO file and execute the installer.exe file : Prerequisite: We need DNS if we want to deploy vCenter with an FQDN but if you don’t have it or you can’t for any reason, you can trick the installer and put the IP address as the hostname and it will work.","title":"vCenter Server 7.0 – Fresh install"},{"content":"A few days ago VMware announced that VMworld will be online due to the current situation with COVID-19. Review the VMworld FAQs.\nTherefore, as there will be only one big online event during the week of September 28, 2020.\nSo, why not attend a free mini-VMworld in less than a month?\nThat’s vForum Online!\nvForum Online is a LIVE virtual event where you can access it directly from any device. Obviously there’s no travel required, so why not engage with more people and learn about new trends, features, and technologies?\nWhen is it? May 13th, 2020 9:00 AM – 3:00 PM PDT 12:00 PM – 6:00 PM EDT 6:00 PM \u0026#8211; 12:00 AM CEST Why attend? Lots of technical breakouts (+30) delivering practical guidance about many different VMware technologies.\nLive Q\u0026amp;A video chats, this is very nice, I like to be able to answer questions when I am on a session and receive an answer or at least some guidance.\n10+ instructor-led Hands-On Labs where you can test many technologies like vSphere, vSAN, VMware Cloud on AWS, Carbon Black, and Workspace ONE.\nWho Should Attend? Anyone! From solutions/network/storage engineers to CxO should join this virtual event, and remember, it’s free.\nThere would be some sessions in Spanish and Portuguese!\nAgenda Do you want to know the schedule? Check out the detailed agenda here\nFeatured attendees Pat Gelsinger – CEO, VMware, will be speaking at the event and there will be a VMware Expert Panel Discussion with:\nKit Colbert – CTO, Cloud Platform\nLee Caswell – VP, Storage and Availability\nPete Chargin – Sr. Director, vSphere Platforms\nDormain Drewitz – Director of Product Marketing\nRegister here!\nThat’s all! I will be there for a couple of hours and attend some sessions just to know a couple of things I am interested in and to chat with some of the experts that will be answering live.\n","permalink":"https://dangaiden.github.io/2020-04-21-vforum-online-spring-2020/","summary":"A few days ago VMware announced that VMworld will be online due to the current situation with COVID-19. Review the VMworld FAQs.\nTherefore, as there will be only one big online event during the week of September 28, 2020.\nSo, why not attend a free mini-VMworld in less than a month?\nThat’s vForum Online!\nvForum Online is a LIVE virtual event where you can access it directly from any device. Obviously there’s no travel required, so why not engage with more people and learn about new trends, features, and technologies?","title":"vForum Online Spring 2020"},{"content":"Just a quick post about the vExpert sub-programs that have been announced recently.\nIn my case, yesterday I received this message:\nThis means that I’ve been selected to be a vExpert PRO!\nBecoming a representative of your country/region and willingness to help others become aware of the vExpert program are the main functions of a vExpert PRO.\nSo, if you want to become a vExpert, start now and you can probably become one!\nI wrote a couple of months ago a post about it: Want to be a vExpert?\nIf you want to check your region vExpertPRO, just take a look at the official directory.\nSince yesterday I can say that I am part of the vExpert PRO program. Also congratulations to others like me that made it and the ones who continue!\nSee you soon!\n","permalink":"https://dangaiden.github.io/2020-04-08-vexpert-pro-announcement/","summary":"Just a quick post about the vExpert sub-programs that have been announced recently.\nIn my case, yesterday I received this message:\nThis means that I’ve been selected to be a vExpert PRO!\nBecoming a representative of your country/region and willingness to help others become aware of the vExpert program are the main functions of a vExpert PRO.\nSo, if you want to become a vExpert, start now and you can probably become one!","title":"vExpert PRO announcement"},{"content":"I was thinking these days what I wish I have known when I started working with Windows servers, some basic (and some not) commands that can help me to troubleshoot servers without requiring additional software.\nThat’s why this is a post dedicated to people who just started administering servers with Windows Server 20xx-2019 (I expect at least 2008 although it is going end of support the next month) or maybe you’re curious and want to know more about Windows Server administration.\nWe will exclude networking problems as that is another huge topic so, we assume that the server is reachable by using ping (ICMP protocol).\nRDP isn’t everything\nFirst thing I notice when someone tells me: «I can’t access the server via RDP, it must be overloaded, unresponsive, etc. because I can ping it».\nAs you may know (or not) RDP is the Remote Desktop protocol which usually runs in port 3389, there can be tons of reasons why you can’t access a server via RDP at the moment an alert raises (port blocked, server out of resources, user not allowed to RDP, etc.)\nTherefore, I will list some points about how to troubleshoot a server when you can’t access using RDP. In this way, you’ll be able to manage a server (Windows) without accessing it.\nMMC (Microsoft Management Console) MMC is everywhere, when you open the Event Viewer it is indeed an MMC that has the Snap-in «Event Viewer». Here is how would you do it manually instead of opening the Event Viewer «console»:\nYou should try to master the MMC as it provides you the best way to manage different aspects and features from a Windows server (remote or local).\nBy typing «mmc» in Run and pressing Enter», an empty console (MMC) will be open.\nAnd then, you can add a «snap-in» about any particular feature, service, etc. from Windows. Meaning that with the MMC you have at your disposal a tool to troubleshoot a remote or local server.\nJust go to File \u0026gt; Add/Remove snap-in and here choose what do you want! For this example, I will add the Certificates snap-in in order to check which certificates are installed in my server:\nOnce you press Add, it will ask you which account, usually you want to use the computer account because services and features related to the computer nor a user account.\nChoose if you want to manage a local or remote server:\nAnd finally, here is the final screenshot after adding the Certificates snap-in from my computer:\nNow, imagine if you do the same with the Services snap-in and select Another Computer, you will be able to manage the services from a remote computer by just doing that and without connecting to the server using RDP!\n\u0026gt;Check memory resources (RAM) CMD (command prompt)\nOur «old» friend CMD or command prompt interpreter which works on all versions of Windows Server, no matter which problem you have on your server that you can always run it and it is available on any Windows installation without any requirement.\nThere are some useful commands to manage a remote Windows server. The first command I want to show you is the «tasklist» command, which is the equivalent of the «Task Manager» that you probably know.\nIt can become very handy to check which processes are consuming more memory resources:\n[powershell]tasklist /s | sort /R /+58[/powershell]\nThe previous command is just for Memory usage (RAM) but it won’t work for CPU so, how can I check which process is consuming more CPU resources? Check the next section!\nCheck CPU resources (CPU) WMIC (Windows Management Interface Console)\nIn order to check the CPU remotely, there isn’t a simple command like «tasklist» with parameters as it is harder to get the stats from the CPU perspective.\nAnyway, this is another command that can be used within CMD, the command is wmic, here you have some examples:\nTo get the CPU usage of the server:\n[powershell] wmic cpu get loadpercentage [/powershell]\nOr the processes that are consuming a particular percentage (70% in this example):\n[powershell] wmic path win32_perfformatteddata_perfproc_process where (PercentProcessorTime ^\u0026gt; 70) get Name, Caption, PercentProcessorTime, IDProcess /format:list [/powershell]\nAs you can see in this output, it says «PercentProcessorTime=100», which means that a process (mcshield) consumed 100% of his time when we asked for the processes above 50% of the server.\nSo in this case, the process «mcshield» (which is related to McAfee) is consuming more than 50% of the CPU.\nObviously de «_Total» process mustn’t take into account and it’s in the output because I didn’t want to make it larger (although is a bit large).\nThere is another command (typeperf) which although it can be more powerful (it uses performance counters), the output is a mess (lots of data). I won’t show it here but I wanted to let you know.\n\u0026gt;Alternate access to RDP\nA server can be physical or virtual then, you can probably access the virtual machine using Hyper-V Manager (if you use Hyper-V) or the vSphere Web Client (vSphere) tools in order to gain access to the virtual server.\nIf the server is physical, you have probably access to some remote console (iLO, iDRAC, etc.) to access the server and finally be able to log if you need to.\nI hope these tips helped you or at least make you remember how to do it, see you next time.\n","permalink":"https://dangaiden.github.io/2020-02-29-troubleshooting-tips-for-beginners-in-windows-server/","summary":"I was thinking these days what I wish I have known when I started working with Windows servers, some basic (and some not) commands that can help me to troubleshoot servers without requiring additional software.\nThat’s why this is a post dedicated to people who just started administering servers with Windows Server 20xx-2019 (I expect at least 2008 although it is going end of support the next month) or maybe you’re curious and want to know more about Windows Server administration.","title":"Troubleshooting tips for beginners in Windows Server"},{"content":"Here I will explain a summary of days 1 and 2 (November 4th and 5th) of VMworld Europe 2019 from my perspective.\nSo, the first official day is on Monday (November 4th) where there aren’t many people like the next day (the second day, Tuesday 5th) but anyway there are many activities to do!\nThis time I was awarded a blogger pass, hence, I will have the honor to be with other bloggers at VMworld while enjoying some privileges like having a reserved seat in the general session, stay with other bloggers or join some special events.\nThe Community: vCommunity I think that for almost everyone that is involved in the vCommunity, VMworld means vCommunity but why?\nEasy, is the main event where you can meet again your friends, make new ones and have fun with them! By the way, vCommunity means virtual community and not VMware Community 😉\nThis year, I was able to help as a Champion for the Tech Level up Project which is the one who made The vTrail Map (A community guide for your virtualization journey)!\nIT'S HERE! IT'S READY \u0026#8211; Here's a sneak peak of the 2019 #vTrailMap cover. Please, find a copy (or 10) and get them into the hands of the people at #VMworld that are not yet connected to the #vCommunity and help them LEVEL UP! BIG Thanks to @Cohesity for sponsoring! pic.twitter.com/ZjwJWnLGyH \u0026mdash; Level Up Project 🍄 (@Tech_LevelUp) August 20, 2019 You can get the digital version here for free!\nMany people from the vCommunity as Champions delivered lots of physical copies of the vTrail Map at VMworld just to engage them in our community.\n1st general session Although there weren’t bigger announcements like at the VMworld US, there were some new projects and features that were announced.\nDay 1 (Now talking about November 5th) is more focused on announcements about new products, strategies and gives you a better vision of what VMware has to offer with new features, insights, etc.\nHere you have the link for the first session:\nDay 1 General Session (November 5th) vBrownbag Tech Talks On Day 1 there wasn’t much to do as we couldn’t record anything at the vBrownbag stage.\nGregg Robertson (vBrownbag member) likes to make fun of me a bit while I am performing tests on the stage:\nCome see @DanGaiden as part of the #vBrownbag crew tomorrow pic.twitter.com/bTJyiaQD01 \u0026mdash; Gregg Robertson (@GreggRobertson5) November 4, 2019 On Day 2 we started the vBrownbag Tech Talks at the VMware Community booth from 11:00 AM to 5:00 PM.\nAriel Sánchez, Alastair Cooke and me recorded around 15 sessions where many people from the vCommunity among other companies that showed us their community programs, new features, versions, etc.\nAlthough I was «anchored» at the VMware community booth recording people with the mixed audio and all of the vBrownbag members helping the presenters (and recording as well), it was so nice to spend time there with lots of new and old people from the community.\nAlso, I learned from each session that we recorded. If the topic is a bit interesting for me, it was great to hear about it and even ask the presenter.\nHere you have a picture of me while I was recording my friend Jorge de la Cruz!\nThe legend, the spanish rockstar @jorgedlcruz presenting at #VMTN tech talks!#VMworld #vBrownBag pic.twitter.com/zL7rSKGemy \u0026mdash; Dan Belmonte (@DanGaiden) November 5, 2019 Enjoying VMworld And here I share with you some events, moments and things that couldn’t be possible without the vCommunity.\nAll these moments are perfect to meet new people, engage with them and have fun!\nvFit Run In the early morning (6:45 AM) we did a run on the first day (November 4th) with some people from the community. It was so nice but at the same time painful to wake up at that time…\n1st #vFit run with these fantastic guys!\nToday, they are the real champions 👌🏼\nTag yourseves please!#vCommunity #VMworld pic.twitter.com/18hyw0M9Um \u0026mdash; Dan Belmonte (@DanGaiden) November 4, 2019 There was a second run scheduled for November 6th but I couldn’t attend so I assume that it wasn’t done.\nvSoccer So, a run for me in the morning and at night…soccer, no, vSoccer!\nJorge Torres organized a match between friends within the community and it was fantastic. We rent a field and after the match, we had a light dinner with some finger-food, omelets, etc. I absolutely recommend you to join the next one!\nNice turnout tonight for the first #vSoccer @VMworld Europe. pic.twitter.com/fr4dXEXb8s \u0026mdash; Jorge Torres (@J_Kolkes) November 4, 2019 vStreetfighter Well… this can happen at any hour… Gregg, Ariel and I love Street Fighter so, if you want to play with us at VMworld (or online) just let us know.\nWe have our own hashtag: #vStreetfighter\nWhen are we playing? #vStreetfighter #VMworld@arielsanchezmor @GreggRobertson5 pic.twitter.com/60o7MEX1BY \u0026mdash; Dan Belmonte (@DanGaiden) November 4, 2019 vBreakfast\nAnother amazing event from the vCommunity (organized by Fred Hofer). This is always done on the second day (November 5th) before the general session. There is a special place where we have a great breakfast and if there is a sponsor (Runecast) you will have it for free 🙂\nBut the main point here is, meet new people, talk with them and have a nice breakfast before going to the conference center!\nJust finished a great #vBreakfast with the #community folks, worth getting up early for! Thanks to @Fred_vBrain and @lessi001 for the organisation and to @sferk and the whole @Runecast team for sponsoring. Great conversation! pic.twitter.com/jAoQErxGF0 \u0026mdash; Dave Simpson (@bfd_diplomacy) November 5, 2019 And that would be all I wanted to share from the first 2 days, I will post the remaining ones in the same format.\nI hope you enjoy it!\n","permalink":"https://dangaiden.github.io/2020-01-31-post-vmworld-europe-2019-days-1-and-2/","summary":"Here I will explain a summary of days 1 and 2 (November 4th and 5th) of VMworld Europe 2019 from my perspective.\nSo, the first official day is on Monday (November 4th) where there aren’t many people like the next day (the second day, Tuesday 5th) but anyway there are many activities to do!\nThis time I was awarded a blogger pass, hence, I will have the honor to be with other bloggers at VMworld while enjoying some privileges like having a reserved seat in the general session, stay with other bloggers or join some special events.","title":"Post VMworld Europe 2019: Days 1 and 2"},{"content":"I haven’t thought of doing this kind of review but reading some of them through the internet, it motivated me to do it.\nAlso by submitting to programs like vExpert from VMware, made me realize that I did many things this year that I forgot and were amazing.\n2019 Timeline January: Going to the gym to get healthier knees and finished exams from the university with good scores. Semester ends.\nFebruary: New semester (about my degree) and many things planned.\nMarch: Earned a certification (MCSA 2016) and letting my self know more in the local VMUGs. I was awarded as a #vExpert for the first time!\nApril: Getting stronger and not feeling more pain in my knees after a long injury (previous year).\nJune: I took some university exams (all passed!) and then… time to enjoy the summer! July: Enjoying the time when there is no semester\nAugust: Lots of sport, going to restaurants and more.\nPlanning what to do in New York. September: I failed an exam which I knew I wasn’t prepared but I got married (eloped) in NY 🙂 October: #BlogtoberTech2019 = 5 blog posts! November: The event VMworld 2019 Europe. Tt was amazing to meet new people, older friends and interact with all of them. Also, I was able to record sessions with the vBrownbag crew.\nI also presented a session at VMworld! December: Nothing to say here, basically, preparing the next year. Success First, things I did and makes me happy that I achieved or earned:\nPersonal: Eloped in New York for just 2 months and 3 weeks ago! Commitment: Continue with my degree by passing all subjects with a good score. Networking: Meet better or new people which made me realize that there are good friends or someone you can chat from time to time. Better writing: Although this year I wrote only 16 posts (I know isn’t too much), I think I write better and I didn’t let quantity overcame the quality. Failure Obviously not all things went well:\nI wasn’t able to pass the VCAP6.5-DCV Design exam in October, you can check it here. For 4-6 weeks, I gained some weight because of time anxiety. I am procrastinating more than I used to (probably because of anxiety?). To work on Procrastination: I tend to procrastinate at home when I have to do university assignments. Also, other personal projects tend to be massively delayed. Organization: I do like to organize what I am going to do every week but maybe I have to put more fun windows and realize that sometimes you need to play games, do nothing and don’t be worried about you could do instead of seizing that time (time anxiety ?)! Writing, hosting, and more: More blog posts for the next year, host people to record sessions with vBrownbag, and presenting more.\nAnd that’s all! This will be the last post of the year (obviously) and although I was aiming to publish another different post that I am working on, I decided and wrote today this quick post in order to let you know that no one is perfect of course and there are bad and good news that people usually don’t talk about.\nSee you!\n","permalink":"https://dangaiden.github.io/2019-12-31-2019-review/","summary":"I haven’t thought of doing this kind of review but reading some of them through the internet, it motivated me to do it.\nAlso by submitting to programs like vExpert from VMware, made me realize that I did many things this year that I forgot and were amazing.\n2019 Timeline January: Going to the gym to get healthier knees and finished exams from the university with good scores. Semester ends.","title":"2019 review"},{"content":"vExpert 2020 applications are open!\nFrom November 25th to January 10th, you can apply to be a vExpert 2020 through many different paths and you must do it if you think you contributed to the VMware community.\nWhat is a vExpert? It’s an award that VMware gives to individuals who have contributed (a lot) to the VMware community.\nOnly the contributions over the past year are evaluated, therefore, it is a program that requires constant dedication every year by being an evangelist and advocacy of VMware products.\nvExpert is not a certification! It’s an award that is given to individuals and not companies so, companies must not claim that title. Why become one? vExperts who participate in the program have access to exclusive benefits. One of the challenges that you will see is, the journey to be and to maintain it. As I will explain later, being active in the community (through different ways) is the key to become one!\nAt VMworld there are some exclusive gifts, access and parties that are only accessible to vExperts but, interacting with the community will be always your best gift in my opinion.\nHere is a list of some of the benefits:\nJoin the private Slack channel (which is quite active!). Permission to use the vExpert certificate and logo on your website, social media, etc. Private forums on communities.vmware.com. Private webinars with VMware partners as well as NFRs. Evaluation licenses (1 year period) for many VMware products for your home lab! Blogger early access program for vSphere and some other products. Your profile will be listed in a public vExpert online directory. Access to vExpert parties and exclusive gifts at both VMworld events. Preferent seating at VMworld Keynotes. How-to Being a VMware vExpert is not a sprint and it doesn’t consist of making the greatest amount of blog-posts about VMware.\nTo become a VMware vExpert, you must be active in the community: This can be achieved by knowing and replying to people on Twitter, writing blog posts about VMware technologies, reply to the VMTN forums even if you don’t know the exact answer.\nAssisting or presenting to VMUG events is one of the best things you can do, not just to know people, promote yourself and learn new things also because you participate in the community and let yourself know.\nTo apply just do it here and list all the contributions from this year (2019).\nIf you still have doubts, you can reach your local vExpert PRO, which will help you with your submission. I can help you if you need some guidance or need any advice, just reach me on Twitter!\nOnce you apply, your submission will be evaluated and once the applications are closed, the vExpert 2020 will be awarded.\nSummary By being part of the community and involving yourself more in evangelizing VMware products through posts, VMUG events/UserCons, VMTN forums, etc. you will have a high chance of being a vExpert.\nRyu And Ken Approve GIF from Ryu GIFs Remember that in only will count the contributions from the previous year (2019 in this case) so, if you are not one know, don’t worry, apply if you think you contributed enough to the VMware community.\nYou didn’t contribute enough or nothing this year? Set yourself a goal and make it happen for the next year!\nFor me, being a vExpert gave me, not just licenses, gifts, etc. but many new friends of the community and a better knowledge of VMware products and culture.\n","permalink":"https://dangaiden.github.io/2019-12-09-being-a-vexpert/","summary":"vExpert 2020 applications are open!\nFrom November 25th to January 10th, you can apply to be a vExpert 2020 through many different paths and you must do it if you think you contributed to the VMware community.\nWhat is a vExpert? It’s an award that VMware gives to individuals who have contributed (a lot) to the VMware community.\nOnly the contributions over the past year are evaluated, therefore, it is a program that requires constant dedication every year by being an evangelist and advocacy of VMware products.","title":"Want to be a vExpert?"},{"content":" As the VCAP-DCV Design 2020 certification is going to be released (but the 3V0-624 exam is not scheduled to be retired yet) on Jan 1, 2020.\nRecently I made another post about my experience with this exam where I failed, check it here.\nFor your information, at the moment the 3V0-624 is the current exam code for the VCAP-DCV 6.5 Design certification (Also named VCAP-DCV Design 2019), always check the code for the exam no matter which is the certification name.\nI decided to share with you some notes for this kind of exams no matter which version. This information will be more helpful for people that have never taken this exam rather than those who are experienced in these advanced exams.\n\u0026gt;Audience The Design exams (VCAP-XXX Design) are mainly for IT Architects (sounds cool?) but, why for architects? Well, if you check the blueprint, you will see a couple of sections and not many objectives. The truth is hidden inside each section, which is huge and covers many aspects.\nCould you pass this exam without being an IT architect? Of course!\nMany did it (not in my case yet) by studying and having a lot of design experience, or also helped doing designs with other peers for example. Also, you can gain all the knowledge of all areas and study your main gaps.\nThe goal is to design VMware solutions to meet specific goals and requirements, ideally, you should have advanced knowledge of storage, network, compute, end-user computing environments and other components.\nYou will have to develop a conceptual design given a set of customer requirements, determining which requirements needed to create a logical design and after that creating a physical design with these items.\n\u0026gt;Technical background As you are aiming for a VMware certification, you must think in all solutions, features, and elements from vSphere.\nHere is a list of the solutions that appear in the Blueprint and are related to VMware of course:\nvSphere vSAN SRM vROps VVOLs vCenter Converter\nInside each solution, you should know at least the most of the features, functionalities that they offer, dependencies between them and test them (if you can).\nApart from knowing about these technologies related to VMware, there are obviously the core areas that compose a general IT infrastructure: Storage, networking and compute.\nSo, be prepared to dig on each area and know about dependencies between each other and with other solutions.\nAdvanced knowledge is desirable (and you will be tested) on each area would deserve more than post so, I am not going to explain anything right now about it 🙂\n\u0026gt;Aiming for the exam Your main guide must be the blueprint, no matter what other unofficial guides say (although they are very helpful). In the blueprint you will have all the sections and objectives that will be qualified.\nThis exam requires to read a lot (more if your daily job isn’t designing solutions) and not just books to gather information about how to gather requirements from the customer and match them to terminologies like RAMPS or RRAC (I will explain a bit of those later), also all the technical papers that the blueprint mention (+50).\nConceptual, Logical and Physical Design, you will see this a lot and once you understand it, you will see why.\nYou must check all the references (documents) that the blueprint mentions because most of them will appear in the exam.\nSome key points from all the features, elements or products I think will be:\nDependencies: Know the dependencies between solutions. What do you need to enable vSAN, apart from at least 1 SSD/Flash and 1 SAS/SATA disk? It also requires vCenter and DNS. Advantages and disadvantages: Does SRM perform replication? Is HA better to ensure availability than FT? Which solution can achieve a 5-minute RPO? vSAN Maximums and limitations: vSphere 6.5U1 supports a maximum of 4 PSCs per site, behind an LB. Also a maximum of 10 PSCs per vSphere Domain.\nUpgrade paths: How would you upgrade a vSphere 6.0 environment to 6.5 with external PSC?\nDetermine RCAR: Differentiate between requirements, constraints, assumptions, and risks. RAMPS: Build recoverability, availability, manageability, performance, and security into a vSphere Logical Design. Gather and analyze business and application requirements from customer interview data, determine customer priorities for defined objectives and categorize those requirements by infrastructure qualities.\nIn the post, I mentioned to you at the beginning there are some resources which are quite helpful in order to learn and improve your non-tech skills. Summary There is so much information to digest if you don’t have a certain level of knowledge in vSphere and the «art» of designing solutions, which could lead you to study a lot of products, methodologies, and features in probably, a great amount of time.\nBut don’t be impatient, it will take you time but, review each section and check the concepts, products or features that you’re not familiar with. Check videos and other unofficial guides that probably will make other fellows from the community.\nThis exam is about theory so, you will be tested as an architect who designs solutions based on customer or application requirements and how to match them to a VMware design.\nIt is difficult to generalize all the things that can appear in past, present, and future VCAP-DCV Design certifications but I tried to give you as much information as I can.\n","permalink":"https://dangaiden.github.io/2019-10-31-vcap-dcv-design-exam-notes/","summary":"As the VCAP-DCV Design 2020 certification is going to be released (but the 3V0-624 exam is not scheduled to be retired yet) on Jan 1, 2020.\nRecently I made another post about my experience with this exam where I failed, check it here.\nFor your information, at the moment the 3V0-624 is the current exam code for the VCAP-DCV 6.5 Design certification (Also named VCAP-DCV Design 2019), always check the code for the exam no matter which is the certification name.","title":"VCAP-DCV Design exam notes"},{"content":"Today, I’ll show you how easy is to install, configure Runecast Analyzer (v 3.1.1.0) in your environment and we will review quickly what can we offer this solution.\nRunecast? Runecast is a company founded in 2014 more recognizable because the CEO is Stanimir Markov which is VCDX #74 but in his team has other virtualization veterans who help them to create this solution.\nIt’s a solution made by and for IT Admins which will scan your VMware environment (vSphere, vSAN, and NSX-T and V) and inform you about issues, best practices, hardware compatibility and apply security hardening in your VMware environment.\nWith all of this information it will save a great amount of time to any IT admin in order to resolve or identify a known (or not) issue, perform an upgrade of any new release of vSphere, apply the correct configurations according any Security standards (PCI-DSS, HIPAA, DISA SITG, etc.) and more…\nThe main functionalities of this application are:\nProactive troubleshooting Security compliance Hardware compatibility Log analytics I will do another post showing and explaining in detail these features, meanwhile, you can check each one on their website.\nUse it in your environment or try it in a demonstration If you want to install and configure this virtual appliance to deploy in your environment, go to https://www.runecast.com/quick-and-secure-deployment and in the upper-right menu click the Free trial button.\nYou will need to create an account (it’s free) but once you created it, you will have access to the OVA file by downloading it:\nRunecast has also a Live Demo where you can try all the features without installing anything, just go to the website: https://demo.runecast.com and login with the credentials provided.\nYou will see immediately a test environment where you can check all the features that it has in just seconds, quite handy if you want to test this solution quickly.\nDeploy and configure Once you download the OVA file, deploy it in your virtual environment like what you will do with other virtual appliances:\nRight-click in your DC and «Deploy OVF Template…» Select the OVA file you downloaded in the previous section. Select name, folder, compute resource Accept the EULA, choose the deployment configuration (in my case Small) Configure the resources necessary for the appliance (storage, network and finally all the networking properties). Once the OVF package has been imported (it took 2 min approximately), it will appear a VM in your vCenter:\nNow, power on the VM and check in the VM console which is the IP that you give to the application in order to access the appliance (https://192.168.1.81):\nThe first time you access through the website, you must use the following credentials (the same as in the Live Demo):\nNow, it will ask you some information to connect to your vCenter, just enter the information (I created a new user to connect to the vCenter) and click Continue:\nAnd provide a schedule, I let the default setting as it’s a reasonable schedule. Continue by selecting «Start analysis»:\nThis, will scan your VMware environment and let you know in the dashboard all kind of issues, configuration, etc.:\nThe screenshot was taken from the Live Demo that Runecast provides Features Here I’ll show you some screenshots from the solution and how they look:\nSecurity Hardening It matches the security standard that you select to your environment and let you know which configuration you must apply in order to be compliant with that security standard.\nBest Practices Guides you about which Best Practices can be configured in your VMware environment against the VMware Best Practices.\nConfig KBs Discovered One of the most pro-active features is Config KBs Discovered, it lets you know which configurations you have currently applied in your environment and the KBs that are published in the VMware DB.\nHardware Compatibility This feature will help you to deal with any kind of upgrades in just seconds, do you know if your hardware is listed in the Hardware Compatibility List for some product? It will give you all the information in just a moment.\nLog Inspector Log inspector will look for patterns in your ESXi logs in real-time in order to analyze and provide a solution before anything happens. What a better way to apply a fix for something that you didn’t even notice?\nAnd that would be all for this quick post about Runecast Analyzer and how can it help in a VMware environment for vSphere, vSAN, and NSX.\nIf you thought that Runecast Analyzer is a single-use tool, you’re wrong, it has many features that make it easier to manage a VMware environment in a daily-basis.\nRemember that you can try it for 30-days with all the features or use the live demo on their website.\n","permalink":"https://dangaiden.github.io/2019-10-30-runecast-analyzer-deploy-configure-and-quick-review/","summary":"Today, I’ll show you how easy is to install, configure Runecast Analyzer (v 3.1.1.0) in your environment and we will review quickly what can we offer this solution.\nRunecast? Runecast is a company founded in 2014 more recognizable because the CEO is Stanimir Markov which is VCDX #74 but in his team has other virtualization veterans who help them to create this solution.\nIt’s a solution made by and for IT Admins which will scan your VMware environment (vSphere, vSAN, and NSX-T and V) and inform you about issues, best practices, hardware compatibility and apply security hardening in your VMware environment.","title":"Runecast Analyzer: Deploy, configure and quick review"},{"content":"Recently I took the 3V0-624 exam (a.k.a. VMware Certified Advanced Professional 6.5 – Data Center Virtualization Design Exam) and I failed (266/500).\nI took it on September, 4th (a month and a half ago) and as I was on holiday and now preparing things for VMworld Europe I won’t be able to study after the event.\nI recognize, I study a bit in a rush. In just one month for someone who is daily tasks aren’t about architecture, it can be hard (or not). In my case, this rush was influenced due to leaving on vacation for more than 2 weeks. Then, I decided to give it a try before leaving but, the outcome wasn’t what someone would like!\nLet me share my experience in the exam, some thoughts, resources, and notes that maybe can help you.\nKnow yourself What I want to say in this section is knowing your limitations and experience against the exam. I am not going to do a comparison against the blueprint right now but, check the blueprint and be honest to yourself.\nThis exam is called «Design» and that means having a broad knowledge on many areas (like networking, storage, computing, hardware, etc.), a different mindset than an engineer (the famous «holistic» view that architects have).\nSo, basically, check all the sections in the blueprint and match them against your knowledge. Are there too many gaps? Then, you probably need more experience and a lot of time to study (or both) but definitely, the experience becomes very handy for this exam.\n(I recommend you to check the blueprint from the VCAP6-DCV Design which is quite better than the 6.5 version (in fact, it has the resources split into sections instead of giving you a list of 50+ resources like in the 6.5 version).\nI am not an architect but I did some projects from the scratch (small ones) and participated in others that were normal (I don’t want to say big because it is subjective) as a technical reference so, I had some of the knowledge regarding how to approach a project\nExpect to gather the requirements, find «RRAC» (Requirements, Risks, Assumptions and Constraints) and also I had knowledge in DC architecture, vSphere (obviously) and other products from VMware (this is a VMware exam so don’t expect another thing!).\nStudy Resources There are many resources that you can find on the internet:\nvBrownbag VCAP6-DCD videos: https://www.youtube.com/playlist?list=PL2rC-8e38bUXAB-VaBem953POgFDrk-Iw Blog posts:\nhttps://thecloudxpert.net/2019/02/vcap6-5-dcv-design-exam-experience/ https://davidstamen.com/2017/12/21/vcap6.5-dcv-design-experience/ http://www.vhersey.com/2017/09/25/some-vcap-6-5-dcv-design-exam-study-notes/ https://www.paluszek.com/wp/2018/06/18/achievement-unlocked-vmware-vcap-6-5-dcv-3v0-624-exam-summary-and-tips/ https://vmninja.wordpress.com/2018/11/09/3v0-624-vcap-6-5-datacenter-virtualization-design-my-exam-experience/ https://www.jeffreykusters.nl/2018/05/22/passed-vcap65-dcv-design-finally-vcdx6/ \u0026lt;p style=\u0026quot;margin: 0in; font-family: Calibri; font-size: 11.0pt;\u0026quot;\u0026gt; \u0026lt;span style=\u0026quot;font-size: 16px;\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;https://www.jeffreykusters.nl/2017/08/02/preparing-vcap65-dcv-design/\u0026quot;\u0026gt;\u0026lt;span\u0026gt;https://www.jeffreykusters.nl/2017/08/02/preparing-vcap65-dcv-design/\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; The books I read:\nVCAP5-DCD guide IT Architect: Foundation in the Art of Infrastructure Design: A Practical Guide for IT Architects VMware vSphere Design 2nd Edition Obviously I reviewed all the technical papers from the blueprint and you should too (at least check if you understand the main concept).\nThe exam As the official webpage states, there are 60 questions and you have 135 minutes (2 hours and 15 minutes) to complete the exam. This is plenty of time for anyone I think.\nI read other experiences and almost anyone had a lot of time left in the clock before finishing the exam. When I took it, I reviewed the questions and there were almost 30 minutes.\nQuestions can be large so, maybe you want to read it a couple of times or even when you’re answering it.\nThe format of the exam is multiple-choice, matching and drag and drop. That means that all questions won\u0026#8217;t have a single choice solution. \u0026lt;p\u0026gt; \u0026lt;span style=\u0026quot;font-family: Nunito; font-size: 16px;\u0026quot;\u0026gt;Even I had time to finish the exam without looking at the clock too much, I failed with a score of 266 (passing score is 300 like many other VMware exams). That means that I need to review which were my weakest points, resolve my doubts and catch up with all I studied a couple of months ago.\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Notes\nAs far as I know, this exam goes until ESXi 6.5 U1 (which is the latest release before the blueprint came out).\nReview dependencies between all products and features within vSphere (especially the ones related to the RAMPS concept).\nThe conceptual, logical and physical design concepts must be mastered.\nReview limitations on each feature (HA, DRS, FT, etc.) or product (vSAN, SRM, etc.).\nThe vBrownbag videos and books like the «VCAP5-DCD guide» can be very helpful even though are «older». About books. the «vSphere Design 2nd edition» along with the «IT Architect series: Foundation in the art of infrastructure design» will give you a general vision of all concepts that an architect must know.\nCheck the blueprint from the VCAP6-DCV Design as the objectives are the same as the 6.5 version but better explained and with references on each section.\nSo, that’s all I wanted to say and I hope that even I didn’t pass in this first attempt, it can help other people willing to take it in the future.\nSometimes you have to fail better before succeed.\n","permalink":"https://dangaiden.github.io/2019-10-25-vcap6-5-dcv-design-failed-exam-experience/","summary":"Recently I took the 3V0-624 exam (a.k.a. VMware Certified Advanced Professional 6.5 – Data Center Virtualization Design Exam) and I failed (266/500).\nI took it on September, 4th (a month and a half ago) and as I was on holiday and now preparing things for VMworld Europe I won’t be able to study after the event.\nI recognize, I study a bit in a rush. In just one month for someone who is daily tasks aren’t about architecture, it can be hard (or not).","title":"VCAP6.5-DCV Design failed exam experience"},{"content":"VMworld 2019 Europe is almost here! And I made a local guide with tips about transport, restaurants, places to go, etc. to ensure you can enjoy more your experience in VMworld.\nGeneral information This event will take place from the 4th (Monday) to 7th (Thursday) of November at Fira Gran Via in Barcelona, Spain.\nVMworld is always an amazing opportunity to learn from all the events that will happen there like the Hands-on Lab, Breakout sessions, General sessions, etc.\nAlso, it is a great way to connect with a lot of people from the community, vendors or other persons that you are interested in.\nPeople are really friendly so, don’t be shy (you can try first on Twitter!) and try to speak to members from the vCommunity. Besides, be sure to meet the vBrownbag team in the VMTN Tech talks area 🙂\nIf you are interested in attending this amazing international event and enjoy many other advantages, you can register here.\nSome notes In Spain, tipping is entirely optional and it’s not very common so, it’s up to you if you want to leave a tip in case the service was exceptional or you think it deserves it. In restaurants, shops, etc. the VAT tax is included. Therefore, you don’t have to worry to calculate an extra amount of money. Also, once you pay with credit card (VISA branded cards are the most used here) they will make you enter the PIN code of your credit card (a bit different than the US).\nI know it’s late but, hotels near Fira are nice and a bit expensive. The best zone I think it is near Sants where there are cheaper hotels, nice transport connections, and great ambient.\nThe official language in Barcelona is Spanish but most of the population speak in Catalan. Saying that, don’t worry if you don’t understand some signboards from the street or public places.\nTransportation There are 3 different train services: Renfe (Local Train), TMB (metro/subway/underground) and FGC (Regional Train).\nRenfe and TMB are the most used because they have more combinations than the FGC and also better schedules. So, basically, you will see in this guide mentioning train for Renfe and metro/subway/underground for TMB.\nComing from the airport Once you land at El Prat airport, there are a few ways to go to the city of Barcelona:\nYou can take a taxi (expensive but more convenient for people with less time or when the hotel is located in an isolated area). It will costs between 20-30 € from the Airport to Sants (always depending on the traffic). Put the hand luggage on the taxi trunk costs an additional euro.\nYou can use the app myTaxi to order one. Uber and Cabifiy are not available in Barcelona.\nBy train (Renfe):\nYou can go to the Aeroport (airport) stop of the R2 Nord line (you must go to Terminal 2 to take the train). This line will take you to Sants-Estacio and will be great for people staying near Sants. This line is less frequent than the next option but it takes less time. Pricing is subjected to zones. In that case, From Aeroport to Sants-Estacio the price for a single ticket will be 4.20 €. By metro (TMB): Use the L9 Sud line, this is the Metro (subway/underground) service and can be combined with other lines (like L5 at Collblanc stop for example) within the same ticket. This metro service is more frequent than the train service and it costs 4.60 €. This can be the best option for most people because you can use the same single ticket to go to other places by combining lines. By bus (Aerobus): The least recommended option as it will be crowded but it depends on your preferences and where do you want to go. The Aerobus will take you to «Plaça Catalunya» (Catalunya Plaza) but it costs a bit more than other services (5,90 € at the moment), you can review more information in this link. T-10 card\nIf you plan to visit Barcelona, consider buying a T-10 ticket (which includes 10 single tickets or 10 journeys) as it will save you half the price of many single tickets. This T-10 card can be used for many people as you want so, consider it if you are a group.\nT-10 cards are sold by zones (because they have other public services integrated), as you are going to stay in Barcelona, you only need 1 zone. Price for a T-10 1 Zone card is 10.20€, versus buying 10 single tickets (1 zone) will cost 2.20 € x 10 = 22€.\nT-10 tickets can be used on any public transport (bus, Metro, Renfe and FGC services) with some exceptions covered here:\nYou cannot use the T-10 ticket from the airport on the Metro Line L9 Sud. This means the T10 ticket is not valid at the stops Aeroport T1 or Aeroport T2 on the airport metro link. The T10 ticket is also not valid on the Aerobus express bus. Moving inside of Barcelona The Metro (subway/underground) is your best choice whatever you stay in Barcelona if you want a cheaper, frequent and reliable service.\nWith the metro (remember the name) you can travel through lines at the same cost. The main stops to consider will be Fira in L9 Sud, Plaça Espanya in L1/L3 and Sants-Estacio in L5/L3\u0026gt;.\nThe fastest way to VMworld? \u0026gt;The closest stop to the VMworld event is Fira in L9 Sud or the Europa-Fira stop which is another stop from the L9-Sud line that also combines with another train service (FGC trains) which is a different transport service than the metro and it has different stops.\n\u0026gt; If you stay near Sants, the Sants-Estacio stop in L5 will be your choice. Then, in Sants-Estacio station take the L5 to Collblanc stop and after that, change the line to L9 Sud until you arrive at Fira stop.\nYou can see in the following map the VMworld precinct highlighted in yellow and the closest stops (marked in blue): Europa-Fira stop which combines FGC and Metro services and, Fira stop at L9 Sud.\nLast year VMworld provided a free metro card; As I don’t know if it will be the same but if you are aiming to visit Barcelona and visit other places, consider to buy a T-10 travel card (10 single rides) which is multi personal and quite cheaper than buying 10 single tickets.\nEvents around VMworld\nFred Hofer has a magnificent post where it summarizes all the events and parties that will happen on these dates, check it here I organized the vFit runs, review my post for more detailed information\nIn my case besides the vFit event (Monday and Wednesday morning), I will attend the vSoccer event on Monday night and vBreakfast on Tuesday.\nOutside VMworld (Sightseeing)\nHere is a summary of the places that you could visit if you come to Barcelona:\n\u0026lt;p\u0026gt; \u0026lt;span \u0026gt;\u0026lt;strong\u0026gt;La Sagrada Familia\u0026lt;/strong\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;\u0026lt;span\u0026gt;Probably the most iconic building \u0026lt;/span\u0026gt;in\u0026lt;span\u0026gt; Barcelona. It is an unfinished church designed by \u0026lt;a href=\u0026quot;https://en.wikipedia.org/wiki/Antoni_Gaud%C3%AD\u0026quot;\u0026gt;Gaudí\u0026lt;/a\u0026gt;, an architect who made many iconic buildings here in Barcelona.\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;Location: \u0026lt;a href=\u0026quot;https://cutt.ly/5eoPoBU\u0026quot;\u0026gt;https://cutt.ly/5eoPoBU\u0026lt;/a\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr style=\u0026quot;height: 30px;\u0026quot;\u0026gt; \u0026lt;td style=\u0026quot;width: 100%; height: 30px;\u0026quot;\u0026gt; \u0026lt;img loading=\u0026quot;lazy\u0026quot; class=\u0026quot;alignnone size-medium_large wp-image-1157\u0026quot; src=\u0026quot;/wp-content/uploads/2019/10/Ramblas-de-Barcelona-768x509.jpg\u0026quot; alt=\u0026quot;\u0026quot; width=\u0026quot;656\u0026quot; height=\u0026quot;435\u0026quot; srcset=\u0026quot;/wp-content/uploads/2019/10/Ramblas-de-Barcelona-768x509.jpg 768w, /wp-content/uploads/2019/10/Ramblas-de-Barcelona-300x199.jpg 300w, /wp-content/uploads/2019/10/Ramblas-de-Barcelona-1024x679.jpg 1024w, /wp-content/uploads/2019/10/Ramblas-de-Barcelona.jpg 1500w\u0026quot; sizes=\u0026quot;(max-width: 656px) 100vw, 656px\u0026quot; /\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;strong\u0026gt;\u0026lt;span \u0026gt;Las Ramblas\u0026lt;/span\u0026gt;\u0026lt;/strong\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;The most famous pedestrian street of Barcelona, you will see many kiosks and artists there while walking in the middle of the city. \u0026lt;strong\u0026gt;Note\u0026lt;/strong\u0026gt;: Keep an eye on your belongings if you are watching an exhibition as pickpockets could be near you.\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;Location: \u0026lt;/span\u0026gt;\u0026lt;a href=\u0026quot;https://bit.ly/35zkqXQ\u0026quot;\u0026gt;\u0026lt;span \u0026gt;https://bit.ly/35zkqXQ\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr style=\u0026quot;height: 30px;\u0026quot;\u0026gt; \u0026lt;td style=\u0026quot;width: 100%; height: 30px;\u0026quot;\u0026gt; \u0026lt;img loading=\u0026quot;lazy\u0026quot; class=\u0026quot;alignnone size-medium_large wp-image-1165\u0026quot; src=\u0026quot;/wp-content/uploads/2019/10/FontMontjuic-768x384.jpg\u0026quot; alt=\u0026quot;font-montjuic\u0026quot; width=\u0026quot;656\u0026quot; height=\u0026quot;328\u0026quot; srcset=\u0026quot;/wp-content/uploads/2019/10/FontMontjuic-768x384.jpg 768w, /wp-content/uploads/2019/10/FontMontjuic-300x150.jpg 300w, /wp-content/uploads/2019/10/FontMontjuic-1024x512.jpg 1024w, /wp-content/uploads/2019/10/FontMontjuic-1536x768.jpg 1536w, /wp-content/uploads/2019/10/FontMontjuic-2048x1024.jpg 2048w, /wp-content/uploads/2019/10/FontMontjuic-1568x784.jpg 1568w\u0026quot; sizes=\u0026quot;(max-width: 656px) 100vw, 656px\u0026quot; /\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p class=\u0026quot;LC20lb\u0026quot;\u0026gt; \u0026lt;strong\u0026gt;\u0026lt;span \u0026gt;La Font Màgica de Montjuïc (Magic fountain of Montjuïc)\u0026lt;/span\u0026gt;\u0026lt;/strong\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;This fountain is amazing at night. You should check the exhibitions scheduled with lights and streams creating shapes. It is located \u0026lt;strong\u0026gt;near the Veeam party\u0026lt;/strong\u0026gt; that will be on Tuesday so, maybe you can go earlier and check it out!\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;Location: \u0026lt;/span\u0026gt;\u0026lt;a href=\u0026quot;https://bit.ly/2VBo9zc\u0026quot;\u0026gt;\u0026lt;span \u0026gt;https://bit.ly/2VBo9zc\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr style=\u0026quot;height: 30px;\u0026quot;\u0026gt; \u0026lt;td style=\u0026quot;width: 100%; height: 30px;\u0026quot;\u0026gt; \u0026lt;img loading=\u0026quot;lazy\u0026quot; class=\u0026quot;alignnone size-medium_large wp-image-1156\u0026quot; src=\u0026quot;/wp-content/uploads/2019/10/Park-guell-768x418.jpg\u0026quot; alt=\u0026quot;Park-guell\u0026quot; width=\u0026quot;656\u0026quot; height=\u0026quot;357\u0026quot; srcset=\u0026quot;/wp-content/uploads/2019/10/Park-guell-768x418.jpg 768w, /wp-content/uploads/2019/10/Park-guell-300x163.jpg 300w, /wp-content/uploads/2019/10/Park-guell-1024x557.jpg 1024w, /wp-content/uploads/2019/10/Park-guell-1536x835.jpg 1536w, /wp-content/uploads/2019/10/Park-guell-1568x853.jpg 1568w, /wp-content/uploads/2019/10/Park-guell.jpg 1920w\u0026quot; sizes=\u0026quot;(max-width: 656px) 100vw, 656px\u0026quot; /\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;\u0026lt;strong\u0026gt;Park Güell\u0026lt;/strong\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;A gorgeous park with some designs from Gaudí and other architects that are interesting. You must buy a ticket in order to gain entrance to the Monumental Area (where you can see some monuments from Gaudí).\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;Location: \u0026lt;/span\u0026gt;\u0026lt;a href=\u0026quot;https://bit.ly/319oIS3\u0026quot;\u0026gt;\u0026lt;span \u0026gt;https://bit.ly/319oIS3\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr style=\u0026quot;height: 30px;\u0026quot;\u0026gt; \u0026lt;td style=\u0026quot;width: 100%; height: 30px;\u0026quot;\u0026gt; \u0026lt;img loading=\u0026quot;lazy\u0026quot; class=\u0026quot;alignnone wp-image-1162\u0026quot; src=\u0026quot;/wp-content/uploads/2019/10/casa-batllo-768x946.jpg\u0026quot; alt=\u0026quot;casa-batllo\u0026quot; width=\u0026quot;565\u0026quot; height=\u0026quot;696\u0026quot; srcset=\u0026quot;/wp-content/uploads/2019/10/casa-batllo-768x946.jpg 768w, /wp-content/uploads/2019/10/casa-batllo-243x300.jpg 243w, /wp-content/uploads/2019/10/casa-batllo-831x1024.jpg 831w, /wp-content/uploads/2019/10/casa-batllo-1247x1536.jpg 1247w, /wp-content/uploads/2019/10/casa-batllo-1662x2048.jpg 1662w, /wp-content/uploads/2019/10/casa-batllo-1568x1932.jpg 1568w\u0026quot; sizes=\u0026quot;(max-width: 565px) 100vw, 565px\u0026quot; /\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;strong\u0026gt;\u0026lt;span \u0026gt;Casa Batlló\u0026lt;/span\u0026gt;\u0026lt;/strong\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;A famous building designed by Gaudí also named «House of bones». Look at the facade which is something that you probably never seen before with the sculpted stonework, the windows or the painting. It is also a museum where you can visit (you need to buy a ticket) the inside of this building.\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;Location: \u0026lt;/span\u0026gt;\u0026lt;a href=\u0026quot;https://cutt.ly/ieoPssI\u0026quot;\u0026gt;\u0026lt;span \u0026gt;https://cutt.ly/ieoPssI\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr style=\u0026quot;height: 30px;\u0026quot;\u0026gt; \u0026lt;td style=\u0026quot;width: 100%; height: 30px;\u0026quot;\u0026gt; \u0026lt;img loading=\u0026quot;lazy\u0026quot; class=\u0026quot;alignnone size-medium_large wp-image-1161\u0026quot; src=\u0026quot;/wp-content/uploads/2019/10/la-pedrera-768x512.jpeg\u0026quot; alt=\u0026quot;la-pedrera\u0026quot; width=\u0026quot;656\u0026quot; height=\u0026quot;437\u0026quot; srcset=\u0026quot;/wp-content/uploads/2019/10/la-pedrera-768x512.jpeg 768w, /wp-content/uploads/2019/10/la-pedrera-300x200.jpeg 300w, /wp-content/uploads/2019/10/la-pedrera-1024x683.jpeg 1024w, /wp-content/uploads/2019/10/la-pedrera-1536x1024.jpeg 1536w, /wp-content/uploads/2019/10/la-pedrera-1568x1045.jpeg 1568w, /wp-content/uploads/2019/10/la-pedrera.jpeg 1920w\u0026quot; sizes=\u0026quot;(max-width: 656px) 100vw, 656px\u0026quot; /\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;\u0026lt;strong\u0026gt;Casa Milà \u0026amp;#8211; La Pedrera (The stone quarry)\u0026lt;/strong\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;Another famous building designed by Gaudí. It has unique balconies and a courtyard that defines the style of Gaudí and also his last private residence.\u0026lt;br /\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;Location: \u0026lt;a href=\u0026quot;https://cutt.ly/reoPjYM\u0026quot;\u0026gt;https://cutt.ly/reoPjYM\u0026lt;/a\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;tr style=\u0026quot;height: 30px;\u0026quot;\u0026gt; \u0026lt;td style=\u0026quot;width: 100%; height: 30px;\u0026quot;\u0026gt; \u0026lt;img loading=\u0026quot;lazy\u0026quot; class=\u0026quot;alignnone size-medium_large wp-image-1160\u0026quot; src=\u0026quot;/wp-content/uploads/2019/10/port-olimpic-768x512.jpg\u0026quot; alt=\u0026quot;port-olimpic\u0026quot; width=\u0026quot;656\u0026quot; height=\u0026quot;437\u0026quot; srcset=\u0026quot;/wp-content/uploads/2019/10/port-olimpic-768x512.jpg 768w, /wp-content/uploads/2019/10/port-olimpic-300x200.jpg 300w, /wp-content/uploads/2019/10/port-olimpic-1024x683.jpg 1024w, /wp-content/uploads/2019/10/port-olimpic.jpg 1200w\u0026quot; sizes=\u0026quot;(max-width: 656px) 100vw, 656px\u0026quot; /\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;\u0026lt;strong\u0026gt;The Olympic port of Barcelona (since recent events in the past months, I will avoid going at night)\u0026lt;/strong\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;\u0026lt;span\u0026gt;It is one of the most exciting leisure and touristic spots throughout Barcelona, with a wide offering of shops, clubs, \u0026lt;/span\u0026gt;and\u0026lt;span\u0026gt; restaurants. It\u0026amp;#8217;s the gateway to the Barcelona beaches and also there is the Barcelona zoo near to it.\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;Location: \u0026lt;/span\u0026gt;\u0026lt;a href=\u0026quot;https://cutt.ly/seoPx1J\u0026quot;\u0026gt;\u0026lt;span \u0026gt;https://cutt.ly/seoPx1J\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;In general, avoid going alone in the night, especially in «Las Ramblas», «El Raval» or near «Olympic Port of Barcelona».\u0026lt;br /\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;Also\u0026lt;span\u0026gt;, avoid the neighborhood known as «La Mina» which is farther from Barcelona but it still accessible by Metro.\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;h2\u0026gt; \u0026lt;span style=\u0026quot;\u0026quot;\u0026gt;Restaurants\u0026lt;/span\u0026gt; \u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;The food in Barcelona is nice and some of you probably know it.\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;Let me suggest a couple of \u0026lt;strong\u0026gt;restaurants near Fira Gran Via (VMworld)\u0026lt;/strong\u0026gt;:\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt; \u0026lt;span \u0026gt;\u0026lt;a href=\u0026quot;https://bit.ly/35tkurS\u0026quot;\u0026gt;Gran Varela\u0026lt;/a\u0026gt;: A restaurant with great food (especially octopus). Also, the wines are great!\u0026lt;/span\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;span \u0026gt;In Gran Via 2 (a shopping center pretty close to Fira Gran via) I can suggest you:\u0026lt;/span\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt; \u0026lt;span \u0026gt;A great Japanese (\u0026lt;strong\u0026gt;Udon\u0026lt;/strong\u0026gt;)\u0026lt;/span\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;span \u0026gt;A good Italian (\u0026lt;strong\u0026gt;La Tagliatella\u0026lt;/strong\u0026gt;) \u0026lt;/span\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;span \u0026gt;Beers and tapas (\u0026lt;strong\u0026gt;Cañas y tapa\u0026lt;/strong\u0026gt;)\u0026lt;/span\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;span \u0026gt;\u0026lt;a href=\u0026quot;https://cutt.ly/dep2q9r\u0026quot;\u0026gt;Restaurant La Vid\u0026lt;/a\u0026gt;: A nice restaurant where you can try local food like the bread with spread tomato, the Spanish omelet, or the ham! \u0026lt;/span\u0026gt;\u0026lt;span \u0026gt;This is also the restaurant that will be hosting the vBreakfast event on Tuesday morning.\u0026lt;/span\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;p\u0026gt; \u0026amp;nbsp; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;The best places \u0026lt;strong\u0026gt;aren\u0026amp;#8217;t near Fira Gran Via\u0026lt;/strong\u0026gt; but if you want to try better food, here are a couple of restaurants that are really nice:\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li style=\u0026quot;list-style-type: none;\u0026quot;\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt; \u0026lt;span \u0026gt;\u0026lt;a href=\u0026quot;https://www.bacoaburger.com/en/\u0026quot;\u0026gt;Bacoa Burger\u0026lt;/a\u0026gt;: Amazing and customized burgers, also hand-made fries and sauces.\u0026lt;/span\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;span \u0026gt;\u0026lt;a href=\u0026quot;https://www.konig.cat/en/\u0026quot;\u0026gt;König\u0026lt;/a\u0026gt;: Amazing restaurant where you can try almost everything: tapas, amazing beer, flatbread, and many other options!\u0026lt;/span\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;span \u0026gt;\u0026lt;a href=\u0026quot;http://www.bellanapoli.es/en/\u0026quot;\u0026gt;La Bella Napoli\u0026lt;/a\u0026gt;: Not many choices on the menu in this Italian restaurant but the food quality is amazing.\u0026lt;/span\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;span \u0026gt;\u0026lt;a href=\u0026quot;http://bairesbcn.com/\u0026quot;\u0026gt;Buenos Aires Grill Restaurant\u0026lt;/a\u0026gt;: Steak, ribs, Argentinian Beef, special cuts?\u0026lt;br /\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;span \u0026gt;\u0026lt;a href=\u0026quot;https://www.facebook.com/RamenYaHiro\u0026quot;\u0026gt;Ramen-Ya Hiro\u0026lt;/a\u0026gt;: Best ramen in Barcelona without a doubt! The queue won\u0026amp;#8217;t be short to get the Ramen\u0026amp;#8230;\u0026lt;/span\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;h4\u0026gt; \u0026lt;span\u0026gt;Local food\u0026lt;/span\u0026gt; \u0026lt;/h4\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;Let me put a short section about local food here. The food you must try while staying here would be: \u0026lt;/span\u0026gt;\u0026lt;strong\u0026gt;\u0026lt;span \u0026gt;Paella, Spanish omelet, \u0026lt;/span\u0026gt;\u0026lt;span \u0026gt;Bread with (spread) tomato and of course \u0026lt;/span\u0026gt;\u0026lt;/strong\u0026gt;\u0026lt;span \u0026gt;\u0026lt;strong\u0026gt;Ham (Jamón)\u0026lt;/strong\u0026gt;!\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;Despite there many restaurants that they prepare all these dishes, I will avoid the ones in Las Ramblas because they\u0026amp;#8217;re usually not the best option\u0026amp;#8230;\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;\u0026lt;strong\u0026gt;Bread with (spread) tomato\u0026lt;/strong\u0026gt; can be found in almost any bar or restaurant so, just ask for it. They are also served at breakfast!\u0026lt;/span\u0026gt;\u0026lt;img loading=\u0026quot;lazy\u0026quot; class=\u0026quot;alignnone wp-image-1236 \u0026quot; src=\u0026quot;/wp-content/uploads/2019/10/pa_amb_tomaquet2.jpg\u0026quot; alt=\u0026quot;pa_amb_tomaquet\u0026quot; width=\u0026quot;558\u0026quot; height=\u0026quot;318\u0026quot; srcset=\u0026quot;/wp-content/uploads/2019/10/pa_amb_tomaquet2.jpg 700w, /wp-content/uploads/2019/10/pa_amb_tomaquet2-300x171.jpg 300w\u0026quot; sizes=\u0026quot;(max-width: 558px) 100vw, 558px\u0026quot; /\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026amp;nbsp; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;If you don\u0026amp;#8217;t want to lose a lot of time by going far from VMworld to taste many of these dishes, I would suggest you go \u0026lt;a href=\u0026quot;https://cutt.ly/dep2q9r\u0026quot;\u0026gt;Restaurant La Vid\u0026lt;/a\u0026gt;, which I talked in the previous section.\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026amp;nbsp; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;Also, on these dates, it is common for street vendors to sell \u0026lt;strong\u0026gt;hot toasted chestnuts\u0026lt;/strong\u0026gt; wrapped in newspaper, give it a try!\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;img loading=\u0026quot;lazy\u0026quot; class=\u0026quot;alignnone wp-image-1232\u0026quot; src=\u0026quot;/wp-content/uploads/2019/10/Chestnuts.jpg\u0026quot; alt=\u0026quot;chestnuts\u0026quot; width=\u0026quot;549\u0026quot; height=\u0026quot;305\u0026quot; srcset=\u0026quot;/wp-content/uploads/2019/10/Chestnuts.jpg 630w, /wp-content/uploads/2019/10/Chestnuts-300x167.jpg 300w\u0026quot; sizes=\u0026quot;(max-width: 549px) 100vw, 549px\u0026quot; /\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;Finally, you should try a sweety called «\u0026lt;strong\u0026gt;panellets\u0026lt;/strong\u0026gt;» (special almond balls covered in pine nuts), you can find them in bakeries:\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;img loading=\u0026quot;lazy\u0026quot; class=\u0026quot;alignnone wp-image-1237\u0026quot; src=\u0026quot;/wp-content/uploads/2019/10/panellets-1024x644.png\u0026quot; alt=\u0026quot;panellets\u0026quot; width=\u0026quot;554\u0026quot; height=\u0026quot;349\u0026quot; srcset=\u0026quot;/wp-content/uploads/2019/10/panellets-1024x644.png 1024w, /wp-content/uploads/2019/10/panellets-300x189.png 300w, /wp-content/uploads/2019/10/panellets-768x483.png 768w, /wp-content/uploads/2019/10/panellets.png 1200w\u0026quot; sizes=\u0026quot;(max-width: 554px) 100vw, 554px\u0026quot; /\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026amp;nbsp; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;There are many other places and foods not included here. If you want something specific just let me know in the comments or via DM on \u0026lt;a href=\u0026quot;https://twitter.com/DanGaiden\u0026quot;\u0026gt;Twitter\u0026lt;/a\u0026gt;.\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;h2\u0026gt; \u0026lt;span style=\u0026quot;\u0026quot;\u0026gt;Conclusion\u0026lt;/span\u0026gt; \u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;That will be a summary of things to do at VMworld and in the city of Barcelona.\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;Be sure to enjoy VMworld with all the events, parties, people and more things that can give you but overall, have fun!\u0026lt;br /\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;If you think that something is missing, let me know.\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026lt;span \u0026gt;See you at \u0026lt;span style=\u0026quot;text-decoration: underline;\u0026quot;\u0026gt;\u0026lt;strong\u0026gt;VMworld\u0026lt;/strong\u0026gt;\u0026lt;/span\u0026gt;!\u0026lt;/span\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026amp;nbsp; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026amp;nbsp; \u0026lt;/p\u0026gt; \u0026lt;p\u0026gt; \u0026amp;nbsp; \u0026lt;/p\u0026gt; ","permalink":"https://dangaiden.github.io/2019-10-14-vmworld-2019-europe-local-guide/","summary":"VMworld 2019 Europe is almost here! And I made a local guide with tips about transport, restaurants, places to go, etc. to ensure you can enjoy more your experience in VMworld.\nGeneral information This event will take place from the 4th (Monday) to 7th (Thursday) of November at Fira Gran Via in Barcelona, Spain.\nVMworld is always an amazing opportunity to learn from all the events that will happen there like the Hands-on Lab, Breakout sessions, General sessions, etc.","title":"VMworld 2019 Europe local guide"},{"content":"Yes! I am happy to announce that the vFit event will happen also at VMworld Europe this year!\nEric Wright (@discoposse) is the creator of this event and you can check how it went at VMworld US here! I love his idea of engaging folks who attend tech events to do some exercise at tech events and why not at VMworld Europe? Enjoy a run with our great community outside VMworld. You can meet people, share a great moment to run outside the event centers and enjoy the city of Barcelona.\nSo, this year in Barcelona I will be the organizer for the #vFit event and I hope you can join me and other community folks in the 2019 #vFit runs at VMworld Europe. Basic information Anyone can join this event to run with a group of community folks at approximately 6.21min per km / 10min per mile. May be a second group if enough walkers join, we will discuss it once when we meet there.\nThe meet up for the runs will be at the exit of Europa-Fira station: https://bit.ly/354kRsN\nThere are two exits at Europa-Fira (showed in blue), you must go to the one which has 3 «big» buildings. Our meet-up will be at the red circle that you can see in the following map: Here you have a Google Street View just in case you’re not sure if you picked the correct exit: https://bit.ly/30N3o4x\nSo, as said we will have the meet up at the red circle that is in front of one of the Europa-Fira exits.\nSchedules Usually, this is a daily run event but, as I am the one organizing it, I can’t commit to doing a daily run because I have other duties to do at VMworld.\nTherefore I decided to do 2 runs and the time of each meet up is:\nMonday, November 4 \u0026#8211; 06:45 AM CEST Wednesday, November 6 \u0026#8211; 06:45 AM CEST On Wednesday many people will be crashed by Tuesday parties however I will be there anyway!\nWhy not Tuesday? I’ll be heading to the vBreakfast event on Tuesday and also on Monday night there is the vSoccer event so, some rest is needed 🙂\nThen, on Tuesday you can rest or even go for a run yourself.\nRoute The route goes from Europa-Fira station (where we meet up) to Montjuic (uphill) and then coming back from the other side (downhill) to end at the Europa Fira station.\nThe route is about 5.5 km / 3.41 miles and we will see some streets from «La Marina» district (where VMworld is hosted) and the Montjuïc Park.\nHere you have the route if you want to check it out:\nRoute map for VFit Running EMEA 2019 by Dan Belmonte on plotaroute.com How do I join? Just to know how many people are going to attend, register here on any date: https://www.eventbrite.com/e/vfit-emea-2019-tickets-74746226977 But the main point is to be there at the time specified in the schedules section.\nUse the #vFit to share it with the community!\nIf you need more information, just send me a DM on Twitter or comment on this post and I’ll be glad to help you.\nSee you there!\n","permalink":"https://dangaiden.github.io/2019-10-04-vfit-at-vmworld-2019-europe/","summary":"Yes! I am happy to announce that the vFit event will happen also at VMworld Europe this year!\nEric Wright (@discoposse) is the creator of this event and you can check how it went at VMworld US here! I love his idea of engaging folks who attend tech events to do some exercise at tech events and why not at VMworld Europe? Enjoy a run with our great community outside VMworld.","title":"vFit at VMworld 2019 Europe"},{"content":"I was wondering why I haven’t talked about Veeam when I use it almost every day in my job, not only administering backups but doing new implementations.\nRecently, I had to implement a design where I need to backup VMs in remote sites but not back up them in a centralized storage, they will be backed up on each remote site storage.\nSo, by deploying a VM with the Backup proxy service and also use it as the backup repository we can accomplish the goal. We will save bandwidth and increase the speed to restore and backup those remote virtual machines by using the local storage on each remote site.\nScenario The scenario I am talking is the following, a dedicated VM with Windows Server 2016 Standard (a.k.a. W2016 STD) to act as a backup proxy and backup repository and Veeam B\u0026amp;R installed on the main site (the cloud we will say).\nThis is the high level design:\nSo, we are going to back up all the VMs that are hosted in the remote ESXi hosts and also save the backup data in the local storage.\nAs said before, in this way we save bandwidth and gain speed in the backup and restore process in case we need to perform any of it.\nWe will assume that we have a vCenter deployed with Veeam B\u0026amp;R installed. The Veeam B\u0026amp;R has configured the vCenter and then all remote ESXi hosts.\nImplementation The implementation is pretty straightforward, we will have a dedicated VM to be deployed on each remote site and then perform the following high-level steps:\n– As a backup repository, we are going to add a hard disk to the remote VM and use that hard disk as the backup repository for the site. We will seize the capabilities of Windows Server 2016 and use ReFS as the filesystem for the added hard disk.\n– Install a backup proxy service, we just need to deploy the backup proxy service from the Veeam B\u0026amp;R console to the VM that we are using. The backup proxy will be who processes jobs and delivers backup traffic.\nSo, let’s go each step!\nBackup proxy service First, our Windows Guest OS VM is joined to the domain, so we won’t have any kind of problem for resolving the name or accessing with domain account credentials.\nLet’s add the proxy by going to the Backup Infrastructure tab \u0026gt; Backup Proxy \u0026gt; Add VMware Backup Proxy…\nAs this is a new server for Veeam, we will have to add it as a «server» by pressing «Add New…»:\nThen, this window will appear, just enter the FQDN of your server:\nChoose credentials and choose «Apply «to install the transport service:\nAfter that, you will be able to choose the newly added server (Proxy_EUR.itgaiden.com) from the drop-down menu:\nNow, let’s configure the Transport mode and Datastores for this proxy (as in the previous screenshot):\nAnd for the datastores, choose the ones that are connected to the ESXi host where the VM is hosted by selecting Manual Selection and adding them:\nAfter configuring that, you will have the same configuration as in this screenshot:\nFinally, just hit Next and apply any kind of traffic rule if you want:\nNow, finish, and the proxy will be fully configured and ready.\nWe configured these options because they are the best for our deployment which is using a Windows VM that will have a backup repository which will save the backups.\nFor more detailed options about the Backup Proxy service go here.\nAfter configuring each backup proxy we will have a bunch of them in the Backup Proxies tab:\nBackup repository configuration In this step, I suggest following this article to perform this step.\nBasically, we just have to add a new hard disk to our dedicated VM as Thick Provision Eager Zeroed, format the disk as ReFS and finally, add the Backup Repository to the Veeam B\u0026amp;R Console.\nIn that article, it’s also explained the benefits of ReFS so, I think it’s more detailed and easy to follow it.\nAfter we configure all the backup repositories, we will have the same amount as the backup proxies:\nAs you can see in the previous screenshot, the path (D:\\Backups) is the disk that we added to the VM on each remote site. We have configured the backup repository to that path because, as explained before, we have a disk formatted in ReFS and it’s explained in the article.\nBackup job configuration After configuring the backup proxy and backup repositories on each site, we are ready to the last step, configuring the backup job to perform backups.\nGo to Home tab and then Backup… Virtual Machine:\nNow, step by step, pick a name for the job:\nProceed to select the VMs you want to backup (in our case the ones in the EUR site):\nLet’s continue and in the Backup proxy, click Choose… and select the correspondent backup proxy (EUR_proxy):\nPress OK and go to Advanced. Configure it like that if you want Synthetic full backups: And then the monthly health check (recommended):\nAccept and here is the summary for the backup proxy step (we will keep 7 restore points in our case):\nConfigure any option as you like (not in my case):\nAnd finally, proceed with the schedule that you want after finishing the configuration for this job!\nAnd that would be all for this remote site. We had to to the same with the other remote sites and our job will be done!\nConclusion Finally, with this design you will be able to back up remote sites and store the backups in the local storage from each site.\nIf you don’t want to use a dedicated VM as a backup proxy, you can install the service on a VM that has low usage and install the backup proxy service, however, it’s recommended to use a dedicated VM which will have the backup proxy service and the backup repository (the virtual hard disk attached).\n","permalink":"https://dangaiden.github.io/?p=1018/","summary":"I was wondering why I haven’t talked about Veeam when I use it almost every day in my job, not only administering backups but doing new implementations.\nRecently, I had to implement a design where I need to backup VMs in remote sites but not back up them in a centralized storage, they will be backed up on each remote site storage.\nSo, by deploying a VM with the Backup proxy service and also use it as the backup repository we can accomplish the goal.","title":"Veeam – Backup VMs in remote sites"},{"content":"I will explain today how to migrate ADFS from 2012 R2 (3.0 v) to 2016 (4.0) without almost no downtime. The overall process consists in adding the new ADFS server to the farm, assign the primary role to the new ADFS, make some changes and then we’re done.\nThe current environment is:\n1 x WAP Server (W2012 R2) 1 x ADFS Server (W2012 R2) No applications published, just an Office 365 Relying party trust.\nA DNS A record that points sts.teselia.com to the ADFS IP address.\nAnd the future environment will be:\n1 x WAP Server (W2016) -\u0026gt; Not in this post\n1 x ADFS Server (W2016) -\u0026gt; In this post\nPlanning for your ADFS Migration Active Directory schema update using ‘ADPrep’ with the Windows Server 2016 additions (not necessary in my case) Build a Windows Server 2016 server with ADFS and join into an existing farm. Promote one of the ADFS 2016 servers as “primary” of the farm, and point all other secondary servers to the new “primary”. Change DNS records to the new servers’s IP address. Raise the Farm Behavior Level feature (FBL) to ‘2016’ Test that the setup works correctly. Remove the old ADFS server (W2012 R2) from the farm. Upgrading Schema Now, time to upgrade the schema of the AD:\nPut the installation media from W2016 Datacenter:\nAdprep /forestprep\nIn my case, it was already updated (my domain is in W2012 R2 so it seems that I don’t need it).\nInstalling and configuring ADFS Once we deployed a new Windows Server 2016 and it’s joined to our domain…\nInstall the role of ADFS in your target server and then continue with the post-deployment config:\nProvide can account with Domain Administrator permissions:\nProvide your federation service name. You can review it in the current ADFS primary server and click Properties in the root folder of the ADFS console:\nIn our case “sts.teselia.com”:\nSpecify your SSL certificate (usually your wildcard):\nThen, I will use an account (Managed service account recommended):\nReview your configuration and after the pre-requisite checks proceed with the «Configure» button:\nAfter the server is installed you will have some warnings that will be fixed later by rebooting the server and making this new server as the primary ADFS server in the farm:\nThen, we will proceed to reboot our server (ADFS01.teselia.com).\nConfiguring as a «PrimaryComputer» in the ADFS farm Once the machine has restarted, open the ADFS Management Console, and you’ll notice it’s not the primary federation server in the farm.\nOpen a PS console and execute: Set-AdfsSyncProperties -Role PrimaryComputer\nAfter that, I can access the ADFS console from our new ADFS server without the warning:\nExecute this on the other ADFS servers (we will point the new ADFS server as the PRIMARY):\nSet-AdfsSyncProperties -Role SecondaryComputer -PrimaryComputerName sts.teselia.com\nThen, we will check that in our old ADFS server it’s correct:\nDetails to bear in mind So, in my case, I have a DNS A record that points sts.teselia.com to an IP address (the ADFS server)\nAfter pointing the new, I had to modify the hosts file from the WAP server in the DMZ to point to the new server!\nAlso, I modified the DNS record from the internal DNS with the new server’s IP address.\nError with 0365 relying party trust After migrating the service from ADFS 3.0 (W2012 R2) to ADFS 4.0 (W2016), I faced a problem when updating the O365 relying party trust.\nThe solution was to apply a fix described by Microsoft:\nhttps://docs.microsoft.com/en-us/security-updates/SecurityAdvisories/2015/2960358\nBasically, what you have to do is to add a couple of registry values in this new ADFS server because it’s Windows Server 2016 and is running ADFS 4.0 version.\nOnce you applied the fix, reboot it and works flawlessly!\nTesting the new setup\nTo check that it’s really working, try to log into your Office 365 portal and it must show you the portal from your federation service.\nAs the WAP service isn’t migrated yet, it should respond correctly but if the configuration is not correct, it won’t be able to gather the configuration from the ADFS service.\nRemoving the old ADFS server Once you tested that it works correctly, as both ADFS servers will have the configuration replicated, you can remove the role from the old one (that now holds the secondary role) and then remove it from the domain.\nWith that done, you will have a fresh new Windows Server 2016 ADFS server and none «old» ADFS servers.\nAnd that’s all, I will do in the future another post about the WAP service migration that it’s easier than this one, I hope that this can help someone.\n","permalink":"https://dangaiden.github.io/2019-07-31-migrating-adfs-from-2012-r2-to-2016/","summary":"I will explain today how to migrate ADFS from 2012 R2 (3.0 v) to 2016 (4.0) without almost no downtime. The overall process consists in adding the new ADFS server to the farm, assign the primary role to the new ADFS, make some changes and then we’re done.\nThe current environment is:\n1 x WAP Server (W2012 R2) 1 x ADFS Server (W2012 R2) No applications published, just an Office 365 Relying party trust.","title":"Migrating ADFS from 2012 R2 (3.0 v) to 2016 (4.0 v.)"},{"content":"I will explain quickly my experience regarding the Exam 70-743, Upgrading Your Skills to MCSA: Windows Server 2016 exam from Microsoft I took last April.\nIt’s been a while since I took an exam from Microsoft (the latest was in 2013 I think) where you probably know that these kind of exams are multiple-choice or single-choice.\nThrough my career, I saw a lot of people cheating with these exams by memorizing the questions you can find on the internet and finishing it in just 20 minutes.\nDespite I envied these persons because they weren’t putting the same effort as I did, in the end, this was translated in almost no knowledge about what they practiced nor familiar with all the features that Windows Server offers.\nSo, I encourage you to study the materials and practice in order to learn and bring value to yourself if you want to use these technologies from Microsoft. The blueprint and webpage for this exam is the following one: https://www.microsoft.com/en-us/learning/exam-70-743.aspx\nAbout the exam In my case, although I am experienced with Windows Server this kind of upgrade exams, which consists in a 3 in 1 exam, can be scary for someone who’s new or hasn’t touched many roles that Windows Server has.\nEven I installed almost all roles from Windows Server 2016 there are some of them that aren’t so common and you should practice it in a homelab (best way to stick in your mind).\nThere are around 60 questions (the quantity may differ) chosen from the following exams:\nExam 70-740: Installation, Storage, and Compute with Windows Server 2016 Exam 70-741: Networking with Windows Server 2016\nExam 70-742: Identity with Windows Server 2016\nRegarding the questions there is a mix of Drag and Drop, Radio buttons, Checkboxes, …you know, the usual ones in this kind of exams.\nImportant: Be aware that the feature «Nano Server» was removed/deprecated in Windows Server 2016 time ago, here is the official post from Microsoft: https://docs.microsoft.com/en-us/windows-server/get-started/deprecated-features\nAlso read the changes that this exam suffered, in the official change document that Microsoft provides (is in the blueprint): https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE2IoQP\nSo, even if you see a lot of information about Nano Server in guides or courses in my case I didn’t find any question in the exam related to it (as it was deprecated years ago).\nResources and suggestions As a resource, I mainly used this course from Pluralsight (not free): https://app.pluralsight.com/paths/certificate/upgrading-your-skills-to-mcsa-windows-server-2016-70-743\nThere are a lot of videos there, I checked the ones I felt more insecure and practiced in the lab. Also, I do recommend that you use Powershell to install and configure everything you can and in this way, you will get used to it.\nAs this is a 3 in 1 exam, the range of features and roles to know is huge, knowing a bit of everything will help you to pass but, without practice, you won’t get anywhere…\nHaving experience helps a lot but if it’s not your case, focus on the roles and features you never used or are not used to use (ADFS, NPS, RRAS, Hyper-V, etc.).\nSo… To conclude, I can say it’s a fair exam and a bit challenging maybe but if you practice a lot with all the roles that Windows Server 2016 offers and know the differences from Windows Server 2012 R2.\nAlso, the most important I think…practice with Powershell. It won’t only help you with the exam also, in your future!\n","permalink":"https://dangaiden.github.io/?p=704/","summary":"I will explain quickly my experience regarding the Exam 70-743, Upgrading Your Skills to MCSA: Windows Server 2016 exam from Microsoft I took last April.\nIt’s been a while since I took an exam from Microsoft (the latest was in 2013 I think) where you probably know that these kind of exams are multiple-choice or single-choice.\nThrough my career, I saw a lot of people cheating with these exams by memorizing the questions you can find on the internet and finishing it in just 20 minutes.","title":"Exam 70-743, Upgrading MCSA Windows Server 2016 experience"},{"content":"I am going to share some thoughts and opinions about a recent video from the Cohesity Build Day Live recorded recently with the Build Day Live! team.\nDisclosure: This post is sponsored by Cohesity.\nFirst, just let me introduce briefly you what is Cohesity:\nCohesity is a platform focused on managing and consolidating secondary applications and the data. It provides a unified view and access to converge that secondary data, such as system backups and analytics in a simpler way to an IT administrator.\nNow, let’s deep into the topic.\nIn the video, you will see how Alastair Cooke and Bharath Nagaraj building a Cohesity cluster from the scratch, configuring jobs, updating the physical appliance, restoring some data and showing some other cool stuff.\nI really like this kind of videos because, you can see how they install a cluster, configure it or resolve any problems that can happen in real time without cuts.\nAlso, you can notice how much time it can take to deploy and configure a Cohesity cluster in some minutes, or even upgrading the whole cluster (node by node) while running some protection jobs (backup jobs).\nHardware In this case, they use a physical unit for deploying their solution, so it’s a 2U enclosure with 4 servers/nodes inside (blade server type). It comes, like most other solutions, with 1GB ports for Management purposes and 10GB ports for Production Data.\nAs this is an HCI solution, it comes with the storage and computes resources necessary to process and store all data (PCIe Flash card and hard drives in each node).\nCluster configuration and UI To configure the cluster you won’t need a lot of data to fill or knowledge to do it, they configure the cluster easier than I thought and straightforward. In a real scenario, a Cohesity engineer will do it for you thus, this is just to let you know of the simplicity of it.\nThe UI is simple and clean, the home dashboard looks nice with some graphics regarding your Storage Reduction, Health, Throughput, Protection Runs, etc.\nBackup As you probably guess, it backups your vSphere/Hyper-V/Nutanix environment like other products do, so you can configure a Backup Policy with a schedule, time retention, etc. to back up your data and then you configure a Protection job which will be the backup job that is associated to a policy.\nJust register the hypervisor of your choice and basically, you’re ready to back up your virtual servers (VMs). One option I really liked when registering a hypervisor was, the option of selecting «Auto Cancel Backup if Datastore is running low on space», so the DataPlatform solution is aware of the datastore’s space and can avoid you a big problem there…\nAbout granularity, there is a lot of options to select when you create a protection job (DB, Virtual/Physical Servers, but regarding what you can see in the video they protected only VMs and Office 365 mailboxes in different backup policies.\nIt’s great that when you are creating a protection job (a.k.a. backup job). you can select an object like a cluster or a folder with some particular VMs and then check the «Autoprotect» option to ensure that new VMs that are added to that object (folder, cluster, etc.) will be automatically protected.\nRegarding long term retentions, you can choose to add an external target like a NAS or any cloud (AWS, Azure, GCP, etc.) to store your archive backups there.\nThis is an option that adds great value to your strategy because when storing great amounts of data for several years, you usually don’t want to store it locally or even in a NAS.\nIn my opinion, having a flexible option to store it in any cloud can save you a lot of headaches despite the money that you must pay for the cloud service (which nowadays almost every company does).\nSo, within a Backup policy select the Archival option and then you add as many external targets to store your long term backups.\nRestore Your backup strategy is useless unless you can restore from it…\nI do like some points about this section that makes so simple to restore, from a single file (even download it) to restore tons of virtual machines to your virtual environment.\n– Single file restore If you want to recover a file, you don’t have to search for the date, where it was, etc. As simple as searching for the name of the file (or the portion you remember) and it will be searched in the entire cluster for you:\nAnd then, when you found that file, look at the options that we have:\nFirst, search for the date and then, you can choose the usual option (Recover to Server) or … download it at the moment (a cool option there).\nIt looks like a painless and simple way to restore files that probably a non-tech person could do.\n– Instant mass restore Now, going bigger, let’s talk about the Cohesity instant mass restore of virtual machines. As the Cohesity platform is designed in a distributed architecture where there isn’t a centralized bottleneck, they can restore tons of VMs quite faster than other products.\nWhen recovering a lot of VMs, in the background (you could look at your vSphere environment) it will mount an NFS datastore and bring up all you requested VMs (quite fast to be honest).\n– Office 365 Finally, the last thing to show you is the option to backup your Office 365 environment. You can integrate Cohesity with your Office 365 and perform protection jobs that will be associated with a policy and consolidate all the data within the same platform.\nUpgrading The process is straightforward, selecting a package from your local computer or getting it from the Internet, this makes it so easy to do it for yourself.\nOne thing that stuck in my mind was that, while there were running some protection jobs you are able to upgrade the whole cluster (node by node) non-disruptively.\nAs the entire solution is designed to tolerate one node failure (N+1 redundancy) thus, you can upgrade one node without disruption in the service.\nAs we said before, the Cohesity platform is based in a distributed architecture so, in case a reboot is required after upgrading one of the nodes, you will only lose the bandwidth coming from that node and not impacting the rest of the environment.\nHelios Cohesity Helios is the console that lets you manage and view all your clusters from one console. As it’s in the cloud, you only have to register your Cohesity appliance and at the end, it will show up in the Helios console.\nHelios Dashboard is similar to a Cohesity management dashboard but with the ability to manage all your clusters from that single pane of glass.\nAnd it’s just not that… Helios lets you install applications!\nYes, you can choose to install applications in one of your clusters without anything else. What Helios will do is to deploy an app within a container (using Kubernetes) in that cluster without having to worry about the underlying infrastructure.\nJust install, configure and run your app (as it sounds).\nFor example, running Splunk to gather data analytics in your clusters without having to worry about to deploy it is really a nice feature to look at it. I’ve never seen a feature like that and it really surprised me when I saw it. A nice additional value that you can consider when using Helios with your Cohesity platform.\nOther use cases As the Cohesity platform is cloud and hypervisor agnostic, you can protect objects on any cloud Azure/GCP/AWS or any hypervisor Hyper-V/VMware/Nutanix but, do you imagine what else can you do?\nWell, you can use it to migrate VMs between different environments! It’s a great use case where you can choose to backup all your vSphere environment and move it to Nutanix for example or moving it to Azure. Obviously, there is work to do after it but, the amount of simplicity that gives you with that, for me, it’s massive.\nThat’s all… We saw a lot of things from the Cohesity platform, how can help your company to achieve that data consolidation by: backing up from different clouds and environments (cloud and hypervisor agnostic) , establishing an SLA in your services (configuring policies), recovering tons of VMs and other features like Helios, a cloud console that brings you a unified view for your Cohesity environment, analytics for all your data and even the ability to deploy applications without needing any kind of resources.\nIf you are interested in more content, check the Cohesity Build Day Live web page or the official web page from Cohesity.\n","permalink":"https://dangaiden.github.io/?p=861/","summary":"I am going to share some thoughts and opinions about a recent video from the Cohesity Build Day Live recorded recently with the Build Day Live! team.\nDisclosure: This post is sponsored by Cohesity.\nFirst, just let me introduce briefly you what is Cohesity:\nCohesity is a platform focused on managing and consolidating secondary applications and the data. It provides a unified view and access to converge that secondary data, such as system backups and analytics in a simpler way to an IT administrator.","title":"Cohesity Build Day Live"},{"content":"This is a quick post of an error I found sometimes while deploying a new vCenter server appliance with an embedded PSC on the vCSA 6.x installer.\nThe problem In my case, I was trying to install vCSA 6.5 without DNS (this is why the system name has an IP address and the DNS is itself). Also, notice that the network section is empty:\nIf you try to continue with the installation, it will show you an error:\nNo networks on the host. Cannot proceed with the installation.\nSolution I checked the ESXi host and obviously, it has other port groups created in a standard virtual switch, then, which was the problem? Why I can’t see them in the drop-down list?\nChecking on the internet I found this: https://serverfault.com/questions/886776/vcenter-server-appliance-6-5-installer-error-no-networks-on-the-host-cannot-p\nSo, that web page mentions the «VM network» port group that is a default port group that is created once you deploy an ESXi host. In my case, it was auto-deployed with different port groups and that one didn’t exist.\nHence, I decided to create a port group called «VM Network» in the host that I am trying to deploy the vCSA and…it worked!\nNow, as you can see, I can see that port group and I was able to continue the installation with success!\nIt seems that with you must have this port group if you are deploying a vCSA at least from your PC, so, bear in mind if you are trying to deploy a new vCSA and you don’t have the default port groups when deploying a vCenter Server.\nI hope this helps if someone has this issue.\n","permalink":"https://dangaiden.github.io/2019-04-30-vcsa-6-x-installer-error/","summary":"This is a quick post of an error I found sometimes while deploying a new vCenter server appliance with an embedded PSC on the vCSA 6.x installer.\nThe problem In my case, I was trying to install vCSA 6.5 without DNS (this is why the system name has an IP address and the DNS is itself). Also, notice that the network section is empty:\nIf you try to continue with the installation, it will show you an error:","title":"vCSA 6.x installer error: “No networks on the host. Cannot proceed with the installation.»"},{"content":"Let’s start with part 3 in the cloning virtual machines in vSphere series, I am going to talk about another type of clones, linked clones!\nAll articles regarding cloning virtual machines in vSphere series:\nPart 1: Types of clone\nPart 2: Full Clone\nPart 4: Instant Clones (not published yet) As said in previous articles, this series is only focused on VMware vSphere hence, VMware Horizon View is not contemplated (Linked clones are commonly used in that product).\nWhat is a linked clone? What can you see here?\nKeanu Reeves has been linked cloned! In the previous image, you can see 3 different characters but they share something in common…the actor!\nLinked clones are the same! A linked clone is a type of clone (a copy of a virtual machine) where the parent VM shares virtual disks with their clones.\nThe resulting linked clone will be created from the parent’s VM snapshot and because of being a snapshot, it will have the same state that was the snapshot was taken.\nWhen the linked clone is created, it shares his own virtual disk (.vmdk file) with the snapshot from the parent VM, this leads to some unique features:\nThe clone will be dependent from the parent VM because they are sharing their virtual disks. If you delete the parent’s VM snapshot, it will corrupt the clone’s virtual disk. Even both VMs are sharing their storage, any changes performed in the clone won’t affect the parent VM and vice-versa. The linked clone will have the exact same data as the source VM because it was created from a snapshot. The save spacings are obvious because the clone will only write the new modifications in its own virtual disk. So, the clone’s virtual disk size will be only the amount of data that changed after it was created! General process\nUse or prepare a VM (Parent VM) that will be used as a master/parent to deploy the linked clones Power-off the Parent VM (Recommended but not mandatory) Perform a snapshot of the VM. Time to create Linked clones referencing the snapshot we created previously. Power-on the clones and customize them (apply customization specifications for example). (Extra) Before powering-on the linked clone, perform another snapshot of the clone to use it as a rollback (if the end-user needs it). (Extra) Power-on the clone and is ready to be delivered. (Extra plus) If you decide to keep the linked clone for any reason, you can perform a full clone of it and it will become an independent VM! In the next section, I will show you how to create a linked clone with PowerCLI from a Windows VM and in my case, I will use Custom Specifications within the script to launch the clone.\nLab time!\nHere we have the VM that we’re going to use as our Parent VM:\n– Name: SQLMasterVM\n– IP: 192.168.1.174\n– Disk allocation: Around 35 GB summing both disks.\n– Domain: vmug.bcn\nInside the Guest OS:\nSpace allocated in DS:\nWhat are we going to do?\nShutdown the master image VM that hosts some DBs. Create a snapshot when the VM is powered-off to ensure that is consistent (this is a VM with a SQL installed so, even more recommended) Perform the linked-clone via PowerCLI. Start the VM (We aren’t going to do the extra step of creating a snapshot of the clone) and use custom specifications to fully customize the clone. All of this will be performed by this simple script:\n[powershell]\n##Creating SQL Linked Clone from a Parent VM \"SQLMasterVM\"\n#variables\n$OSSpec = Get-OSCustomizationSpec -Name \u0026#8216;Win-SQL\u0026#8217;\n$BaseVM = \"SQLMasterVM\"\n$LinkedVM = \"SQL-LC1\" # Delete snapshots on the Parent VM\nGet-Snapshot -VM $BaseVM | Remove-Snapshot -Confirm:$falseStart-Sleep -Seconds 2 #Create snapshot\nNew-Snapshot -VM $BaseVM -Name \"Linked-Snapshot\" -Description \"Snapshot for linked clones for $LinkedVM\" #Gather information of the created snapshot\n$snapshotParent = Get-Snapshot -VM $BaseVM | Select Name\n$snapshotParent = $snapshotParent.Name\nStart-Sleep -Seconds 5 #Create Linked Clone referencing snapshot and start the VM.\nNew-VM -Name $LinkedVM -VM $BaseVM -Datastore \"VMS\" -ResourcePool (Get-Cluster -Name Gaiden-Cluster | Get-ResourcePool) -OSCustomizationSpec $OSSpec -LinkedClone -ReferenceSnapshot $snapshotParent -DiskStorageFormat Thin\nStart-VM -VM $LinkedVM\n[/powershell] In this script, I am also using the OSCustomizationSpec parameter, while using the sentence to create the linked clone, to change the IP, name and join again to the domain the resultant clone. Also, I am changing the SQL instance name in my case because it’s a server with MSSQL server installed.\nOnce the script finished, a new linked clone is created and powered on with the name «SQL-LC1».\nWe can see the amount of time that takes to create a Linked clone (5 seconds):\nAnd now look at the storage allocated by the Linked clone (powered off), 750 MB approximately:\nAfter the Linked clone is created and powered on, you can do whatever you want. I had to wait some minutes (around 10 min. in my case) until the OS customization specification finish all the actions specified (power on the VM, join to the domain, reboot the VM, execute a script to update SQL instance, etc.)\nHere is the «real» space allocated after the Linked clone has booted up and I logged in with a user, around 4 GB:\nA look inside the Guest OS of the linked clone (new hostname, IP and has the same storage as the Parent VM:\nUse cases It’s commonly used in VDI and DEV environments but here are some examples:\nDesktop Deployment\nQA Bug testing DB server testing File server testing General testing Benefits and limits\nLet’s summarize which are the benefits and limits that we can find in linked clones:\nPros\nSuperfast cloning compared to a Full/Normal clone, it takes seconds instead of minutes to clone large VMs.\nSpace savings due to changes are stored in a separate disk (clone’s flat disk). Useful for development environments or if you want to keep the clone just, perform a full clone of it! Deploy as many linked clones as you want, they will reference the snapshot in the Parent VM hence, there is no disk chain on that (except for the snapshot you created of course) and the benefits of replicating. Ongoing changes made in the virtual disk of the source VM don’t affect the linked clones and changes to the disk of the linked don’t affect the parent. It can be performed with the parent VM powered on but, it will have some performance degradation and probably inconsistent data (if for example, the parent VM hosts a DB). Cons\nRecommended but not mandatory that the parent VM has to be powered off. There is a storage/disk dependency as the linked clone is created from the parent’s VM snapshot then, if you delete that snapshot, inconsistencies will occur in the clone (and at the end you will delete it). Performance on the destination clone will be impacted (as virtual machines are sharing storage) To conclude Linked clones have multiple benefits compared to full clones and it has many use cases as we saw before.\nYou can easily replicate the status of a VM (snapshot) and deploy linked clones to your end-users with all the benefits as for example space savings or the deployment speed. To end this series, we will look at instant clones, another type of clone that is even faster than linked clones but, with some particularities.\n","permalink":"https://dangaiden.github.io/2019-04-16-cloning-virtual-machines-in-vsphere-series-part-3-linked-clones/","summary":"Let’s start with part 3 in the cloning virtual machines in vSphere series, I am going to talk about another type of clones, linked clones!\nAll articles regarding cloning virtual machines in vSphere series:\nPart 1: Types of clone\nPart 2: Full Clone\nPart 4: Instant Clones (not published yet) As said in previous articles, this series is only focused on VMware vSphere hence, VMware Horizon View is not contemplated (Linked clones are commonly used in that product).","title":"Cloning virtual machines in vSphere series – Part 3: Linked Clones"},{"content":"Hey! I am Dan Belmonte and now I am working as a Cloud SRE (weird name I know) at NTT.\nMy daily work is associated with Cloud, container, and IaC technologies. Here you will see a variety of topics from VMware and Microsoft to Linux, Cloud, and containerization stuff.\nYou can find me at:\nTwitter: @DanGaiden VMTN: https://communities.vmware.com/people/dbalcaraz I do like videogames and sports (mainly cycling and padel). For gamers, there is a Discord page http://vgamers.gg/ where you can register and play some videogames with people who share their love about virtualization and games.\nI am a member of vBrownbag which is a community of people who believe in helping other people. Specifically, we work in IT infrastructure and we help other people in the IT industry to be better at their jobs by learning about IT.\nI presented in some VMUGs like in the VMUG Barcelona and VMUG Madrid in 2018 and 2019 and now I am VMUG leader for the Madrid one\nAnd also at VMworld 2019 EU!\nIf you love Street Fighter/Tekken or any fighting game, some of us use #vStreetfighter when we are at VMworld or just at home playing against each other.\n","permalink":"https://dangaiden.github.io/about-me/","summary":"Hey! I am Dan Belmonte and now I am working as a Cloud SRE (weird name I know) at NTT.\nMy daily work is associated with Cloud, container, and IaC technologies. Here you will see a variety of topics from VMware and Microsoft to Linux, Cloud, and containerization stuff.\nYou can find me at:\nTwitter: @DanGaiden VMTN: https://communities.vmware.com/people/dbalcaraz I do like videogames and sports (mainly cycling and padel). For gamers, there is a Discord page http://vgamers.","title":"About me"},{"content":"I am going to talk about my experience at a local VMUG, in my case the VMUG from Barcelona (BCN). It was my first time at a local VMUG event and this is why I decided to share my thoughts about it.\nVMUG – What is? As you probably know VMUG stands for VMware User Group. Basically, you will find an international community of people where they share their experiences and discuss things related to VMware and other technologies.\nAt your local VMUG, you will find VMUG members that you can meet online or in person, sponsors. There you can find many passionate people about VMware and connect with them, so I highly recommend to attend to the VMUG events as it is a great experience to learn concepts or technologies and connect with a lot of people.\nThere are many communities around the world if you want to find your local VMUG go and register at https://www.vmug.com/\nVMUG – Why attend? Because you won’t regret it!\nI didn’t imagine that the environment and people were so good, everyone is passioned about technology, mainly VMware things, and you can hear their stories and share experiences that both probably lived in your life.\nHence, it doesn’t matter if you’re presenting or attending your local VMUG, the thing is to go there, meet people and learn about the sessions! You will find that a lot of people share some passion for VMware and technology so, don’t be shy to say hello and try to meet them.\nPresenting at a local VMUG\nI’ve been involved in this local VMUG for a year approximately but, I never had the chance to attend any event. Since VMworld I didn’t hear anything about a new event so, I spoke with the VMUG forum about when would be a new event and finally, it ended with myself presenting my session.\nIn my case, I presented a session (in Spanish) about Clones in vSphere (I’ll do a post about presenting in the near future) on March, 15th.\nYou didn’t expect something like my case, I was lucky to present at my first time in this event but, usually, it’s better to go there and meet the people before presenting and not in the other way.\nFinal thoughts I am glad that I finally was able to attend and meet a lot of VMUG members, you can learn a lot from people through their sessions and also make connections that will be valuable in the future.\nI would highly recommend attending and experience the passion of VMUG members and the knowledge that you can gather from them.\nAlso, I would like to acknowledge the VMUG leaders from the BCN VMUG for letting me present and the sponsors that make it possible.\nI hope to see everyone in the next event!\n","permalink":"https://dangaiden.github.io/2019-03-29-experience-at-a-local-vmug-barcelona-vmug/","summary":"I am going to talk about my experience at a local VMUG, in my case the VMUG from Barcelona (BCN). It was my first time at a local VMUG event and this is why I decided to share my thoughts about it.\nVMUG – What is? As you probably know VMUG stands for VMware User Group. Basically, you will find an international community of people where they share their experiences and discuss things related to VMware and other technologies.","title":"Experience at a local VMUG – Barcelona VMUG"},{"content":"Continuing with the cloning virtual machines in vSphere series, today I am going to write about the full clone, how it works and some useful information about it.\nSo, let’s talk about clones… but just full clones.\nHow does it work? As you probably know a full clone is an exact copy of a source VM, meaning that, everything from the parent VM is copied (VM settings, disks, files, etc.).\nThis action can be performed if the parent VM is powered off or powered on and, if it has snapshots it will consolidate them once the clone is done.\nWhen you clone a VM be aware that, all data will be identical so, if you power on the clone without performing any customization, probably you will have conflicts with IPs, MAC addresses, SIDs (Windows), etc.\nThe great thing about a full clone is that, after the cloning operations are performed the clone will be an independent copy of a virtual machine that doesn’t share anything with the parent virtual machine (we are talking about from a compute and storage perspective within vSphere).\nWays to do it First of all, you will need VMware vCenter to do it. There are other ways (not official) like copying all data related to the virtual machine (.vmdk and .vmx files) and then register the «new» VM with another name.\nLet’s continue with the usual ways:\nvSphere Web Client You can do it through vSphere Web Client, as simple as, right-click a VM -\u0026gt; «Clone to Virtual Machine…» :\nOnce it finishes, it takes some time (depends on the storage that the source VM has allocated) but in the end, you will have your new clone.\nLikely you are more familiar about deploying templates…\nDeploying a template is the same as cloning but. aside from copying the same data from the parent virtual machine, vSphere lets you customize the deployed VM for creating many clones and with different configurations as you wish.\nPowerCLI Of course, you can do it with PowerCLI. These are the minimal parameters needed to perform it (Disk Storage Format parameter is optional but recommended because, by default, it will convert all disks to Thick Provision Eager Zeroed):\nNew-VM -Name -VMHost -VM [-DiskStorageFormat ]\nIn the previous screenshot, you can see the minimum parameters required to perform a full clone, if you want to see more options you can check it here.\nAs you can see in the code, it’s similar to deploying a template, isn’t it?\nUse cases The main use case is deploying from a template, maybe we are not aware but, deploying from a template is just cloning our source VM (Master template) and then customizing it.\nI saw many customers use it as a «rollback» when they have to perform a destructive task within the Guest OS. In this way, just shutting down the parent VM and powering on the clone.\nIf you think a snapshot can do the same as a clone well, not always… some applications don’t handle well doing a quiesced snapshot.\nThis is why, as a solution, you can create a full clone when the virtual machine is powered off and then, have a copy that will be consistent and without corruption.\nAnother use case could be to perform a full clone to use it in other environments. Although there are better ways to do this (with other products), when the Guest OS has many customizations, this can be an alternative solution of re-creating the entire virtual machine.\nBenefits and limitations\nThe benefits of a full clone were mentioned before: If the cloning operation is executed when the source VM is powered off, it can be used as a rollback in many cases (there are better options like a VM backup but, it can help a lot). Creation of an independent VM that shares nothing with the source VM. Used in templates, so, they are very useful! These are some limitations instead of disadvantages that we can find:\nIt takes some time to create a full clone (it depends on the allocated storage) as it has to copy all storage from the source VM. It can only be performed with VMware vCenter (there are other ways as I explained before but they are not official). If done when the VM is powered on, it has an impact on the source VM that can be noticed by the business so, isn’t the best option to do it while the virtual machine is in running. Conclusion To sum up, a full clone is a great way to have an identical copy of another VM to use it as a permanent virtual machine once you configure it accordingly.\nAs said before, is the same as deploying a template because you are just cloning a VM (deploying a template) and then customizing it. It usually takes some minutes to finish the clone (depending on the storage allocated in the parent VM), this is why there are other ways to deploy clones in a faster way (on the next posts!).\n","permalink":"https://dangaiden.github.io/2019-03-06-cloning-virtual-machines-in-vsphere-part-2-full-clone/","summary":"Continuing with the cloning virtual machines in vSphere series, today I am going to write about the full clone, how it works and some useful information about it.\nSo, let’s talk about clones… but just full clones.\nHow does it work? As you probably know a full clone is an exact copy of a source VM, meaning that, everything from the parent VM is copied (VM settings, disks, files, etc.).","title":"Cloning virtual machines in vSphere series – Part 2: Full clone"},{"content":"Most of you already know how to clone virtual machines within vSphere, and I mean cloning from the vSphere Web client within vCenter but, beyond that, there are other types of clones you can use in vCenter like, Linked Clones or Instant Clones (aka Project Fargo/VMfork)\nDue to the large content that can be discussed about each clone’s type, I decided to make a short series of posts talking about cloning VMs!\nTypes of clone Here I will summarize each type of clone that exists in vSphere, some of them are used in different products or interfaces but in the end, all of them are accessible through PowerCLI.\nFull clone This is the «classic» clone you can perform in vSphere Web Client no matter which is the VM’s status (powered on or off), that you can perform a copy of the VM.\nIf you want to perform a consistent clone, it’s recommended that you power off the VM and then perform the clone.\nThis is an independent copy and has no dependency from the parent virtual machine after the clone is complete (meaning that you can remove the parent VM if you need it).\nThe main advantage is that you can have a reliable copy of the Parent VM (remember this is not a backup) if you want to replace it. As this is a full copy of the VM (it will copy the entire disk), this might take several minutes depending on the size of the VM.\nAfter you perform it, remember that everything will be the same then, all configuration (SID, network configuration, hostname, etc.) within the VM will be identical hance, it can lead to problems if both VMs co-exist at the same time without the proper configuration.\nFull clone Linked clone Is a clone made from a snapshot of the Parent VM. This means that both VMs (the Linked clone and the parent VM) have in common virtual disks. So, the linked clone is dependent on the parent VM, meaning that the linked clone needs access to the parent VM. The clone must be done while the Parent VM is powered off (as a best practice).\nOnce a linked clone is performed, changes on the parent VM doesn’t affect the linked clone and in the other way, changes in the linked clone don’t affect the original VM. Mainly the benefits of using linked clones are: Saving disk space because only the differences between the origin snapshot and the linked clone are allocated and the fast. Quickly deploy tens or hundreds of VMs in a fast way as it doesn\u0026#8217;t need to copy the entire disk. This is a technology commonly used in VMware Horizon View to provide desktop deployment (rapidly deploy a lot of VMs). The thing is that we can also use it with PowerCLI without having Horizon View and use it for more use cases.\nLinked clone Instant clone Similar to the linked clone, Instant Clone is like an improved version of linked clone technology. This is something «new» in vSphere 6.7 as is available through the API.\nLike the linked clone technology, there is a parent VM which will share the disk with the clone (Instant clone) but, in this case, it will share the memory too (even if TPS is disabled).\nThere are two types of Instant Clones that I will explain in more detail in the next posts but, as a summary, you can do an instant clone from a source VM from a point in time and deliver many VMs (instant clones) as you want. The Parent VM must be powered-on instead of powered off like other types of clones, in this way, it can provide even a faster way to deploy VMs because it will not require to power-cycle the Instant Clones.\nAs benefits, we will have the same as in Linked Clones technology plus memory efficiency (because it shares memory between VMs) and the ability to resume the VM in a point of time without power cycling the clone. In the other hand, depending on which type of instant clone you can run with a lot of delta disks.\nInstant clone So… I tried to summarize each clone’s type that we can perform within vSphere and if you want to read more, stay tuned to go in more detail in the coming series of posts related to cloning VMs within vSphere.\n","permalink":"https://dangaiden.github.io/2019-02-25-cloning-vms-in-vsphere-part-1/","summary":"Most of you already know how to clone virtual machines within vSphere, and I mean cloning from the vSphere Web client within vCenter but, beyond that, there are other types of clones you can use in vCenter like, Linked Clones or Instant Clones (aka Project Fargo/VMfork)\nDue to the large content that can be discussed about each clone’s type, I decided to make a short series of posts talking about cloning VMs!","title":"Cloning virtual machines in vSphere series – Part 1: Types of clone"},{"content":"Regarding this nice article, I read while ago from Eric Shanks: https://theithollow.com/2018/03/26/fill-skills-tank/.\nI decided to write about it as it’s always in my mind since he published it. In particular, I will talk about what we should learn in order to fill a gap for a position/job in any technology and my experience.\nWhich path to choose? I started learning Microsoft (MS) products and then I learned other technologies like Virtualization, Cloud, Storage, etc. In any case, you don’t have to worry about which would be your first technology because you can move later if you realize it doesn’t fit you. For example, you can start learning Linux (I hope I had taken that path!) instead of Windows and then move to Windows or learning about Storage, any path would be correct as long as you continue to learn the same technology or a new one.\nWhen you start learning, you have an idea of what do you want to learn: Network, Cloud, Storage, etc. and then try to master that technology or move on to another one. Hence, you must start somewhere in order to grow your knowledge and then, you will decide which technology or technologies do you want to focus on.\nAs soon as you start you will notice if you like or not, but choose one!\nKnowledge lost as a tank with a leak. As I mentioned at the beginning of this post, Eric Shanks mentioned in his blog https://theithollow.com/2018/03/26/fill-skills-tank/ , is like filling a tank (which drains as time passes by) with your knowledge:\nWhen you learn a new topic it stays in your mind (won’t drain) as long as you keep using it, hence you will gain different levels of knowledge within the topic, in some years maybe you will achieve an advance and then maybe an expert level or maybe not, as not everyone has the ease to learn things. Also, remember that to maintain a certain level you must update your wisdom (due to the topic is always acquiring new updates or features) about the topic and therefore more effort and time to put on.\nYou can try to learn other things and try to earn the same level of knowledge in each one but, it can be tough to do…You must spend a lot of time updating the different topics and to maintain it. So, we should try to fill our tank with the knowledge we really want or desire (by testing, reading, writing, etc.), in this way, we could maintain a great level of wisdom but, nothing is more useful than practising!\nIn my personal experience, when you are learning something new (by reading or watching videos) at the end, there is nothing more useful than practising it in a lab, even if you know the steps. It’s really a way to ingrain in your mind those steps and if you fail when deploying a new product or feature it’s even better 🙂\nFilling the gap, but which? This is what I really wanted to talk.\nSometimes, it can be really hard to achieve a new position because you notice that there are some gaps between your skills and the desired position/job.\nAbout dream jobs… For example, if your dream position is to be a Technical Architect, you must be good enough in a lot of topics (networking, storage, virtualization, soft skills, etc.) but, can be very difficult to earn expertise on each area(without mentioning the soft skills needed).\nAs you know, each matter has sub-matters, for example, if you want to learn VMware, you can learn the Server virtualization platform (vSphere) but, there are other areas like Storage virtualization platform (vSAN) and Network virtualization and Security platform (NSX) for example.\nSo, here we see that you can be an expert on vSphere but, a lot of positions will demand that you know about vSAN or NSX for example, and you spent a lot of time and effort on being a great expert on vSphere.Then, do you really need to gain an advanced level before applying to a position that requires it?\nWell, it depends, you should figure it out with the Recruiter but at least earn an entry level in the skills that the job requests.\nWe can conclude that to achieve that position, you must do an approach to each technology so, it usually takes a lot of years of experience and learning\nAbout filling the gap Another example, if you are a Windows Administrator and now you want to learn about Azure, well, it’s related to Microsoft but it’s different than learning about an another OS. In this case, you should gain knowledge in areas like Storage, Networking and maybe some coding skills.\nHence, we can conclude that you should try to learn at least a bit of every technology (related to your main knowledge) and trying to maintain/update your knowledge in those areas.\nAlso, bear in mind that the more you learn about different topics, the more you «lose» in other ones, so, my personal advice is to stay close of what do you want to learn and don’t be shy to learn about what you don’t.\n","permalink":"https://dangaiden.github.io/2019-01-31-it-skills-which-gap-to-fill/","summary":"Regarding this nice article, I read while ago from Eric Shanks: https://theithollow.com/2018/03/26/fill-skills-tank/.\nI decided to write about it as it’s always in my mind since he published it. In particular, I will talk about what we should learn in order to fill a gap for a position/job in any technology and my experience.\nWhich path to choose? I started learning Microsoft (MS) products and then I learned other technologies like Virtualization, Cloud, Storage, etc.","title":"IT skills: Which gap to fill?"},{"content":"To finish these posts about VMworld 2018 Europe, I am going to summarize day 3 and day 4 together as day 4 is usually the less busy of all of them (people usually leave in the morning).\nOn day 3 (Wednesday), I rest like 5-6 hours (pretty normal to me) after spending some part of the night at the Veeam Party. I made it to be at the enclosure at 8:30 AM because at 9:00 it will start the second general session.\nI grabbed some coffee and go to the correspondent Hall, the same as the day before.\n2nd General Session For me it was a weaker session than on the previous day but, I was great.\nHere you have a link to the Youtube video of the session: https://www.youtube.com/watch?v=5W_8t6F_yY0\nIn the previous post, I forgot to mention the VMware ESXi on a Raspberry PI as a prototype, that Pat and Ray showed us, really cool. vCommunity, vStreetfighter and more I must say that I had like 4 sessions scheduled on Wednesday and I only went to a couple of those. The most of the time I was hanging with people from the vCommunity and playing also I played some Street Fighter V in the gaming area. We have a group for that, check out #vstreetfighter for some tweets on Twitter and join us!\nFirst, let me show us a couple of fights that I had against Bilal Ahmed (I lost and I don’t how yet…). You can check here that Gregg Robertson offered a challenge against me at the gaming area.\nSo I was Ryu he was ken . I beat him 3 times in a row\u0026#8230;..then we played alpha2 and I was akuma and he whooooppped my ass 🤣 I do admit there was some luck and button bashing on my part lol pic.twitter.com/XqDEBy5icI \u0026mdash; Bilal Ahmed (@Dark_KnightUK) November 7, 2018 Another picture I took from him while been interviewed (Will we see this interview at any time?)\nWith Brett Guarino who, is really a nice guy and chatted a lot with him! Absoultely awesome finally meeting @DanBelmonte_ ! pic.twitter.com/3hqPKwBkfb \u0026mdash; Brett Guarino (@Brett_Guarino) November 7, 2018 Here a blurry photo with Chris Williams! Also, there is half Val there! haha\nLast selfie I took today with some of the @vBrownBag crew! @mistwire @homelaber #VMworld These guys rock! pic.twitter.com/LnuTnVxVq9 \u0026mdash; Dan Belmonte (@DanGaiden) November 8, 2018 I can’t be happier to be able to meet these persons and more that I didn’t mention or couldn’t take a photo. When you are there, the time passes by quick and because of this, I didn’t go to some sessions (I knew that I could watch them later at home).\nI enjoyed having dinner with Chris a couple of times, hanging a lot in the Solutions Exchange area or with Jorge de la Cruz to everywhere.\nThank you to Virtual Speaking Podcast for the Headphones, I was the lucky winner!\nVMparty I was there about an hour or so and there I went with Jorge de la Cruz to have dinner in a nice restaurant.\nThere was plenty of fast food: hamburgers, nachos, seafood, candy and more… so, if you want to feel full, you can’t go there!\nAlso, a Rolling Stones tribute band was there and they played really well!\nThe end Well, I left around 5 PM and say goodbye to some people that still there.\nIt only would have been better if Gregg Robertson and Ariel Sanchez were been there.\nAnd that’s all! Last post of the year obviously because it’s the last day.\nP.S. : I forgot to mention I took a photo with someone… Rodney Mullen!\n","permalink":"https://dangaiden.github.io/2018-12-31-vmworld-18-eu-day3-and-day4/","summary":"To finish these posts about VMworld 2018 Europe, I am going to summarize day 3 and day 4 together as day 4 is usually the less busy of all of them (people usually leave in the morning).\nOn day 3 (Wednesday), I rest like 5-6 hours (pretty normal to me) after spending some part of the night at the Veeam Party. I made it to be at the enclosure at 8:30 AM because at 9:00 it will start the second general session.","title":"Experience at VMworld 2018 Europe – Day 3 and Day 4"},{"content":"Today I am going to explain from my personal experience, the Day 2 at VMworld 2018 Europe, lots of networking, some technical sessions, events and the Solutions Exchange.\nBefore moving forward, I forgot to mention that I met in my first day a nice guy, Daniel Paluszek @dpaluszek, we had a great conversation and he should be known as the vCloud Director guy ;).\nvBreakfast If you don’t what is, check it here: http://www.vbrain.info/2018/10/14/vmworld-emea-2018-vbreakfast-2018-edition/\nThank you, Fred @Fred_vBrain for doing this kind of things! In this case, Abdullah Abdullah @do0dzZZ was the host for this year as Fred couldn’t assist.\nI woke up at 6 AM… a bit painful but, some sacrifices needed to be done when you are not at the office! It started at 7:00 AM but, I arrived around 7:30 AM or so.\nAnd I arrived… a lot of people were sitting there! I had the chance met some people I already know from Twitter and others that not. We had great conversations there meanwhile we tried to eat some toasts with iberian ham and also a bit of omelet.\nThere I met finally Chris Williams @mistwire and Alastair Cooke @DemitasseNZ part of the vBrownbag crew! And also, more folks like @matjovanovic, @uprightvinyl.\nThe first General Session I arrived at the hall and sit wherever I could and what a nice session…with some announcements and great stories to hear!\nVMworld Europe 18 \u0026#8211; 1st General Session Besides the newer versions of VCF, Horizon, AppVolumes and more, the more interesting for me was the acquisition of Heptio and the announcement of VMware Cloud PKS (it will be expanded to Azure in the future!).\nIf you want to watch it, you can do it here: https://www.vmworld.com/en/europe/learning/general-sessions.html\nAfter that, I had plenty of time to meet more people and attending a couple of technical sessions.\nThe best time, the vCommunity The best time of all of this is the #vCommunity and the networking that you can do. I met a lot of people there and I couldn’t be happier to have done it.\nI met an amazing person and famous (amazing) blogger here in Spain, if you don’t who is, please do it! He’s Jorge de la Cruz (@jorgedlcruz) and nowadays works for Veeam. He’s just a blogger machine (I don’t know anyone who posts more than this man). In their blogs, he has information about anything! You can check it out here: https://www.jorgedelacruz.es/ and https://jorgedelacruz.uk/\nSelfie with Jorge de la Cruz A couple of selfies I took this day with some vBrownbag’s members!\nFinally a photo with the amazing @homelaber ! @arielsanchezmor pic.twitter.com/WciPwTZAGu \u0026mdash; Dan Belmonte (@DanGaiden) November 6, 2018 With the greatest @DemitasseNZ ! A pleasure to meet him 🙂 #vCommunity pic.twitter.com/1vQMzaNMbF \u0026mdash; Dan Belmonte (@DanGaiden) November 6, 2018 This day, I also meet there Héctor Herrero @nheobug, Federico Cinalli @FCinalliP and Xavier Genestós @sysadmit.\nThe Solutions Exchange A thing you can’t miss, the Solutions Exchange. A lot of partners in this Hall where you can chat with people that work in the company and have great discussions, gather some swag and maybe you can win something in the raffle (yes, a lot of companies offered free tickets and there were big prizes like a Nintendo Switch, Apple Watch, etc.) !\nVeeam’s party I was so lucky to be invited to this party and what a nice party! I only can say that there were good drinks, food and of course music! It was in a famous discotheque called Apollo.\nBad quality picture from the Veeam party I know it’s not the best quality but, is just to show you how it looked:\nAnd that’s all… I had to leave «early», around 12 AM as I had to commute by train so, I didn’t have a chance to stay and enjoy this party.\nP.S.: I forgot to mention that each day there is a free lunch in a specific area where you can grab food. The lunchtime I think that I was delivered between 12:00 – 2:00 PM\nThe next post, the third day!\n","permalink":"https://dangaiden.github.io/2018-12-13-vmworld-18-eu-day2/","summary":"Today I am going to explain from my personal experience, the Day 2 at VMworld 2018 Europe, lots of networking, some technical sessions, events and the Solutions Exchange.\nBefore moving forward, I forgot to mention that I met in my first day a nice guy, Daniel Paluszek @dpaluszek, we had a great conversation and he should be known as the vCloud Director guy ;).\nvBreakfast If you don’t what is, check it here: http://www.","title":"Experience at VMworld 2018 Europe – Day 2"},{"content":"VMworld 2018 Europe is only a week away! And I wanted to explain you share expectations and information I found about. It will be my 1st time!\nVMworld Location As you may know, VMworld Europe is located in Fira Barcelona between 5-8th of November. As it’s in Barcelona, I am able to assist without paying any trip (I live close to the city).\nMain information When: 5-8 November 2018\nWhere: Barcelona, Spain | Exact location: https://goo.gl/maps/eR8cFyow89q\nAgenda: https://www.vmworld.com/en/europe/agenda.html\nIf you want to register: https://www.vmworld.com/en/europe/index.html A quick guide from VMware before going: https://blogs.vmware.com/vmworld/2018/07/vmworld-guide.html Events At VMworld, there are a lot of events happening before, during and after. You can join them free or by invitation. Be quick to register as some events will close earlier…\nAll events (parties, meetings, etc.):\nhttp://www.vbrain.info/2018/10/09/vmworld-emea-2018-parties-gatherings-events-and-more/\nhttp://www.running-system.com/vmworld-2018-barcelona-party-list/\nI will be attending vBreakfast: http://www.vbrain.info/2018/10/14/vmworld-emea-2018-vbreakfast-2018-edition/\nAlso, I’ll be at VMFest on Wednesday and maybe other parties but I can’t assure anything.\nExpectations I am going every day except for Thursday that I’ll leave before 1 PM.\nMy schedule is built with sessions, workshops, parties (just a couple) and obviously a couple of hours of free time, to network and do whatever I want (also relax, as it seems that can be exhausting). Remember that all sessions will be recorded so if you can’t attend it, you can watch it later.\nAbout the parties, I won’t be able to stay too late because I need to come back home and we have more days to enjoy VMworld.\nIf you want to talk or something (like play some video games), you can find me on Twitter (I am really active). I’ll be open to everyone in the community!\nEven I know I am not a famous guy, (and don’t pretend to be it), talking with new people can be satisfying and it’s always great to meet someone new. If you are shy you could try to engage someone on Twitter and let him/her know that you are there!\nAs it is my 1st time I can’t give any advice on this, you should check other blogs for that.\nP.S. I wanted to meet especially (among other people) Ariel (@arielsanchezmora) but it couldn’t be as he can’t assist.\nSee you there and enjoy Barcelona!\nDan Belmonte\n","permalink":"https://dangaiden.github.io/2018-10-29-pre-vmworld-2018-europe-expectations-and-information/","summary":"VMworld 2018 Europe is only a week away! And I wanted to explain you share expectations and information I found about. It will be my 1st time!\nVMworld Location As you may know, VMworld Europe is located in Fira Barcelona between 5-8th of November. As it’s in Barcelona, I am able to assist without paying any trip (I live close to the city).\nMain information When: 5-8 November 2018\nWhere: Barcelona, Spain | Exact location: https://goo.","title":"Pre-VMworld 2018 Europe – Expectations and information"},{"content":"Hi! I am going to talk about my VCAP6-DCV Deploy exam experience.\nI thought about making a huge post about the VCAP6-DCV experience (resources, notes, etc.) but, I don’t want to overwhelm you know. Hence, I am going to make another post for that, hence this post will be shorter and more readable.\n1st attempt (Java error at the beginning) At September, 21st I sat down to take my first attempt in a VCAP exam. I was confident because I was studying the previous 10 weeks approximately and I covered all the objectives.\nWell, my exam was scheduled at 10:00 AM, I sat down and my exam starts. The interface is exactly the same as the HOLs, so, if you familiarized with it, you will gain a lot of time!\nThe lab was deploying and the manual on the right side showed some information but as soon as the lab finishes to deploy…bum!\nA Java error appeared: Java error: Unhandled Exception, then I pressed OK and my exam finishes itself!\nI contacted the TA and she told me that my exam was finished, and I was like «What? In 2 minutes?». After spending some hours with Pearson VUE, the TA (Test Administrator) opened a case with Pearson VUE and I left the Test Center.\nI left with a feeling that this test center has serious issues, the TA didn’t know how to speak in English (I was taking it in Barcelona, Spain) and finally, I ended talking my self with Pearson VUE and explaining the problem. They couldn’t do anything as my exam was finished (it wasn’t my fault obviously)\nA week later I received a voucher code for my crashed exam.\n2nd attempt (Manual stuck in loading) This second attempt was scheduled at October, 5th. I rescheduled in another Test Center as I didn’t trust the TA for that Test Center.\nThe problem you face with the VCAP exams is that they are delivered in fewer Test Centers, therefore, there are less available spots to take it. I found another Test Center here in Barcelona, so I scheduled there even I didn’t know that one.\nWell, my exam started at 10:00 am, the server’s console loaded correctly after the lab was deployed (nice!) but, the manual didn’t appear, there was only a grey window without content.\nAfter waiting for 5 minutes, I spoke with the TA, and he told me to wait another 5 minutes. So, as expected, the manual was stuck loading and even trying to stop and start the exam didn’t fix the problem.\nHence, the TA contacts Pearson VUE and Pearson VUE fixed the problem this time! But what happened with all the time I lost in my exam? Well, the TA told me Pearson VUE would contact with VMware and the time will be added meanwhile I am taking it.\nAt that time, the exam started again but I had a weird feeling about.\nIn the exam, I finished writing down each question number and a brief description on the erasable board, in this manner, I could check quickly which questions I can take first and cross out which I have done.\nIt was curious that at times, backspace and shift keys worked in Putty. Also, occasionally, during 5-10 minutes I experienced quite delay with the Web Client. I continued with the exam, contacted with the TA about the time but no response from Pearson VUE and time were running out…\nThe time isn’t going to be added, hence, I had to left like 4 or 5 empty questions because I didn’t have more time (I lost 30 minutes) and the exam finalizes automatically. I felt bad because of the 30 mins. would be nice to try other questions.\nAfter that, I spoke with the TA and he opened a case with Pearson VUE about the time lost. One hour later, I received my score report, 278/500 (almost got it!).\nAfter a few days, Pearson VUE reviewed my case and, as I was close to passing the exam (remember that you need 300/500), I suppose they decided to give me another voucher code, so I felt good about the free re-schedule but bad for the score and the time lost.\n3rd attempt (Redeployed lab and final attempt) Well, this is really a lie, because I «took» 2 exams in a row. Let me explain…\nOn October, 16th, my exam was scheduled at 10:00 AM, I studied a bit the previous night just to remember some things. My last attempt was 11 days ago and I was focused on other things so, it’s always good to brush up some concepts.\nWell, the exam started and the lab was deploying itself… then, it appeared a notification like «Query not found». This time the manual loaded correctly, but the pop-up appeared all the time, appearing and disappearing, and the console didn’t load as the error appears instead.\nTherefore, the TA (Test Administrator) contacted Pearson VUE and for my surprise, Pearson VUE this time could contact VMware quite fast. The TA told me that VMware was going to redeploy another lab (Now my time wasn’t wasted at all!) and I could try in 30 minutes.\nFinally, I tried again and it worked correctly, the manual and console loaded correctly so, I took the exam. The connection seemed a bit better so I can’t complain about. Also, the backspace and shift keys worked as in my previous exam, therefore, I took advantage of it.\nNow, I tried to answer all questions (I left 1 answer empty because I didn’t want to lose more time) and I finished my exam (well the lab finished and it closes automatically) with a good feeling.\nIn 1 hour approximately I received the email and…a PASS! Couldn’t be happier! Finally, a full exam without issues made me pass the exam!\nConclusion I can do a recap of what I learned about my experience with that exam and all the issues I experienced:\nIf you have any problem, contact your TA, don\u0026#8217;t waste time to wait for the manual or console to load. Test if backspace and shift keys work! I was concerned that these keys were blocked but I was able to use it and avoid the On-Screen keyboard, maybe it can work for you. Manage your time, manage your time. Everything you will read about this exam (or new ones) is about managing your time and I couldn\u0026#8217;t agree more. Use the erasable board! I used to write down each question number and a brief description, it helped me to know if I was running out of time and focus in the «easy» questions. Be aware of the dates, it was like a month ago since I scheduled the first attempt, so, if you are going to take it because your certification is expiring, be sure to schedule it in advance. I am not going sugar coat the fact that I was happy with the exam’s delivery because I suffered many issues…but, finally, with some patience it was paid-off.\nI hope this can be helpful for someone and I will write another post about the resources and how I prepared my self about this exam.\nThanks for reading!\nDan Belmonte\n","permalink":"https://dangaiden.github.io/2018-10-19-vcap6-dcv-deploy-exam-experience/","summary":"Hi! I am going to talk about my VCAP6-DCV Deploy exam experience.\nI thought about making a huge post about the VCAP6-DCV experience (resources, notes, etc.) but, I don’t want to overwhelm you know. Hence, I am going to make another post for that, hence this post will be shorter and more readable.\n1st attempt (Java error at the beginning) At September, 21st I sat down to take my first attempt in a VCAP exam.","title":"VCAP6-DCV Deploy exam experience"},{"content":"Some time ago, I was doing some clean up on VMs that have attached an image file, when I found a particular VM with strange behavior, each disk from the VM (local and RDM disks) was showing 0 MB of disk size:\nSo, what I did? First of all, I checked the guest OS and verified that it was up and running. So I was wondering how the guest OS seems correct but vSphere Web Client (I refreshed several times the browser) was showing no space in all disks and I verified in the Datastores that the .vmdk files were there.\nInvestigation I found in the Events tab for this VM, an error about a snapshot a few weeks ago that it wasn’t successfully created (from the 3rd party Software), so, maybe this problem is related to the snapshots?\nI verified the .vmx file configuration and check that was correct, also reviewing each descriptor file (vmdk), they were pointing to the disk data (vmdk-flat) that really exists in the datastore, so it couldn’t be a problem related to snapshots.\nAnyway, I logged out and logged in just to verify that it wasn’t a problem of the vSphere Web client but it showed the same (no luck), all disks (LUNs and disks) attached to that VM showed 0 MB .\nConclusion Well, it’s an easy solution, if you power-off the VM, unregister and register the VM in the vCenter then… it works! The VM appeared as usual (showing the allocated space for each disk).\nHence, which was the error? I can’t assure which was the error but maybe something happened to the .vmx file and unregistering and registering the VM again «repaired» the VM configuration file.\n","permalink":"https://dangaiden.github.io/2018-10-03-vm-showing-disk-size-is-0-mb/","summary":"Some time ago, I was doing some clean up on VMs that have attached an image file, when I found a particular VM with strange behavior, each disk from the VM (local and RDM disks) was showing 0 MB of disk size:\nSo, what I did? First of all, I checked the guest OS and verified that it was up and running. So I was wondering how the guest OS seems correct but vSphere Web Client (I refreshed several times the browser) was showing no space in all disks and I verified in the Datastores that the .","title":"VM showing disk size is 0 MB"},{"content":"A quick post talking about how to backup and restore a SQL database on Azure using SQL Server Management Studio (SSMS).\nFirst, you will need to install SSMS. You can download it here: https://go.microsoft.com/fwlink/?linkid=875802\nOnce installed, in order to access the database, you will need the server name where is installed. So, you will have to check the Server name in Azure Portal (you can also do it by Powershell of course):\nNow, open SSMS and access the server name (you gathered the information before):\nExport/Backup Database Once you logged in, select the database you want to export -\u0026gt; Export Data-tier Application\nIn the new window \u0026gt; Next \u0026gt; Select where do you want to save the DB (you can do it locally or in a Storage Account), in our case Local Disk:\nIn the Advanced tab you can choose which tables you want to export, we will Select All:\nFinally, we have a Summary of the process before exporting the database:\nThen it will start to export the database, depending on the size of your DB will take more or less time to export:\nFinally, we will have a file with .bacpac extension.\nImport/Restore database The process is almost the same but now we select Import Data-tier Application:\nContinue selecting the file with .bacpac extension we exported before:\nThen, with Database settings, here you can choose different options as you can do on the Azure portal:\nSummary of the imported database:\nFinally, it was imported successfully (it took a while for a 10 MB DB):\nIn consequence of the restore, it will appear the restored database (Restore_DB) in SSMS:\nTherefore, I posted a quick way to export and import a SQL database by using SSMS. You could use it as a backup (please, not in local) or for example, to overwrite changes from UAT to PROD.\n","permalink":"https://dangaiden.github.io/2018-09-14-azure-backup-and-restore-sql-db-using-ssms/","summary":"A quick post talking about how to backup and restore a SQL database on Azure using SQL Server Management Studio (SSMS).\nFirst, you will need to install SSMS. You can download it here: https://go.microsoft.com/fwlink/?linkid=875802\nOnce installed, in order to access the database, you will need the server name where is installed. So, you will have to check the Server name in Azure Portal (you can also do it by Powershell of course):","title":"Azure – Backup and restore SQL DB using SSMS"},{"content":"Hello there!\nA quick post talking about a new external PSC in vSphere 6.0 environments.\nAs you may now the vCenter product is composed by the PSC (Platform Services Controller) and the vCenter component.\nServices provided by each component: Platform Services Controller \u0026lt;td style=\u0026quot;width: 50%; height: 10px; text-align: center;\u0026quot;\u0026gt; \u0026lt;span style=\u0026quot;font-family: Didact Gothic;\u0026quot;\u0026gt;\u0026lt;strong\u0026gt;\u0026lt;span style=\u0026quot;background-color: #ffffff; color: #000000; font-size: 12pt;\u0026quot;\u0026gt;vCenter\u0026lt;/span\u0026gt;\u0026lt;/strong\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/td\u0026gt; vCenter Single Sign-On \u0026lt;td style=\u0026quot;width: 50%; height: 27px; text-align: center;\u0026quot;\u0026gt; \u0026lt;span style=\u0026quot;font-size: 10pt; font-family: Didact Gothic;\u0026quot;\u0026gt;PostgreSQL or SQL Express (in 6.0 version)\u0026lt;/span\u0026gt; \u0026lt;/td\u0026gt; VMware Certificate Authority \u0026lt;td style=\u0026quot;width: 50%; height: 27px; text-align: center;\u0026quot;\u0026gt; \u0026lt;span style=\u0026quot;font-size: 10pt; font-family: Didact Gothic;\u0026quot;\u0026gt;vSphere Web Client\u0026lt;/span\u0026gt; \u0026lt;/td\u0026gt; vSphere License Service \u0026lt;td style=\u0026quot;width: 50%; height: 27px; text-align: center;\u0026quot;\u0026gt; \u0026lt;span style=\u0026quot;font-size: 10pt; font-family: Didact Gothic;\u0026quot;\u0026gt;vSphere Client\u0026lt;/span\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td style=\u0026quot;width: 50%; height: 27px; text-align: center;\u0026quot;\u0026gt; \u0026lt;span style=\u0026quot;font-size: 10pt; font-family: Didact Gothic;\u0026quot;\u0026gt;vSphere ESXi Dump Collector\u0026lt;/span\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td style=\u0026quot;width: 50%; height: 10px; text-align: center;\u0026quot;\u0026gt; \u0026lt;span style=\u0026quot;font-size: 10pt; font-family: Didact Gothic;\u0026quot;\u0026gt;vSphere Syslog Collector\u0026lt;/span\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td style=\u0026quot;width: 50%; height: 27px; text-align: center;\u0026quot;\u0026gt; \u0026lt;span style=\u0026quot;font-size: 10pt; font-family: Didact Gothic;\u0026quot;\u0026gt;vSphere Auto Deploy\u0026lt;/span\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td style=\u0026quot;width: 50%; height: 32px; text-align: center;\u0026quot;\u0026gt; \u0026lt;span style=\u0026quot;font-size: 10pt; font-family: Didact Gothic;\u0026quot;\u0026gt;vSphere Update Manager\u0026lt;br /\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/td\u0026gt; Let\u0026#8217;s go to the point. I am going to repoint a vCenter with an embedded PSC (a vCSA called «pokecenter») to an external PSC I created in a Windows server called «digicenter» (I know is kinda original). Digicenter is already joined to the same SSO domain as pokecenter.\nNote: If you have any problem when adding an external PSC to an existing SSO domain, check cmsso-util unregister command in the vCSA appliance. In my case, I had to re-install it three times and in the last one, I used the command. More information in KB: https://kb.vmware.com/s/article/2114233\nIn the vCenter with embedded PSC, I will connect through SSH and repoint my vCenter to the external Windows PSC «digicenter».\nThe command is: cmsso-util reconfigure –-repoint-psc digicenter.pokemon.jp –username administrator –domain-name vsphere.local –passwd VMware1!\nNow, time to wait, it will take a couple of minutes as the text says: And after the pass, successful!\nHence, our vCenter «pokecenter» has an external PSC «digicenter». We can check it in vCenter \u0026gt; Manage \u0026gt; Settings \u0026gt; Advanced Settings:\nSo… If found some problems when repointing to the external PSC, make sure the time on both servers is the same (check NTP server), also DNS resolution of the external PSC. Give some time for the vSphere Client to initialize after the repointment.\nFinally, be patient, I found some errors (SSO errors about the external PSC) when login to the vSphere Web Client but, after waiting about 10 minutes finally it initialized up successfully.\n","permalink":"https://dangaiden.github.io/2018-08-20-vsphere-6-0-new-external-psc-within-existing-sso-domain/","summary":"Hello there!\nA quick post talking about a new external PSC in vSphere 6.0 environments.\nAs you may now the vCenter product is composed by the PSC (Platform Services Controller) and the vCenter component.\nServices provided by each component: Platform Services Controller \u0026lt;td style=\u0026quot;width: 50%; height: 10px; text-align: center;\u0026quot;\u0026gt; \u0026lt;span style=\u0026quot;font-family: Didact Gothic;\u0026quot;\u0026gt;\u0026lt;strong\u0026gt;\u0026lt;span style=\u0026quot;background-color: #ffffff; color: #000000; font-size: 12pt;\u0026quot;\u0026gt;vCenter\u0026lt;/span\u0026gt;\u0026lt;/strong\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/td\u0026gt; vCenter Single Sign-On \u0026lt;td style=\u0026quot;width: 50%; height: 27px; text-align: center;\u0026quot;\u0026gt; \u0026lt;span style=\u0026quot;font-size: 10pt; font-family: Didact Gothic;\u0026quot;\u0026gt;PostgreSQL or SQL Express (in 6.","title":"vSphere 6.0: New external PSC within existing SSO Domain"},{"content":"Today let’s talk about vSphere Network I/O Control (NIOC) version 3 (vSphere 6.0), it’s a feature in the vSphere Distributed Switch that allows you to control granularly the output/egress bandwidth from a VM network adapter level. Besides there are other useful options within NIOC capabilities, today, I will focus only in the network adapter bandwidth limit for VMs.\nPrerequisites: Enable the feature in the dvSwitch (in our case the one with Data Network):Scenario:\n2 VMs within 2 Networks (Portgroups in dvSwitch)\nKenshiroVM is a VM with Ubuntu that simulates traffic with iperf as a client.\nWin10Pro is a VM with iperf application configured as a server:\nObjective: We will look in how Network I/O control (NIOC) let us limit the bandwidth granularly from a Virtual Machine (KenshiroVM), so, we will limit the bandwidth for a single NIC and see if it really works.\nTesting: Lab time! I enabled NIOC in the dvSwitch that I have created for OS traffic (Data Network), dvSwitch is called “DSwitch_DataNW”. The other dvSwitch is “DSwitchMGMT” and NIOC is not enabled (no NIOC = no restrictions).\nAs I said before we have 2 networks:\nData Network: 10.10.6.0/24 Management Network: 192.168.1.0/24 Main steps: 1. Verify that the client (KenshiroVM) has no restrictions within the network. 2. Then, we will limit the Data Network adapter from KenshiroVM, launch iperf to simulate traffic and review the limitation configured. 3. Finally we will test iperf again but in the Management Network and review that we have no restrictions. 1. Currently, KenshiroVM has no restrictions configured (notice that in the blue rectangle there are no options for NIOC because that portgroup (Management) it’s located in another dvSwitch where we didn’t enable NIOC):\nIf we launch iperf command with 200Mbps on port 9999 from KenshiroVM:\nWe can see the traffic \u0026gt;on the destination (Win10Pro) on the Data Network Adapter (you can see the subnet in the screenshot):\nAlso, we can review it in vSphere Web Client (25 MBps = 200 Mbps):\n2. Now we are going to set a limit on KenshiroVM Data Network adapter to 88 Mbits:\nNow, we perform the same command with iperf on the client (KenshiroVM):\nEven pushing 200 Mbits through the Data Netowork Adapter using iperf, NIOC will limit the traffic to 88 Mbits as set before. Here is the traffic seen by Win10Pro Data Network adapter:\nIn KenshiroVM, iperf performed the transfer in 88 Mbps approximately:\n3. Now, if we do the same experiment (150 Mbps) but in the adapter where NIOC is not enabled:\nKenshiroVM confirmed that it performed at 150 Mbps approximately:\nConclusion As a result of using vSphere NIOC, we can granularly set limits in the bandwidth in a VM network adapter and it will obey the settings configured. It only works for outbound traffic, if you set a limit in a destination VM adapter, then, NIOC will not make any restrictions regarding the inbound traffic.\n","permalink":"https://dangaiden.github.io/2018-08-03-vsphere-network-i-o-control-nic-limit-bandwidth/","summary":"Today let’s talk about vSphere Network I/O Control (NIOC) version 3 (vSphere 6.0), it’s a feature in the vSphere Distributed Switch that allows you to control granularly the output/egress bandwidth from a VM network adapter level. Besides there are other useful options within NIOC capabilities, today, I will focus only in the network adapter bandwidth limit for VMs.\nPrerequisites: Enable the feature in the dvSwitch (in our case the one with Data Network):Scenario:","title":"vSphere Network I/O Control: NIC Limit bandwidth"},{"content":"It’s been a while since I posted something, but I was busy with university duties and to be honest I couldn’t spend time on publishing things but, here we are!\nFirst, I am currently studying for the VCAP6 – DCV Deployment Exam (3V0-623) and I am learning a lot with it, so maybe I will post more topics related with.\nToday I am going to talk about TCP/IP stacks in VMkernels (for vSphere 6). This is a thing that I didn’t care so much when I studied for the VCP6-DCV but now with the VCAP and all the time spent in the lab I thought that it was a great topic to talk!\nSo, get down to brass tacks.\nJust as a reminder, a VMkernel port is a port you create in an ESXi host to connect with the “outside world” (outside the host), so when you want to communicate two hosts, each host will have a VMkernel port to communicate.\nTCP/IP stacks A TCP/IP stack is a set of networking protocols (Do you remember the OSI Model?) used to provide networking support for the services that it handles. So you can use different stacks to support in different ways a service within the stack.\nA quick look at the services you can choose when creating a VMkernel port:\nI am not going to explain each one because we are going to focus on vMotion and Provisioning traffic.\nContinuing with TCP/IP stacks, when you create a new VMkernel in an ESXi host, you can choose which services do you want to enable: Regarding vMotion and Provisioning TCP/IP stacks you could do it in two ways:\nFor vMotion, for example, you can do the following (this is the most common configuration, Default TCP/IP stack with a service Enabled): Or (Dedicated TCP/IP stack): I must admit I always use the first one, the Default TCP/IP stack with the service enabled, so which should we use, the dedicated stack or the default one?\nDedicated TCP/IP stack options vMotion: It provides better isolation (more security), a separate set of buffers and sockets and avoids routing table conflicts than using the same TCP/IP Stack. Provisioning: Used for cold VM migration (migrate power-off VMs), cloning and snapshot traffic. So, I discussed with some people because I wanted to know which benefit could give you to use the dedicated TCP/IP stacks and this is what I gathered:\nFor vMotion: As a short answer, I would say, that if you need to do Cross vCenter vMotion you will need it because the dedicated stack gives you a Layer 3 VMkernel, meaning routing. With a dedicated stack, you can change the Gateway and DNS used in the default TCP/IP stack, meaning that you don’t have to use the same stack options that other services.do. For Provisioning traffic: If you have massive data coming from snapshots or cloning, is better that you use this dedicated stack instead of the default one. In the end, this is my recap and I hope it can help someone that is not familiar with it. Obviously, you could use the dedicated TCP/IP stack whenever you want but bear in mind that it will disable that service in the rest of the VMkernels.\nAnyway, if you think that I missed or want to discuss something, let me know in the comments!\n","permalink":"https://dangaiden.github.io/2018-07-23-vmkernel-vmotion-and-provisioning-dedicated-tcp-ip-stacks/","summary":"It’s been a while since I posted something, but I was busy with university duties and to be honest I couldn’t spend time on publishing things but, here we are!\nFirst, I am currently studying for the VCAP6 – DCV Deployment Exam (3V0-623) and I am learning a lot with it, so maybe I will post more topics related with.\nToday I am going to talk about TCP/IP stacks in VMkernels (for vSphere 6).","title":"VMkernel: vMotion and Provisioning in dedicated TCP/IP stacks"},{"content":"Hello everyone!\nIt’s been a while since I wrote something, but I was so busy with other things (University) and I wasn’t able to allocate time to write anything.\nToday I’m going to talk about an issue I found on Azure when trying to add new rules to some NSGs.\nTo create rules in Azure I used this script from TechNet Gallery: https://gallery.technet.microsoft.com/scriptcenter/Create-Azure-Network-5f5c5332\nProblem I was trying to add some rules in an NSG with the address 193.23.120.230/30 and, when I execute the code, the output was:\nSet-AzureRmNetworkSecurityGroup : Security rule has invalid Address prefix. Value provided: 193.23.120.230/30.\nStatusCode: 400\nReasonPhrase: Bad Request\nOperationID : ‘b2f7-b2f7-b2f7’\nAt line:4 char:55\n+ … efix 193.23.120.230/30 -SourcePortRange * | Set-AzureRmNetworkSecurityGroup\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+ CategoryInfo : CloseError: (:) [Set-AzureRmNetworkSecurityGroup], NetworkCloudException\n+ FullyQualifiedErrorId : Microsoft.Azure.Commands.Network.SetAzureNetworkSecurityGroupCommand\nTried again and again, and this only happened in certain NSGs, so well I thought there was a problem with the command line, I tried the same with the GUI and… the same.\nSolution Investigating the error it didn’t match with any of the new rules I was trying to add. Address 193.23.120.230/30 seems correct but if we use a subnet calculator, you will see this:\nThe right address should be deleting all ones after the netmask because it doesn’t care about what is after the netmask bits.\nThis means that the new address is 193.23.120.228/30 because we put zeros instead of ones after the netmask bits.\nSo, it seems a CIDN error! Seems that Azure let me add this rules in the past, but now it’s not accepting it so, if we change it the way that subnet calculator does, problem resolved!\nSolution? Had to delete the non-compliant CIDR rules and added the new ones CIDR compliant. Executed the same in other NSGs and worked like a charm.\nAll rules are finally shown in Azure Panel:\nWell, seems that Azure didn’t comply with CIDR addresses in the past and now it’s mandatory if it founds any non-compliant CIDR rule. An easy mistake that we can avoid checking our addresses before we try to add them to Azure.\nAnd that’s all, Happy New Year!\n","permalink":"https://dangaiden.github.io/2017-12-31-azure-error-adding-new-rule-nsg/","summary":"Hello everyone!\nIt’s been a while since I wrote something, but I was so busy with other things (University) and I wasn’t able to allocate time to write anything.\nToday I’m going to talk about an issue I found on Azure when trying to add new rules to some NSGs.\nTo create rules in Azure I used this script from TechNet Gallery: https://gallery.technet.microsoft.com/scriptcenter/Create-Azure-Network-5f5c5332\nProblem I was trying to add some rules in an NSG with the address 193.","title":"Azure – Error when adding new rule on NSG"},{"content":"Hello everyone!\nIt’s been a while since I wrote something, but I was so busy with other things (University) and I wasn’t able to allocate time to write anything.\nToday I’m going to talk about an issue I found on Azure when trying to add new rules to some NSGs.\nTo create rules in Azure I used this script from TechNet Gallery: https://gallery.technet.microsoft.com/scriptcenter/Create-Azure-Network-5f5c5332\nProblem I was trying to add some rules in an NSG with the address 193.23.120.230/30 and, when I execute the code, the output was:\nSet-AzureRmNetworkSecurityGroup : Security rule has invalid Address prefix. Value provided: 193.23.120.230/30.\nStatusCode: 400\nReasonPhrase: Bad Request\nOperationID : ‘b2f7-b2f7-b2f7’\nAt line:4 char:55\n+ … efix 193.23.120.230/30 -SourcePortRange * | Set-AzureRmNetworkSecurityGroup\n+ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+ CategoryInfo : CloseError: (:) [Set-AzureRmNetworkSecurityGroup], NetworkCloudException\n+ FullyQualifiedErrorId : Microsoft.Azure.Commands.Network.SetAzureNetworkSecurityGroupCommand\nTried again and again, and this only happened in certain NSGs, so well I thought there was a problem with the command line, I tried the same with the GUI and… the same.\nSolution Investigating the error it didn’t match with any of the new rules I was trying to add. Address 193.23.120.230/30 seems correct but if we use a subnet calculator, you will see this:\nThe right address should be deleting all ones after the netmask because it doesn’t care about what is after the netmask bits.\nThis means that the new address is 193.23.120.228/30 because we put zeros instead of ones after the netmask bits.\nSo, it seems a CIDN error! Seems that Azure let me add this rules in the past, but now it’s not accepting it so, if we change it the way that subnet calculator does, problem resolved!\nSolution? Had to delete the non-compliant CIDR rules and added the new ones CIDR compliant. Executed the same in other NSGs and worked like a charm.\nAll rules are finally shown in Azure Panel:\nWell, seems that Azure didn’t comply with CIDR addresses in the past and now it’s mandatory if it founds any non-compliant CIDR rule. An easy mistake that we can avoid checking our addresses before we try to add them to Azure.\nAnd that’s all, Happy New Year!\n","permalink":"https://dangaiden.github.io/2017-12-31-azure-error-adding-new-rule-nsg_backup/","summary":"Hello everyone!\nIt’s been a while since I wrote something, but I was so busy with other things (University) and I wasn’t able to allocate time to write anything.\nToday I’m going to talk about an issue I found on Azure when trying to add new rules to some NSGs.\nTo create rules in Azure I used this script from TechNet Gallery: https://gallery.technet.microsoft.com/scriptcenter/Create-Azure-Network-5f5c5332\nProblem I was trying to add some rules in an NSG with the address 193.","title":"Azure – Error when adding new rule on NSG"},{"content":"I am going to start talking about the exam VCP6-DCV from VMware. The main resource you should use is the VMware site: http://bit.ly/1PLshWR\nThere you can check a path to achieve VCP6-DCV (there is a newer version VCP6.5-DCV). I took path 1, as I wasn’t certified.\nLater, I took one official training course, VMware vSphere: Install, Configure, Manage [V6].\nNext, I passed the vSphere 6 Foundations Exam (2V0-620) months ago and finally I did VMware Certified Professional 6 – Data Center Virtualization Exam (2V0-621).\nAnd finally, last week I passed!\nThe first exam is an introduction of VMware and I didn’t find it difficult. The second one is more difficult and there is a lot of content to study..\nHere you have a list of the resources I used for VCP6-DCV (2V0-621):\nPaid resources:\nOnline videos in Pluralsight: http://bit.ly/1p7bt1E Online videos in CBT Nuggets: http://bit.ly/2w1Axif You can use the free trial period and try to study as faster as you can.\nFree resources:\nVladan VCP6-DCV study guide: https://www.vladan.fr/vcp6-dcv/ vBrownBag study guide: https://goo.gl/jcbpSH Veeam study guide: https://go.veeam.com/vmware-certification-vcp6-dcv-study-guide-exam-blueprint But, In fact, what really helped me was to do the Hands-on-Lab (HOLs) and test things in my own lab (create your own ESXi hosts, vCenter, create a cluster, test DRS, HA, FT and so on).\nAnd well, that’s all!\n","permalink":"https://dangaiden.github.io/2017-09-03-vcp6-dcv-achieved/","summary":"I am going to start talking about the exam VCP6-DCV from VMware. The main resource you should use is the VMware site: http://bit.ly/1PLshWR\nThere you can check a path to achieve VCP6-DCV (there is a newer version VCP6.5-DCV). I took path 1, as I wasn’t certified.\nLater, I took one official training course, VMware vSphere: Install, Configure, Manage [V6].\nNext, I passed the vSphere 6 Foundations Exam (2V0-620) months ago and finally I did VMware Certified Professional 6 – Data Center Virtualization Exam (2V0-621).","title":"VCP6-DCV achieved!"},{"content":"Backup and restore etcd data. Look up the value for the key cluster.name in the etcd cluster:\nETCDCTL_API=3 etcdctl get cluster.name \u0026ndash;endpoints=https://10.0.1.101:2379 \u0026ndash;cacert=/home/cloud_user/etcd-certs/etcd-ca.pem \u0026ndash;cert=/home/cloud_user/etcd-certs/etcd-server.crt \u0026ndash;key=/home/cloud_user/etcd-certs/etcd-server.key\nThe returned value should be beebox. Back up etcd using etcdctl and the provided etcd certificates: ETCDCTL_API=3 etcdctl snapshot save /home/cloud_user/etcd_backup.db \u0026ndash;endpoints=https://10.0.1.101:2379 \u0026ndash;cacert=/home/cloud_user/etcd-certs/etcd-ca.pem \u0026ndash;cert=/home/cloud_user/etcd-certs/etcd-server.crt \u0026ndash;key=/home/cloud_user/etcd-certs/etcd-server.key\nReset etcd by removing all existing etcd data: sudo systemctl stop etcd sudo rm -rf /var/lib/etcd Restore the etcd Data from the Backup Restore the etcd data from the backup (this command spins up a temporary etcd cluster, saving the data from the backup file to a new data directory in the same location where the previous data directory was): sudo ETCDCTL_API=3 etcdctl snapshot restore /home/cloud_user/etcd_backup.db \\ --initial-cluster etcd-restore=https://10.0.1.101:2380 \\ --initial-advertise-peer-urls https://10.0.1.101:2380 \\ --name etcd-restore \\ --data-dir /var/lib/etcd ##Set ownership on the new data directory:\nsudo chown -R etcd:etcd /var/lib/etcd\nStart etcd:\nsudo systemctl start etcd\nVerify the restored data is present by looking up the value for the key cluster.name again:\nETCDCTL_API=3 etcdctl get cluster.name \u0026ndash;endpoints=https://10.0.1.101:2379 \u0026ndash;cacert=/home/cloud_user/etcd-certs/etcd-ca.pem \u0026ndash;cert=/home/cloud_user/etcd-certs/etcd-server.crt \u0026ndash;key=/home/cloud_user/etcd-certs/etcd-server.key\nThe returned value should be beebox. ","permalink":"https://dangaiden.github.io/post/2021/k8s-etcd_restore/","summary":"Backup and restore etcd data. Look up the value for the key cluster.name in the etcd cluster:\nETCDCTL_API=3 etcdctl get cluster.name \u0026ndash;endpoints=https://10.0.1.101:2379 \u0026ndash;cacert=/home/cloud_user/etcd-certs/etcd-ca.pem \u0026ndash;cert=/home/cloud_user/etcd-certs/etcd-server.crt \u0026ndash;key=/home/cloud_user/etcd-certs/etcd-server.key\nThe returned value should be beebox. Back up etcd using etcdctl and the provided etcd certificates: ETCDCTL_API=3 etcdctl snapshot save /home/cloud_user/etcd_backup.db \u0026ndash;endpoints=https://10.0.1.101:2379 \u0026ndash;cacert=/home/cloud_user/etcd-certs/etcd-ca.pem \u0026ndash;cert=/home/cloud_user/etcd-certs/etcd-server.crt \u0026ndash;key=/home/cloud_user/etcd-certs/etcd-server.key\nReset etcd by removing all existing etcd data: sudo systemctl stop etcd sudo rm -rf /var/lib/etcd Restore the etcd Data from the Backup Restore the etcd data from the backup (this command spins up a temporary etcd cluster, saving the data from the backup file to a new data directory in the same location where the previous data directory was): sudo ETCDCTL_API=3 etcdctl snapshot restore /home/cloud_user/etcd_backup.","title":""},{"content":"Upgrade the Control Plane Upgrade kubeadm: [cloud_user@k8s-control]$ sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y \u0026ndash;allow-change-held-packages kubeadm=1.21.1-00\nMake sure it upgraded correctly: [cloud_user@k8s-control]$ kubeadm version\nDrain the control plane node: [cloud_user@k8s-control]$ kubectl drain k8s-control \u0026ndash;ignore-daemonsets\nPlan the upgrade: [cloud_user@k8s-control]$ sudo kubeadm upgrade plan v1.21.1\nUpgrade the control plane components: [cloud_user@k8s-control]$ sudo kubeadm upgrade apply v1.21.1\nUpgrade kubelet and kubectl on the control plane node: [cloud_user@k8s-control]$ sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y \u0026ndash;allow-change-held-packages kubelet=1.21.1-00 kubectl=1.21.1-00\nRestart kubelet: [cloud_user@k8s-control]$ sudo systemctl daemon-reload\n[cloud_user@k8s-control]$ sudo systemctl restart kubelet\nUncordon the control plane node: [cloud_user@k8s-control]$ kubectl uncordon k8s-control\nVerify the control plane is working: [cloud_user@k8s-control]$ kubectl get nodes\nIf it shows a NotReady status, run the command again after a minute or so. It should become Ready.\nUpgrade the Worker Nodes Note: In a real-world scenario, you should not perform upgrades on all worker nodes at the same time. Make sure enough nodes are available at any given time to provide uninterrupted service. Worker Node Run the following on the control plane node to drain worker node 1: [cloud_user@k8s-control]$ kubectl drain k8s-worker1 --ignore-daemonsets --force You may get an error message that certain pods couldn't be deleted, which is fine. In a new terminal window, log in to worker node 1: ssh cloud_user@\u0026lt;WORKER_1_PUBLIC_IP_ADDRESS\u0026gt; Upgrade kubeadm on worker node 1: [cloud_user@k8s-worker1]$ sudo apt-get update \u0026amp;\u0026amp; \\ sudo apt-get install -y --allow-change-held-packages kubeadm=1.21.1-00 [cloud_user@k8s-worker1]$ kubeadm version Back on worker node 1, upgrade the kubelet configuration on the worker node: [cloud_user@k8s-worker1]$ sudo kubeadm upgrade node Upgrade kubelet and kubectl on worker node 1: [cloud_user@k8s-worker1]$ sudo apt-get update \u0026amp;\u0026amp; \\ sudo apt-get install -y --allow-change-held-packages kubelet=1.21.1-00 kubectl=1.21.1-00 Restart kubelet: [cloud_user@k8s-worker1]$ sudo systemctl daemon-reload [cloud_user@k8s-worker1]$ sudo systemctl restart kubelet From the control plane node, uncordon worker node 1: [cloud_user@k8s-control]$ kubectl uncordon k8s-worker1 ","permalink":"https://dangaiden.github.io/post/2021/k8scluster-upgrade_version/","summary":"Upgrade the Control Plane Upgrade kubeadm: [cloud_user@k8s-control]$ sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y \u0026ndash;allow-change-held-packages kubeadm=1.21.1-00\nMake sure it upgraded correctly: [cloud_user@k8s-control]$ kubeadm version\nDrain the control plane node: [cloud_user@k8s-control]$ kubectl drain k8s-control \u0026ndash;ignore-daemonsets\nPlan the upgrade: [cloud_user@k8s-control]$ sudo kubeadm upgrade plan v1.21.1\nUpgrade the control plane components: [cloud_user@k8s-control]$ sudo kubeadm upgrade apply v1.21.1\nUpgrade kubelet and kubectl on the control plane node: [cloud_user@k8s-control]$ sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y \u0026ndash;allow-change-held-packages kubelet=1.","title":""},{"content":"Install Packages in all nodes Log into the Control Plane Node (Note: The following steps must be performed on all three nodes.). Create configuration file for containerd: cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/containerd.conf overlay br_netfilter EOF Load modules: sudo modprobe overlay sudo modprobe br_netfilter Set system configurations for Kubernetes networking: cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-ip6tables = 1 EOF Apply new settings: sudo sysctl --system Install containerd: sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y containerd Create default configuration file for containerd: sudo mkdir -p /etc/containerd Generate default containerd configuration and save to the newly created default file: sudo containerd config default | sudo tee /etc/containerd/config.toml Restart containerd to ensure new configuration file usage: sudo systemctl restart containerd Verify that containerd is running. sudo systemctl status containerd Disable swap: sudo swapoff -a Disable swap on startup in /etc/fstab: sudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab Install dependency packages: sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y apt-transport-https curl Download and add GPG key: curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - Add Kubernetes to repository list: cat \u0026lt;\u0026lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list deb https://apt.kubernetes.io/ kubernetes-xenial main EOF Update package listings: sudo apt-get update Install Kubernetes packages (Note: If you get a dpkg lock message, just wait a minute or two before trying the command again): sudo apt-get install -y kubelet=1.21.0-00 kubeadm=1.21.0-00 kubectl=1.21.0-00 Turn off automatic updates: sudo apt-mark hold kubelet kubeadm kubectl Initialize the Cluster Initialize the Kubernetes cluster on the control plane node using kubeadm (Note: This is only performed on the Control Plane Node): sudo kubeadm init \u0026ndash;pod-network-cidr 192.168.0.0/16 \u0026ndash;kubernetes-version 1.21.0\nSet kubectl access: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config kubectl get nodes\nInstall the Calico Network Add-On On the Control Plane Node, install Calico Networking:\nkubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml\nCheck status of the control plane node:\nkubectl get nodes\nJoin the Worker Nodes to the Cluster In the Control Plane Node, create the token and copy the kubeadm join command (NOTE:The join command can also be found in the output from kubeadm init command):\nkubeadm token create \u0026ndash;print-join-command OUTPUT: kubeadm join 10.0.1.101:6443 \u0026ndash;token 2gbzsg.6hwes2nc3d8pyt28 \u0026ndash;discovery-token-ca-cert-hash sha256:2a3d93fb56aa227353ec2810f46739701c1712495fabe2c69db9ee3df48c3317\nIn both Worker Nodes, paste the kubeadm join command to join the cluster. Use sudo to run it as root:\nsudo kubeadm join \u0026hellip;\nIn the Control Plane Node, view cluster status (Note: You may have to wait a few moments to allow all nodes to become ready):\nkubectl get nodes\n","permalink":"https://dangaiden.github.io/post/2021/kubernetes-cluster-installation-config/","summary":"Install Packages in all nodes Log into the Control Plane Node (Note: The following steps must be performed on all three nodes.). Create configuration file for containerd: cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/containerd.conf overlay br_netfilter EOF Load modules: sudo modprobe overlay sudo modprobe br_netfilter Set system configurations for Kubernetes networking: cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-ip6tables = 1 EOF Apply new settings: sudo sysctl --system Install containerd: sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y containerd Create default configuration file for containerd: sudo mkdir -p /etc/containerd Generate default containerd configuration and save to the newly created default file: sudo containerd config default | sudo tee /etc/containerd/config.","title":""},{"content":"Quick guide to install OS within VMs 3 Virtual machines configured and ready Here is a quick \u0026ldquo;guide\u0026rdquo; I made for myself to create a VM, configure RHEL and have ready 3 VMs with the OS configured to start playing with Kubernetes.\nLink to Insta\n","permalink":"https://dangaiden.github.io/post/2021/note-about-k8s-part1/","summary":"Quick guide to install OS within VMs 3 Virtual machines configured and ready Here is a quick \u0026ldquo;guide\u0026rdquo; I made for myself to create a VM, configure RHEL and have ready 3 VMs with the OS configured to start playing with Kubernetes.\nLink to Insta","title":""},{"content":"Introduction Here, I\u0026rsquo;ll explain you how to upgrade your Traefik version sitting on a Kubernetes cluster (version 1.23.1) on AWS.\nIn my case, I was moving from Traefik 2.1 to 2.5, but this could be more or less translated between other versions.\nNote: This is the way I performed the migration of Traefik and there are other ways to do it so YMML.\nSteps overview Check 2.4 and 2.5 releases for breaking changes Reference: https://doc.traefik.io/traefik/migration/v2/#v23-to-v24 Reference: https://doc.traefik.io/traefik/migration/v2/#v24-to-v25\nCheck helm chart releases for breaking changes Fix your custom values for all your deployment Apply CRDs (Remember Helm doesn\u0026rsquo;t manage CRDs) Deploy a new release of Traefik with Helm (installing the final Traefik version that we want to move) Perform your DNS changes pointing to the new ELB (External Load Balancer) Check your monitoring for new traffic When you feel comfortable, delete the previous release! ","permalink":"https://dangaiden.github.io/post/2022/migrating-your-traefik-deployment-managed-by-helm/","summary":"Introduction Here, I\u0026rsquo;ll explain you how to upgrade your Traefik version sitting on a Kubernetes cluster (version 1.23.1) on AWS.\nIn my case, I was moving from Traefik 2.1 to 2.5, but this could be more or less translated between other versions.\nNote: This is the way I performed the migration of Traefik and there are other ways to do it so YMML.\nSteps overview Check 2.4 and 2.5 releases for breaking changes Reference: https://doc.","title":""},{"content":"Traefik currently seats on a custom version owned by us but the patch was merged into the upstream repository and needs to be back to the main docker image along with the upgrade to \u0026gt; 2.5\nSteps Check 2.4 and 2.5 releases for breaking changes Reference: https://doc.traefik.io/traefik/migration/v2/#v23-to-v24 Reference: https://doc.traefik.io/traefik/migration/v2/#v24-to-v25\nServersTransport -\u0026gt; Update RBAC and CRD (To check in Helm chart for 2.4) This is done by the chart as it updates everything needed.\nK8S CrossNamespace\nK8S ExternalName Service\nDefined in the values.yaml which will be applied for the upgrade:\n![[Pasted image 20220127095012.png]]\nNon-ASCII Domain Names Update RBAC and CRD definitions. Headers middleware: ssl redirect options \u0026amp; accessControlAllowOrigin X.509 CommonName API version: The extensions/v1beta1 API Version should now be replaced either by networking.k8s.io/v1beta1 or by networking.k8s.io/v1 (as of Kubernetes v1.19+) Paysites (prod and staging)\nCurrent: helm.sh/chart=traefik-9.13.0 Containers: traefik2-frontend: Image: javipolo/traefik:2.3.3-router-metrics We need to put: traefik v2.5.6 ❯ helm search repo traefik -l | grep -i 2.5.6 traefik/traefik 10.9.1 2.5.6 A Traefik based Kubernetes ingress controller Check helm chart releases for breaking changes https://wiki.cac.washington.edu/display/MCI/Ingress+Resource+Changes+Kubernetes+1.19+through+1.21\nhttps://kubernetes.io/docs/reference/using-api/deprecation-guide/\nChanges in Ingress apiVersion make the object to be defined different:\nSpecific Changes to Ingress spec.backend is renamed to spec.defaultBackend\nThe backend serviceName field is renamed to service.name\nNumeric backend servicePort fields are renamed to service.port.number\nString backend servicePort fields are renamed to service.port.name\nI changed different YAML manifests where the backend service had a different structure. For each project I changed all the manifests.\n![[GH_changes_SYS-1556.png]]\nUpgrade tag in staging and deploy to paysites staging New parameters needed: ![[Pasted image 20220127095012.png]]\n\u0026amp;\n![[Pasted image 20220127094937.png]]\nLatest 2.5.4 version in is:\n❯ helm search repo traefik -l | grep -i 2.5.6 traefik/traefik 10.9.1 2.5.6 A Traefik based Kubernetes ingress controller Destination chart: \u0026gt; helm show values traefik/traefik --version 10.2.0 Helm uses the app version as tag so the process to upgrade is:\nhelm upgrade -i traefik2 --namespace staging -f values.yaml traefik/traefik This installs the latest version from Traefik!\nWhere values.yaml is the file where we override for our own values.\nhelm upgrade -i traefik2 -n staging -f values.yaml traefik/traefik --version 10.9.1 Check the traefik dashboard (http://127.0.0.1:9000) to see the general status of Traefik objects:\nkubectl port-forward deployment/traefik2 -n staging 9000:9000 Added new middleware within the same templates with - Example\n{{- $name := include \u0026#34;chart.name\u0026#34; . -}} apiVersion: traefik.containo.us/v1alpha1 kind: Middleware metadata: name: \u0026#34;whitelist-{{ $name }}\u0026#34; spec: ipWhiteList: ipStrategy: depth: {{ .Values.whitelist.depth }} sourceRange: {{- range .Values.whitelist.ips }} - {{ . }} {{- end }} --- apiVersion: traefik.containo.us/v1alpha1 kind: Middleware metadata: name: \u0026#34;{{ .Release.Namespace }}-whitelist-{{ $name }}\u0026#34; spec: ipWhiteList: ipStrategy: depth: {{ .Values.rssWhiteList.depth }} sourceRange: {{- range .Values.rssWhiteList.ips }} - {{ . }} {{- end }} Deploy your new ingresses that are pointing to your new apiVersion networking.k8s.io/v1 Once deployed, you probably can check that you haven\u0026rsquo;t missed anything by doing something like.\n❯ k get ingress -o yaml -A | grep apiVersion: | more apiVersion: v1 - apiVersion: networking.k8s.io/v1 - apiVersion: networking.k8s.io/v1 - apiVersion: networking.k8s.io/v1 - apiVersion: networking.k8s.io/v1 . . . Upgrade CRDs manually!!! How snippets work Great gist \u0026ndash;\u0026gt; Useful\nTraefik CRDs reference: https://github.com/traefik/traefik/blob/v2.5/docs/content/reference/dynamic-configuration/kubernetes-crd.md\nCRDs to be updated, in particular these definitions and the RBAC one\nCheck current CRDs from Traefik ❯ k get crd | grep traefik ingressroutes.traefik.containo.us 2020-10-16T13:49:48Z ingressroutetcps.traefik.containo.us 2020-10-16T13:49:48Z ingressrouteudps.traefik.containo.us 2020-10-16T13:49:48Z middlewares.traefik.containo.us 2020-10-16T13:49:48Z tlsoptions.traefik.containo.us 2020-10-16T13:49:48Z tlsstores.traefik.containo.us 2020-10-16T13:49:48Z traefikservices.traefik.containo.us 2020-10-16T13:49:48Z Exported Traefik CRDs k get crd -A | grep traefik | awk \u0026#39;{ print $1 }\u0026#39; | xargs -I % /bin/bash -c \u0026#39;kubectl get crd % -o yaml \u0026gt; %.yaml\u0026#39; After being sure that I am in the correct context and those are the CRDs I want to apply ❯ ./CRDs.sh Warning: resource customresourcedefinitions/ingressroutes.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/ingressroutes.traefik.containo.us configured Warning: resource customresourcedefinitions/ingressroutetcps.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/ingressroutetcps.traefik.containo.us configured Warning: resource customresourcedefinitions/ingressrouteudps.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/ingressrouteudps.traefik.containo.us configured Warning: resource customresourcedefinitions/middlewares.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/middlewares.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/middlewaretcps.traefik.containo.us created customresourcedefinition.apiextensions.k8s.io/serverstransports.traefik.containo.us created Warning: resource customresourcedefinitions/tlsoptions.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/tlsoptions.traefik.containo.us configured Warning: resource customresourcedefinitions/tlsstores.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/tlsstores.traefik.containo.us configured Warning: resource customresourcedefinitions/traefikservices.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/traefikservices.traefik.containo.us configured clusterrole.rbac.authorization.k8s.io/traefik-ingress-controller created clusterrolebinding.rbac.authorization.k8s.io/traefik-ingress-controller created After the CRDs are installed, I have a couple more: ❯ k get crd | grep traefik ingressroutes.traefik.containo.us 2020-10-16T13:49:48Z ingressroutetcps.traefik.containo.us 2020-10-16T13:49:48Z ingressrouteudps.traefik.containo.us 2020-10-16T13:49:48Z middlewares.traefik.containo.us 2020-10-16T13:49:48Z middlewaretcps.traefik.containo.us 2022-02-22T10:05:26Z serverstransports.traefik.containo.us 2022-02-22T10:05:28Z tlsoptions.traefik.containo.us 2020-10-16T13:49:48Z tlsstores.traefik.containo.us 2020-10-16T13:49:48Z traefikservices.traefik.containo.us 2020-10-16T13:49:48Z Now applying the upgrade with Helm to v.2.5.6 (chart version is 10.9.1) helm upgrade -i traefik2 -n staging -f values.yaml traefik/traefik --version 10.9.1 After applying the upgrade, all went well although some redirections didn\u0026rsquo;t work in the staging environment I applied it. Checked the logs and saw some middlewares were missing: {\u0026#34;entryPointName\u0026#34;:\u0026#34;websecure\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;error\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;middleware \\\u0026#34;staging-blue-auth-pass-blacked-frontend-canary-redesign@kubernetescrd\\\u0026#34; does not exist\u0026#34;,\u0026#34;routerName\u0026#34;:\u0026#34;tushyraw-frontend-blue-redesign-new-join-form-staging-blue-staging-blue-members-tushyraw-com-joinnow@kubernetes\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-02-22T13:10:37Z\u0026#34;} {\u0026#34;entryPointName\u0026#34;:\u0026#34;websecure\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;error\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;middleware \\\u0026#34;staging-blue-auth-pass-blacked-frontend-canary-redesign@kubernetescrd\\\u0026#34; does not exist\u0026#34;,\u0026#34;routerName\u0026#34;:\u0026#34;slayed-frontend-blue-redesign-new-join-form-staging-blue-staging-blue-members-slayed-com-joinnow@kubernetes\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-02-22T13:10:37Z\u0026#34;} {\u0026#34;entryPointName\u0026#34;:\u0026#34;websecure\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;error\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;middleware \\\u0026#34;staging-auth-pass-blacked-frontend-canary-redesign@kubernetescrd\\\u0026#34; does not exist\u0026#34;,\u0026#34;routerName\u0026#34;:\u0026#34;deeper-frontend-redesign-new-join-form-staging-staging-members-deeper-com-joinnow@kubernetes\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-02-22T13:10:37Z\u0026#34;} {\u0026#34;entryPointName\u0026#34;:\u0026#34;websecure\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;error\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;middleware \\\u0026#34;staging-auth-pass-blacked-frontend-canary-redesign@kubernetescrd\\\u0026#34; does not exist\u0026#34;,\u0026#34;routerName\u0026#34;:\u0026#34;vixen-frontend-redesign-new-join-form-staging-staging-members-vixen-com-joinnow@kubernetes\u0026#34;,\u0026#34;time\u0026#34;:\u0026#34;2022-02-22T13:10:37Z\u0026#34;} After some investigation, I found that in the previous version of Traefik (2.3.3) the middlewares were already missing, so it wasn\u0026rsquo;t a problem with the upgrade.\nIn conclusion, the newer version of Traefik (2.5.6) simply gave an incorrect redirection for a Router when a middleware was missing but in the previous version don\u0026rsquo;t.\nIn the end, I created the missing middlewares and redirections were working as expected.\nUpgrading to 2.6.1 ❯ ./CRDs_2_6.sh customresourcedefinition.apiextensions.k8s.io/ingressroutes.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/ingressroutetcps.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/ingressrouteudps.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/middlewares.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/middlewaretcps.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/serverstransports.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/tlsoptions.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/tlsstores.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/traefikservices.traefik.containo.us configured clusterrole.rbac.authorization.k8s.io/traefik-ingress-controller unchanged clusterrolebinding.rbac.authorization.k8s.io/traefik-ingress-controller unchanged\n❯ helm search repo traefik -l | grep -i 2.6.1 traefik/traefik 10.14.2 2.6.1 A Traefik based Kubernetes ingress controller\nChange values.yaml tag for \u0026ldquo;2.6.1\u0026rdquo; Then:\nhelm upgrade -i traefik2 -n staging -f values.yaml traefik/traefik --version 10.14.2 --dry-run Real update:\n❯ helm upgrade -i traefik2 -n staging -f values.yaml traefik/traefik --version 10.14.2 Release \u0026#34;traefik2\u0026#34; has been upgraded. Happy Helming! NAME: traefik2 LAST DEPLOYED: Wed Feb 23 16:42:11 2022 NAMESPACE: staging STATUS: deployed REVISION: 29 TEST SUITE: None ","permalink":"https://dangaiden.github.io/post/2022/sys-1556-traefik-2.6-upgrade.md/","summary":"Traefik currently seats on a custom version owned by us but the patch was merged into the upstream repository and needs to be back to the main docker image along with the upgrade to \u0026gt; 2.5\nSteps Check 2.4 and 2.5 releases for breaking changes Reference: https://doc.traefik.io/traefik/migration/v2/#v23-to-v24 Reference: https://doc.traefik.io/traefik/migration/v2/#v24-to-v25\nServersTransport -\u0026gt; Update RBAC and CRD (To check in Helm chart for 2.4) This is done by the chart as it updates everything needed.","title":""},{"content":"","permalink":"https://dangaiden.github.io/post/2022/untitled/","summary":"","title":""},{"content":"Apply the correct CRDs for 2.5 and 2.6 versions: Great gist \u0026ndash;\u0026gt; Useful\nTraefik CRDs reference: https://github.com/traefik/traefik/blob/v2.5/docs/content/reference/dynamic-configuration/kubernetes-crd.md\n~/Traefik_upgrade/backup_220222_2_5v  ./CRDs_2_5.sh  ✔ │ 17:29:32 Warning: resource customresourcedefinitions/ingressroutes.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/ingressroutes.traefik.containo.us configured Warning: resource customresourcedefinitions/ingressroutetcps.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/ingressroutetcps.traefik.containo.us configured Warning: resource customresourcedefinitions/ingressrouteudps.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/ingressrouteudps.traefik.containo.us configured Warning: resource customresourcedefinitions/middlewares.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/middlewares.traefik.containo.us configured Warning: resource customresourcedefinitions/middlewaretcps.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/middlewaretcps.traefik.containo.us configured Warning: resource customresourcedefinitions/serverstransports.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/serverstransports.traefik.containo.us configured Warning: resource customresourcedefinitions/tlsoptions.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/tlsoptions.traefik.containo.us configured Warning: resource customresourcedefinitions/tlsstores.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/tlsstores.traefik.containo.us configured Warning: resource customresourcedefinitions/traefikservices.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/traefikservices.traefik.containo.us configured clusterrole.rbac.authorization.k8s.io/traefik-ingress-controller created clusterrolebinding.rbac.authorization.k8s.io/traefik-ingress-controller created Then immediately the changes for v.2.6 ~/Traefik_upgrade/backup_230222_2_6v  ./CRDs_2_6.sh  ✔ │ 17:33:52 customresourcedefinition.apiextensions.k8s.io/ingressroutes.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/ingressroutetcps.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/ingressrouteudps.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/middlewares.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/middlewaretcps.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/serverstransports.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/tlsoptions.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/tlsstores.traefik.containo.us configured customresourcedefinition.apiextensions.k8s.io/traefikservices.traefik.containo.us configured clusterrole.rbac.authorization.k8s.io/traefik-ingress-controller unchanged clusterrolebinding.rbac.authorization.k8s.io/traefik-ingress-controller unchanged Now let\u0026rsquo;s install a new release of Traefik in parallel ~/K/paysite-systems/k/p/n/d/traefik2-frontend │ SYS-1628/Traefikv2_upgrade  date;helm install traefik2 -f values.yaml traefik/traefik --version 10.16.0 --debug Thu Apr 21 17:37:41 CEST 2022 install.go:178: [debug] Original chart version: \u0026#34;10.16.0\u0026#34; install.go:199: [debug] CHART PATH: /Users/dba7x/Library/Caches/helm/repository/traefik-10.16.0.tgz client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD ingressroutes.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD ingressroutetcps.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD ingressrouteudps.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD middlewares.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD middlewaretcps.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD serverstransports.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD tlsoptions.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD tlsstores.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD traefikservices.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 6 resource(s) client.go:299: [debug] Starting delete for \u0026#34;traefik2-dashboard\u0026#34; IngressRoute client.go:328: [debug] ingressroutes.traefik.containo.us \u0026#34;traefik2-dashboard\u0026#34; not found client.go:128: [debug] creating 1 resource(s) NAME: traefik2 LAST DEPLOYED: Thu Apr 21 17:37:47 2022 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None The new LB has been created: ![[Pasted image 20220421174244.png]]\nProceed to check which Public IPs are using the new LB as we\u0026rsquo;ll use it later:\n~/Kodify/paysite-systems/kubernetes/prod/namespace/default/traefik2-frontend │ SYS-1628/Traefikv2_upgrade  dig +short aee7021d96f3f4e30ad2d12442baff49-641409121.us-east-1.elb.amazonaws.com  INT ✘ │ 17:45:18 52.200.222.41 34.230.158.253 35.169.146.177 Now I will tweak my hosts file to see if I can reach some endpoints (ingresses) and check with cURL: curl -Isv https://vixen.com  ✔ │ 18:02:47 * Trying 52.200.222.41:443... * Connected to vixen.com (52.200.222.41) port 443 (#0) * ALPN, offering h2 * ALPN, offering http/1.1 * successfully set certificate verify locations: * CAfile: /etc/ssl/cert.pem * CApath: none * (304) (OUT), TLS handshake, Client hello (1): * LibreSSL SSL_connect: SSL_ERROR_SYSCALL in connection to vixen.com:443 * Closing connection 0 ","permalink":"https://dangaiden.github.io/post/2022/upgrade-traefik-to-v261/","summary":"Apply the correct CRDs for 2.5 and 2.6 versions: Great gist \u0026ndash;\u0026gt; Useful\nTraefik CRDs reference: https://github.com/traefik/traefik/blob/v2.5/docs/content/reference/dynamic-configuration/kubernetes-crd.md\n~/Traefik_upgrade/backup_220222_2_5v  ./CRDs_2_5.sh  ✔ │ 17:29:32 Warning: resource customresourcedefinitions/ingressroutes.traefik.containo.us is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically. customresourcedefinition.apiextensions.k8s.io/ingressroutes.traefik.containo.us configured Warning: resource customresourcedefinitions/ingressroutetcps.traefik.containo.us is missing the kubectl.","title":""},{"content":"Traefik upgrade The overall process Context Upgrading traefik from 1.7.26 (chart traefik-1.87.7) to 2.5.6 (chart 10.9.1) isn\u0026rsquo;t possible because of labels immutability: ❯ helm upgrade -i traefik -n default -f values.yaml traefik/traefik --version 10.9.1 --force --debug history.go:56: [debug] getting history for release traefik upgrade.go:139: [debug] preparing upgrade for traefik upgrade.go:147: [debug] performing update for traefik upgrade.go:319: [debug] creating upgraded release for traefik client.go:218: [debug] checking 5 resources for changes client.go:493: [debug] Replaced \u0026#34;traefik\u0026#34; with kind ServiceAccount for kind ServiceAccount client.go:493: [debug] Replaced \u0026#34;traefik\u0026#34; with kind ClusterRole for kind ClusterRole client.go:493: [debug] Replaced \u0026#34;traefik\u0026#34; with kind ClusterRoleBinding for kind ClusterRoleBinding client.go:250: [debug] error updating the resource \u0026#34;traefik\u0026#34;: failed to replace object: Deployment.apps \u0026#34;traefik\u0026#34; is invalid: spec.selector: Invalid value: v1.LabelSelector{MatchLabels:map[string]string{\u0026#34;app.kubernetes.io/instance\u0026#34;:\u0026#34;traefik\u0026#34;, \u0026#34;app.kubernetes.io/name\u0026#34;:\u0026#34;traefik\u0026#34;}, MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: field is immutable client.go:250: [debug] error updating the resource \u0026#34;traefik\u0026#34;: failed to replace object: Service \u0026#34;traefik\u0026#34; is invalid: spec.clusterIPs[0]: Invalid value: []string(nil): primary clusterIP can not be unset upgrade.go:430: [debug] warning: Upgrade \u0026#34;traefik\u0026#34; failed: failed to replace object: Deployment.apps \u0026#34;traefik\u0026#34; is invalid: spec.selector: Invalid value: v1.LabelSelector{MatchLabels:map[string]string{\u0026#34;app.kubernetes.io/instance\u0026#34;:\u0026#34;traefik\u0026#34;, \u0026#34;app.kubernetes.io/name\u0026#34;:\u0026#34;traefik\u0026#34;}, MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: field is immutable \u0026amp;\u0026amp; failed to replace object: Service \u0026#34;traefik\u0026#34; is invalid: spec.clusterIPs[0]: Invalid value: []string(nil): primary clusterIP can not be unset Error: UPGRADE FAILED: failed to replace object: Deployment.apps \u0026#34;traefik\u0026#34; is invalid: spec.selector: Invalid value: v1.LabelSelector{MatchLabels:map[string]string{\u0026#34;app.kubernetes.io/instance\u0026#34;:\u0026#34;traefik\u0026#34;, \u0026#34;app.kubernetes.io/name\u0026#34;:\u0026#34;traefik\u0026#34;}, MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: field is immutable \u0026amp;\u0026amp; failed to replace object: Service \u0026#34;traefik\u0026#34; is invalid: spec.clusterIPs[0]: Invalid value: []string(nil): primary clusterIP can not be unset helm.go:88: [debug] failed to replace object: Deployment.apps \u0026#34;traefik\u0026#34; is invalid: spec.selector: Invalid value: v1.LabelSelector{MatchLabels:map[string]string{\u0026#34;app.kubernetes.io/instance\u0026#34;:\u0026#34;traefik\u0026#34;, \u0026#34;app.kubernetes.io/name\u0026#34;:\u0026#34;traefik\u0026#34;}, MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: field is immutable \u0026amp;\u0026amp; failed to replace object: Service \u0026#34;traefik\u0026#34; is invalid: spec.clusterIPs[0]: Invalid value: []string(nil): primary clusterIP can not be unset helm.sh/helm/v3/pkg/kube.(*Client).Update helm.sh/helm/v3/pkg/kube/client.go:263 helm.sh/helm/v3/pkg/action.(*Upgrade).releasingUpgrade helm.sh/helm/v3/pkg/action/upgrade.go:375 runtime.goexit runtime/asm_arm64.s:1133 UPGRADE FAILED main.newUpgradeCmd.func2 helm.sh/helm/v3/cmd/helm/upgrade.go:202 github.com/spf13/cobra.(*Command).execute github.com/spf13/cobra@v1.2.1/command.go:856 github.com/spf13/cobra.(*Command).ExecuteC github.com/spf13/cobra@v1.2.1/command.go:974 github.com/spf13/cobra.(*Command).Execute github.com/spf13/cobra@v1.2.1/command.go:902 main.main helm.sh/helm/v3/cmd/helm/helm.go:87 runtime.main runtime/proc.go:255 runtime.goexit runtime/asm_arm64.s:1133 You can see the problem about the labels because they\u0026rsquo;re immutable, therefore, what I have done is to deploy a parallel traefik deployment (in version 2.5.6) which sits with the older version (1.8.7). There are no issues, because the ELB which Traefik creates by default (if you\u0026rsquo;re using AWS) is not used in our DNS. When I want to test it externally, I do need to create a new CNAME and point it to the:\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE cerebro ClusterIP 100.65.108.89 \u0026lt;none\u0026gt; 80/TCP 539d kubernetes ClusterIP 100.64.0.1 \u0026lt;none\u0026gt; 443/TCP 540d tokenservice ClusterIP 100.66.106.178 \u0026lt;none\u0026gt; 3000/TCP 390d traefik LoadBalancer 100.67.75.183 a2c139e9a42564cbb897203cd2f9f16d-740162447.us-east-1.elb.amazonaws.com 443:30809/TCP,80:32518/TCP 11d traefik-dashboard ClusterIP 100.67.228.71 \u0026lt;none\u0026gt; 80/TCP 11d traefik2 LoadBalancer 100.69.196.88 a60c47c8fa23e4f09b562afc93e80274-894996197.us-east-1.elb.amazonaws.com 80:31852/TCP,443:30701/TCP 5h57m Installing Traefik2 in parallel with current deployment. Then as this doesn\u0026rsquo;t work, we will install Traefik v2 as a parallel deployment: ~/Kodify/infrastructure/kubernetes/staging/namespaces/default/traefik │ SYS-1556/Traefik_upgrade  date;helm install traefik2 -f values.yaml traefik/traefik --version 10.9.1 --debug  ✔ │ tubes-stg ⎈ │ 12:50:30 Mon Mar 7 12:51:41 CET 2022 install.go:178: [debug] Original chart version: \u0026#34;10.9.1\u0026#34; install.go:199: [debug] CHART PATH: /Users/dba7x/Library/Caches/helm/repository/traefik-10.9.1.tgz client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD ingressroutes.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD ingressroutetcps.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD ingressrouteudps.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD middlewares.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD middlewaretcps.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD serverstransports.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD tlsoptions.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD tlsstores.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 1 resource(s) install.go:151: [debug] CRD traefikservices.traefik.containo.us is already present. Skipping. client.go:128: [debug] creating 5 resource(s) client.go:299: [debug] Starting delete for \u0026#34;traefik2-dashboard\u0026#34; IngressRoute client.go:128: [debug] creating 1 resource(s) NAME: traefik2 LAST DEPLOYED: Mon Mar 7 12:51:49 2022 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None USER-SUPPLIED VALUES: accessLogs: enabled: true fields: defaultMode: keep headers: defaultMode: drop names: Referer: keep User-Agent: keep format: json additionalArguments: - --providers.kubernetesCRD.allowCrossNamespace=true - --providers.kubernetesingress.ingressclass=traefik-staging autoscaling: maxReplicas: 5 metrics: - resource: name: cpu targetAverageUtilization: 70 type: Resource minReplicas: 1 dashboard: domain: traefik.kodify.com enabled: true debug: enabled: false deployment: hostPort: dashboardEnabled: true httpEnabled: true httpsEnabled: true deploymentStrategy: rollingUpdate: maxSurge: 1 maxUnavailable: 1 type: RollingUpdate externalTrafficPolicy: Local forwardedHeaders: enabled: false gzip: enabled: true image: name: traefik tag: 2.5.6 metrics: prometheus: enabled: false serviceMonitor: enabled: false proxyProtocol: enabled: true trustedIPs: - 10.0.0.0/8 rbac: enabled: true replicas: 1 resources: limits: memory: 500Mi requests: cpu: 200m memory: 200Mi sendAnonymousUsage: false service: annotations: service.beta.kubernetes.io/aws-load-balancer-proxy-protocol: \u0026#39;*\u0026#39; serviceType: LoadBalancer ssl: enabled: true enforced: false insecureSkipVerify: false upstream: false tolerations: [] tracing: enabled: false serviceName: traefik traefikLogFormat: json websecure: tls: enabled: true Then re-formatting the values.yaml file used in the helm release to use the appropiate values and removes the ones not needed as stated in the official chart repository\nIssue with HTTPS endpoints I created a new CNAME record pointing to the new ELB created and when I try to access with curl I found that HTTPS didn\u0026rsquo;t work correctly.\ncurl -vvv https://int.fux.com  ✔ │ 18:06:49 * Trying 54.156.8.198:443... * Connected to int.fux.com (54.156.8.198) port 443 (#0) * ALPN, offering h2 * ALPN, offering http/1.1 * successfully set certificate verify locations: * CAfile: /etc/ssl/cert.pem * CApath: none * TLSv1.2 (OUT), TLS handshake, Client hello (1): * TLSv1.2 (IN), TLS handshake, Server hello (2): * TLSv1.2 (IN), TLS handshake, Certificate (11): * TLSv1.2 (IN), TLS handshake, Server key exchange (12): * TLSv1.2 (IN), TLS handshake, Server finished (14): * TLSv1.2 (OUT), TLS handshake, Client key exchange (16): * TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1): * TLSv1.2 (OUT), TLS handshake, Finished (20): * TLSv1.2 (IN), TLS change cipher, Change cipher spec (1): * TLSv1.2 (IN), TLS handshake, Finished (20): * SSL connection using TLSv1.2 / ECDHE-RSA-CHACHA20-POLY1305 * ALPN, server accepted to use h2 * Server certificate: * subject: OU=Domain Control Validated; CN=*.fux.com * start date: Jun 7 13:06:34 2021 GMT * expire date: Jul 9 13:06:34 2022 GMT * subjectAltName: host \u0026#34;int.fux.com\u0026#34; matched cert\u0026#39;s \u0026#34;*.fux.com\u0026#34; * issuer: C=US; ST=Arizona; L=Scottsdale; O=GoDaddy.com, Inc.; OU=http://certs.godaddy.com/repository/; CN=Go Daddy Secure Certificate Authority - G2 * SSL certificate verify ok. * Using HTTP2, server supports multi-use * Connection state changed (HTTP/2 confirmed) * Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0 * Using Stream ID: 1 (easy handle 0x13e811e00) \u0026gt; GET / HTTP/2 \u0026gt; Host: int.fux.com \u0026gt; user-agent: curl/7.77.0 \u0026gt; accept: */* \u0026gt; * Connection state changed (MAX_CONCURRENT_STREAMS == 250)! \u0026lt; HTTP/2 404 \u0026lt; content-type: text/plain; charset=utf-8 \u0026lt; x-content-type-options: nosniff \u0026lt; content-length: 19 \u0026lt; date: Mon, 07 Mar 2022 17:06:50 GMT \u0026lt; 404 page not found * Connection #0 to host int.fux.com left intact So, HTTP works but not HTTPs (although is presenting me the certifictate correctly). Then, what what am I missing?\nAfter reviewing the breaking changes from Traefik 1.x and 2.x, in my case, the problem is that my ingress resource doesn\u0026rsquo;t have the necessary annotation to enable TLS.\nAnd if I check the ingress (here I am using the Ingress resource from K8s not the Ingressroute from Traefik) I see that is missing traefik.ingress.kubernetes.io/router.tls: \u0026quot;true\u0026quot;:\nk get ingress -n fux fux-front -o yaml apiVersion: networking.k8s.io/v1 kind: Ingress metadata: annotations: ingress.kubernetes.io/ssl-redirect: \u0026#34;false\u0026#34; ingress.kubernetes.io/whitelist-x-forwarded-for: \u0026#34;true\u0026#34; kubectl.kubernetes.io/last-applied-configuration: | {\u0026#34;apiVersion\u0026#34;:\u0026#34;extensions/v1beta1\u0026#34;,\u0026#34;kind\u0026#34;:\u0026#34;Ingress\u0026#34;,\u0026#34;metadata\u0026#34;:{\u0026#34;annotations\u0026#34;:{\u0026#34;ingress.kubernetes.io/ssl-redirect\u0026#34;:\u0026#34;false\u0026#34;,\u0026#34;ingress.kubernetes.io/whitelist-x-forwarded-for\u0026#34;:\u0026#34;true\u0026#34;,\u0026#34;kubernetes.io/ingress.class\u0026#34;:\u0026#34;traefik-staging\u0026#34;,\u0026#34;kubernetes.io/tls-acme\u0026#34;:\u0026#34;true\u0026#34;,\u0026#34;meta.helm.sh/release-name\u0026#34;:\u0026#34;fux-front\u0026#34;,\u0026#34;meta.helm.sh/release-namespace\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;status\u0026#34;:{\u0026#34;loadBalancer\u0026#34;:{}}} kubernetes.io/ingress.class: traefik-staging kubernetes.io/tls-acme: \u0026#34;true\u0026#34; meta.helm.sh/release-name: fux-front meta.helm.sh/release-namespace: fux creationTimestamp: \u0026#34;2020-12-08T13:55:03Z\u0026#34; generation: 1 labels: app.kubernetes.io/managed-by: Helm name: fux-front namespace: fux resourceVersion: \u0026#34;194662430\u0026#34; uid: 27406fb6-65f8-44ef-a396-e6bf656144f1 spec: rules: - host: int.fux.com http: paths: - backend: service: name: fux-front port: number: 80 path: / pathType: ImplementationSpecific tls: Solution I just added traefik.ingress.kubernetes.io/router.tls: \u0026quot;true\u0026quot; to my ingress resource by editing or just redeploying your ingress and, finally it works:\n curl -v https://int.fux.com  0|1 ✘ │ 16:41:40 * Trying 34.196.145.235:443... * Connected to int.fux.com (34.196.145.235) port 443 (#0) * ALPN, offering h2 * ALPN, offering http/1.1 * successfully set certificate verify locations: * CAfile: /etc/ssl/cert.pem * CApath: none * TLSv1.2 (OUT), TLS handshake, Client hello (1): * TLSv1.2 (IN), TLS handshake, Server hello (2): * TLSv1.2 (IN), TLS handshake, Certificate (11): * TLSv1.2 (IN), TLS handshake, Server key exchange (12): * TLSv1.2 (IN), TLS handshake, Server finished (14): * TLSv1.2 (OUT), TLS handshake, Client key exchange (16): * TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1): * TLSv1.2 (OUT), TLS handshake, Finished (20): * TLSv1.2 (IN), TLS change cipher, Change cipher spec (1): * TLSv1.2 (IN), TLS handshake, Finished (20): * SSL connection using TLSv1.2 / ECDHE-RSA-CHACHA20-POLY1305 * ALPN, server accepted to use h2 * Server certificate: * subject: OU=Domain Control Validated; CN=*.fux.com * start date: Jun 7 13:06:34 2021 GMT * expire date: Jul 9 13:06:34 2022 GMT * subjectAltName: host \u0026#34;int.fux.com\u0026#34; matched cert\u0026#39;s \u0026#34;*.fux.com\u0026#34; * issuer: C=US; ST=Arizona; L=Scottsdale; O=GoDaddy.com, Inc.; OU=http://certs.godaddy.com/repository/; CN=Go Daddy Secure Certificate Authority - G2 * SSL certificate verify ok. * Using HTTP2, server supports multi-use * Connection state changed (HTTP/2 confirmed) * Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0 * Using Stream ID: 1 (easy handle 0x120010600) \u0026gt; GET / HTTP/2 \u0026gt; Host: int.fux.com \u0026gt; user-agent: curl/7.77.0 \u0026gt; accept: */* \u0026gt; * Connection state changed (MAX_CONCURRENT_STREAMS == 250)! \u0026lt; HTTP/2 200 \u0026lt; content-type: text/html; charset=utf-8 \u0026lt; date: Tue, 08 Mar 2022 15:41:46 GMT \u0026lt; etag: W/\u0026#34;50590-miVJLAHT/A1iTR6izN3u0hAsgL4\u0026#34; \u0026lt; server: nginx/1.11.13 \u0026lt; strict-transport-security: max-age=15552000; includeSubDomains \u0026lt; vary: Accept-Encoding \u0026lt; x-content-type-options: nosniff \u0026lt; x-dns-prefetch-control: off \u0026lt; x-download-options: noopen \u0026lt; x-frame-options: SAMEORIGIN \u0026lt; x-xss-protection: 1; mode=block \u0026lt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt; . . . \u0026lt;script\u0026gt; \u0026lt;/script\u0026gt; \u0026lt;script async src=\u0026#39;https://www.google-analytics.com/analytics.js\u0026#39;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; * Connection #0 to host int.fux.com left intact Then I upgraded to latest chart version (after changing my values.yaml):\ndate;helm upgrade traefik2 -f values.yaml traefik/traefik --version 10.14.2\nSide notes Found that for Whitelisting IPs, you need to use a middleware instead of the annotation in the ingress. Then in your ingress, point to that middleware you have created. ![[Pasted image 20220405174110.png]]\nMiddleware created:\n![[Pasted image 20220405174158.png]]\nGood thing to test if it works correctly is pointing your etc/hosts to the Public IP of the LB you have created in Kubernetes. ![[Pasted image 20220405174348.png]]\nThen in your /etc/hosts\n![[Pasted image 20220405174411.png]]\n","permalink":"https://dangaiden.github.io/post/2022/upgrading-traefik-with-helm/","summary":"Traefik upgrade The overall process Context Upgrading traefik from 1.7.26 (chart traefik-1.87.7) to 2.5.6 (chart 10.9.1) isn\u0026rsquo;t possible because of labels immutability: ❯ helm upgrade -i traefik -n default -f values.yaml traefik/traefik --version 10.9.1 --force --debug history.go:56: [debug] getting history for release traefik upgrade.go:139: [debug] preparing upgrade for traefik upgrade.go:147: [debug] performing update for traefik upgrade.go:319: [debug] creating upgraded release for traefik client.go:218: [debug] checking 5 resources for changes client.go:493: [debug] Replaced \u0026#34;traefik\u0026#34; with kind ServiceAccount for kind ServiceAccount client.","title":""},{"content":"Let me talk to you about my experience on my first VMworld! This is a personal experience I want to share about Day 1 at VMworld 2018 Europe.\nIntroduction I live in Barcelona so, I am fortunate that I don’t need to travel to go to the VMworld Europe. The only thing is to commute by train between home and Fira Barcelona (where VMworld is established). It was Monday, November 5th, 2018. I woke up around 6 AM and took the train to arrive at 8 AM approximately.\nThis is how the entrance looked:\nInside VMworld I picked up my badge (using a QR code from the VMworld app) and headed to the VMvillage (the main place on this event). After taking some pictures… I went to take a lab at the HOL Lounge, why? Because I wanted to try new labs, there are more slots available and I wanted to feel an experience like that at VMworld. Also, you learn some coins for the VMware code ( http://vmwcc.com/).\nThe first day is the calm day, I mean, the Solutions Exchange (where partners have their booths) is not opened and there are less interesting sessions (at least for my self) than other days. People usually are on TAM/Partners sessions or maybe they come on Tuesday.\nI explored every enclosure’s corner and checked where were all Halls (to not waste more time the next day). There was food everywhere, from sandwiches to pastries and of course coffee, you could pick it on any lounge or at the VMvillage for free.\nIn the middle of the VMvillage, there was a Gaming Area with a table tennis table, pinball machines, a giant table football and more things… my favourite part, the Arcade machines with a lot of games!\nI was eager to meet some people I met on Twitter and of course, I did it!\nThe first person I met was Graham Barker @VirtualG_UK an awesome guy who which I spent some time in the beginning, now I am thinking we didn’t take a selfie…\nAlso, I met Angelo Luciani @AngeloLuciani, very kind guy! He takes selfies with a lot of people and always open to anyone, I chatted with him a bit and it was a pleasure.\nSee you…tomorrow! At the end of the day, I had some workshops to attend and couldn’t meet more people (obviously some of them are busy in the first day) but this only was the beginning of an awesome journey that will start at the next day, when the action begins.\nI returned home early as I had things to do and also on the next day vBreakfast will be awaiting me (at 7:00 AM). So, the first day was a great experience, is more dedicated for the partners but maybe you can network with people that on the next days will have no time (as probably you).\nIn the next post, the second day, hasta la vista!\n","permalink":"https://dangaiden.github.io/2018-11-19-vmworld-18-eu-day1/","summary":"Let me talk to you about my experience on my first VMworld! This is a personal experience I want to share about Day 1 at VMworld 2018 Europe.\nIntroduction I live in Barcelona so, I am fortunate that I don’t need to travel to go to the VMworld Europe. The only thing is to commute by train between home and Fira Barcelona (where VMworld is established). It was Monday, November 5th, 2018.","title":"Experience at VMworld 2018 Europe – Day 1"},{"content":"Context Let\u0026rsquo;s continue with the guide, in this part 2.\nThis is based in: https://github.com/kelseyhightower/kubernetes-the-hard-way/blob/master/docs/03-compute-resources.md\nKubernetes Controllers We will be using the following CIDR 192.168.1.0/24 for node within the cluster:\nSomred1: 192.168.1.50/24 Somred2: 192.168.1.51/24 Somred3: 192.168.1.52/24 Kubernetes Workers This nodes will act as the Kubernetes workers nodes which will host the pods, we need to have 2 NICs for each node.\nOne NIC will be the one used before to communicate with the other nodes: 192.168.1.0/24\nTherefore:\nWorknet1 NIC1: 192.168.1.101 Worknet2 NIC1: 192.168.1.102 Worknet3 NIC1: 192.168.1.103 %%We will be using the following pod CIDR 10.200.0.0/16 for each worker node.\nWorknet1 NIC2: 10.200.1.1/24 Worknet2 NIC2: 10.200.2.1/24 Worknet3 NIC2: 10.200.3.1/24%% ","permalink":"https://dangaiden.github.io/kubernetes-the-hard-way-but-on-prem-part2/","summary":"Context Let\u0026rsquo;s continue with the guide, in this part 2.\nThis is based in: https://github.com/kelseyhightower/kubernetes-the-hard-way/blob/master/docs/03-compute-resources.md\nKubernetes Controllers We will be using the following CIDR 192.168.1.0/24 for node within the cluster:\nSomred1: 192.168.1.50/24 Somred2: 192.168.1.51/24 Somred3: 192.168.1.52/24 Kubernetes Workers This nodes will act as the Kubernetes workers nodes which will host the pods, we need to have 2 NICs for each node.\nOne NIC will be the one used before to communicate with the other nodes: 192.","title":"Kubernetes the hard way but on-prem - part 2"}]